<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/RyanLi.github.io/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/RyanLi.github.io/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/RyanLi.github.io/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/RyanLi.github.io/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/RyanLi.github.io/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/RyanLi.github.io/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/RyanLi.github.io/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="I miss u.">
<meta property="og:type" content="website">
<meta property="og:title" content="Ryan Li God">
<meta property="og:url" content="https://ryanlic.github.io/index.html">
<meta property="og:site_name" content="Ryan Li God">
<meta property="og:description" content="I miss u.">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Ryan Li God">
<meta name="twitter:description" content="I miss u.">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/RyanLi.github.io/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":true,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://ryanlic.github.io/"/>





  <title>Ryan Li God</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/RyanLi.github.io/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Ryan Li God</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/RyanLi.github.io/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/RyanLi.github.io/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://ryanlic.github.io/RyanLi.github.io/2018/08/03/2018-08-03 Spark RDD常用算子操作合辑/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ryan Li">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/RyanLi.github.io/uploads/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ryan Li God">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/RyanLi.github.io/2018/08/03/2018-08-03 Spark RDD常用算子操作合辑/" itemprop="url">Spark RDD常用算子操作合辑</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-08-03T21:21:50+10:00">
                2018-08-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote><p>本文作者：翟开顺<br>首发：CSDN<br>本人仅为自己方便查阅做了摘抄，请支持原作者。<br>原文地址：<a href="https://blog.csdn.net/t1dmzks/article/details/72077428" target="_blank" rel="noopener">https://blog.csdn.net/t1dmzks/article/details/72077428</a></p>
</blockquote>
<h1 id="parallelize，makeRDD，textFile"><a href="#parallelize，makeRDD，textFile" class="headerlink" title="parallelize，makeRDD，textFile"></a>parallelize，makeRDD，textFile</h1><h2 id="parallelize"><a href="#parallelize" class="headerlink" title="parallelize"></a>parallelize</h2><p>调用SparkContext 的 parallelize()，将一个存在的集合，变成一个RDD，这种方式试用于学习spark和做一些spark的测试</p>
<p><strong>scala版本</strong><br>def parallelize[T](seq: Seq[T], numSlices: Int = defaultParallelism)(implicit arg0: ClassTag[T]): RDD[T] </p>
<ul>
<li>第一个参数一是一个 Seq集合 </li>
<li>第二个参数是分区数 </li>
<li>返回的是RDD[T]</li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; sc.parallelize(<span class="type">List</span>(<span class="string">"shenzhen"</span>, <span class="string">"is a beautiful city"</span>))</span><br><span class="line">res1: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">String</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">1</span>] at parallelize at &lt;console&gt;:<span class="number">22</span></span><br></pre></td></tr></table></figure>
<p><strong>java版本</strong><br>def parallelize[T](list : java.util.List[T], numSlices : scala.Int) : org.apache.spark.api.java.JavaRDD[T] = { /* compiled code */ } </p>
<ul>
<li>第一个参数是一个List集合 </li>
<li>第二个参数是一个分区，可以默认 </li>
<li>返回的是一个JavaRDD[T]<br>java版本只能接收List的集合</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;String&gt; javaStringRDD = sc.parallelize(Arrays.asList(<span class="string">"shenzhen"</span>, <span class="string">"is a beautiful city"</span>));</span><br></pre></td></tr></table></figure>
<h2 id="makeRDD"><a href="#makeRDD" class="headerlink" title="makeRDD"></a>makeRDD</h2><p>只有scala版本的才有makeRDD<br>def makeRDD[T](seq : scala.Seq[T], numSlices : scala.Int = { /* compiled code */ })<br>跟parallelize类似</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sc.makeRDD(<span class="type">List</span>(<span class="string">"shenzhen"</span>, <span class="string">"is a beautiful city"</span>))</span><br></pre></td></tr></table></figure>
<h2 id="textFile"><a href="#textFile" class="headerlink" title="textFile"></a>textFile</h2><p>调用SparkContext.textFile()方法，从外部存储中读取数据来创建 RDD<br>例如在我本地F:\dataexample\wordcount\input下有个sample.txt文件，文件随便写了点内容，我需要将里面的内容读取出来创建RDD</p>
<p><strong>scala版本</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> lines = sc.textFile(<span class="string">"F:\\dataexample\\wordcount\\input"</span>)</span><br></pre></td></tr></table></figure></p>
<p><strong>java版本</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;String&gt; lines = sc.textFile(<span class="string">"F:\\dataexample\\wordcount\\input"</span>);</span><br></pre></td></tr></table></figure></p>
<p>注: textFile支持分区，支持模式匹配，例如把F:\dataexample\wordcount\目录下inp开头的给转换成RDD<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">var lines = sc.textFile(<span class="string">"F:\\dataexample\\wordcount\\inp*"</span>)</span><br></pre></td></tr></table></figure></p>
<p>多个路径可以使用逗号分隔，例如<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">var lines = sc.textFile(<span class="string">"dir1,dir2"</span>,<span class="number">3</span>)</span><br></pre></td></tr></table></figure></p>
<hr>
<h1 id="filter-map-flatMap"><a href="#filter-map-flatMap" class="headerlink" title="filter,map,flatMap"></a>filter,map,flatMap</h1><h2 id="filter"><a href="#filter" class="headerlink" title="filter"></a>filter</h2><p>举例，在F:\sparktest\sample.txt 文件的内容如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">aa bb cc aa aa aa dd dd ee ee ee ee </span><br><span class="line">ff aa bb zks</span><br><span class="line">ee kks</span><br><span class="line">ee  zz zks</span><br></pre></td></tr></table></figure></p>
<p>我要将包含zks的行的内容给找出来<br><strong>scala版本</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">    <span class="keyword">val</span> lines = sc.textFile(<span class="string">"F:\\sparktest\\sample.txt"</span>).filter(line=&gt;line.contains(<span class="string">"zks"</span>))</span><br><span class="line">    <span class="comment">//打印内容</span></span><br><span class="line">    lines.collect().foreach(println(_));</span><br><span class="line">-------------输出------------------</span><br><span class="line">ff aa bb zks</span><br><span class="line">ee  zz zks</span><br></pre></td></tr></table></figure></p>
<p><strong>java版本</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">        JavaRDD&lt;String&gt; lines = sc.textFile(<span class="string">"F:\\sparktest\\sample.txt"</span>);</span><br><span class="line">        JavaRDD&lt;String&gt; zksRDD = lines.filter(<span class="keyword">new</span> Function&lt;String, Boolean&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> Boolean <span class="title">call</span><span class="params">(String s)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> s.contains(<span class="string">"zks"</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="comment">//打印内容</span></span><br><span class="line">        List&lt;String&gt; zksCollect = zksRDD.collect();</span><br><span class="line">        <span class="keyword">for</span> (String str:zksCollect) &#123;</span><br><span class="line">            System.out.println(str);</span><br><span class="line">        &#125;</span><br><span class="line">----------------输出-------------------</span><br><span class="line">ff aa bb zks</span><br><span class="line">ee  zz zks</span><br></pre></td></tr></table></figure></p>
<h2 id="map"><a href="#map" class="headerlink" title="map"></a>map</h2><p>map() 接收一个函数，把这个函数用于 RDD 中的每个元素，将函数的返回结果作为结果RDD编程 ｜ 31<br>RDD 中对应元素的值 map是一对一的关系<br>举例，在F:\sparktest\sample.txt 文件的内容如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">aa bb cc aa aa aa dd dd ee ee ee ee </span><br><span class="line">ff aa bb zks</span><br><span class="line">ee kks</span><br><span class="line">ee  zz zks</span><br></pre></td></tr></table></figure></p>
<p>把每一行变成一个数组<br><strong>scala版本</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//读取数据</span></span><br><span class="line">scala&gt; <span class="keyword">val</span> lines = sc.textFile(<span class="string">"F:\\sparktest\\sample.txt"</span>)</span><br><span class="line"><span class="comment">//用map，对于每一行数据，按照空格分割成一个一个数组，然后返回的是一对一的关系</span></span><br><span class="line">scala&gt; <span class="keyword">var</span> mapRDD = lines.map(line =&gt; line.split(<span class="string">"\\s+"</span>))</span><br><span class="line">---------------输出-----------</span><br><span class="line">res0: <span class="type">Array</span>[<span class="type">Array</span>[<span class="type">String</span>]] = <span class="type">Array</span>(<span class="type">Array</span>(aa, bb, cc, aa, aa, aa, dd, dd, ee, ee, ee, ee), <span class="type">Array</span>(ff, aa, bb, zks), <span class="type">Array</span>(ee, kks), <span class="type">Array</span>(ee, zz, zks))</span><br><span class="line"><span class="comment">//读取第一个元素</span></span><br><span class="line">scala&gt; mapRDD.first</span><br><span class="line">---输出----</span><br><span class="line">res1: <span class="type">Array</span>[<span class="type">String</span>] = <span class="type">Array</span>(aa, bb, cc, aa, aa, aa, dd, dd, ee, ee, ee, ee)</span><br></pre></td></tr></table></figure></p>
<p><strong>java版本</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">    JavaRDD&lt;Iterable&lt;String&gt;&gt; mapRDD = lines.map(<span class="keyword">new</span> Function&lt;String, Iterable&lt;String&gt;&gt;() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> Iterable&lt;String&gt; <span class="title">call</span><span class="params">(String s)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">            String[] split = s.split(<span class="string">"\\s+"</span>);</span><br><span class="line">            <span class="keyword">return</span> Arrays.asList(split);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">    <span class="comment">//读取第一个元素</span></span><br><span class="line">    System.out.println(mapRDD.first());</span><br><span class="line">---------------输出-------------</span><br><span class="line">[aa, bb, cc, aa, aa, aa, dd, dd, ee, ee, ee, ee]</span><br></pre></td></tr></table></figure></p>
<h2 id="flatMap"><a href="#flatMap" class="headerlink" title="flatMap"></a>flatMap</h2><p>有时候，我们希望对某个元素生成多个元素，实现该功能的操作叫作 flatMap()<br>faltMap的函数应用于每一个元素，对于每一个元素返回的是多个元素组成的迭代器(想要了解更多，请参考scala的flatMap和map用法)<br>例如我们将数据切分为单词<br><strong>scala版本</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">    scala&gt;  <span class="keyword">val</span> lines = sc.textFile(<span class="string">"F:\\sparktest\\sample.txt"</span>)</span><br><span class="line">    scala&gt; <span class="keyword">val</span> flatMapRDD = lines.flatMap(line=&gt;line.split(<span class="string">"\\s"</span>))</span><br><span class="line">    scala&gt; flatMapRDD.first() </span><br><span class="line">---输出----</span><br><span class="line">res0: <span class="type">String</span> = aa</span><br></pre></td></tr></table></figure></p>
<p><strong>java版本，spark2.0以下</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">    JavaRDD&lt;String&gt; lines = sc.textFile(<span class="string">"F:\\sparktest\\sample.txt"</span>);</span><br><span class="line">    JavaRDD&lt;String&gt; flatMapRDD = lines.flatMap(<span class="keyword">new</span> FlatMapFunction&lt;String, String&gt;() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> Iterable&lt;String&gt; <span class="title">call</span><span class="params">(String s)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">            String[] split = s.split(<span class="string">"\\s+"</span>);</span><br><span class="line">            <span class="keyword">return</span> Arrays.asList(split);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">    <span class="comment">//输出第一个</span></span><br><span class="line">    System.out.println(flatMapRDD.first());</span><br><span class="line">------------输出----------</span><br><span class="line">aa</span><br></pre></td></tr></table></figure></p>
<p><strong>java版本，spark2.0以上</strong><br>spark2.0以上，对flatMap的方法有所修改，就是flatMap中的Iterator和Iteratable的小区别<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;String&gt; flatMapRDD = lines.flatMap(<span class="keyword">new</span> FlatMapFunction&lt;String, String&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Iterator&lt;String&gt; <span class="title">call</span><span class="params">(String s)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        String[] split = s.split(<span class="string">"\\s+"</span>);</span><br><span class="line">        <span class="keyword">return</span> Arrays.asList(split).iterator();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure></p>
<hr>
<h1 id="distinct，union，intersection，subtract，cartesian"><a href="#distinct，union，intersection，subtract，cartesian" class="headerlink" title="distinct，union，intersection，subtract，cartesian"></a>distinct，union，intersection，subtract，cartesian</h1><p><strong>spark伪集合</strong><br>尽管 RDD 本身不是严格意义上的集合，但它也支持许多数学上的集合操作，比如合并和相交操作, 下图展示了这四种操作 </p>
<h2 id="distinct"><a href="#distinct" class="headerlink" title="distinct"></a>distinct</h2><p>distinct用于去重， 我们生成的RDD可能有重复的元素，使用distinct方法可以去掉重复的元素, 不过此方法涉及到混洗，操作开销很大<br><strong>scala版本</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">var</span> <span class="type">RDD1</span> = sc.parallelize(<span class="type">List</span>(<span class="string">"aa"</span>,<span class="string">"aa"</span>,<span class="string">"bb"</span>,<span class="string">"cc"</span>,<span class="string">"dd"</span>))</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="type">RDD1</span>.collect</span><br><span class="line">res3: <span class="type">Array</span>[<span class="type">String</span>] = <span class="type">Array</span>(aa, aa, bb, cc, dd)</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">var</span> distinctRDD = <span class="type">RDD1</span>.distinct</span><br><span class="line"></span><br><span class="line">scala&gt; distinctRDD.collect</span><br><span class="line">res5: <span class="type">Array</span>[<span class="type">String</span>] = <span class="type">Array</span>(aa, dd, bb, cc)</span><br></pre></td></tr></table></figure></p>
<p><strong>java版本</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">    JavaRDD&lt;String&gt; RDD1 = sc.parallelize(Arrays.asList(<span class="string">"aa"</span>, <span class="string">"aa"</span>, <span class="string">"bb"</span>, <span class="string">"cc"</span>, <span class="string">"dd"</span>));</span><br><span class="line">    JavaRDD&lt;String&gt; distinctRDD = RDD1.distinct();</span><br><span class="line">    List&lt;String&gt; collect = distinctRDD.collect();</span><br><span class="line">    <span class="keyword">for</span> (String str:collect) &#123;</span><br><span class="line">        System.out.print(str+<span class="string">", "</span>);</span><br><span class="line">    &#125;</span><br><span class="line">---------输出----------</span><br><span class="line">aa, dd, bb, cc,</span><br></pre></td></tr></table></figure></p>
<h2 id="union"><a href="#union" class="headerlink" title="union"></a>union</h2><p>两个RDD进行合并<br><strong>scala版本</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">var</span> <span class="type">RDD1</span> = sc.parallelize(<span class="type">List</span>(<span class="string">"aa"</span>,<span class="string">"aa"</span>,<span class="string">"bb"</span>,<span class="string">"cc"</span>,<span class="string">"dd"</span>))</span><br><span class="line">scala&gt; <span class="keyword">var</span> <span class="type">RDD2</span> = sc.parallelize(<span class="type">List</span>(<span class="string">"aa"</span>,<span class="string">"dd"</span>,<span class="string">"ff"</span>))</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="type">RDD1</span>.collect</span><br><span class="line">res6: <span class="type">Array</span>[<span class="type">String</span>] = <span class="type">Array</span>(aa, aa, bb, cc, dd)</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="type">RDD2</span>.collect</span><br><span class="line">res7: <span class="type">Array</span>[<span class="type">String</span>] = <span class="type">Array</span>(aa, dd, ff)</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="type">RDD1</span>.union(<span class="type">RDD2</span>).collect</span><br><span class="line">res8: <span class="type">Array</span>[<span class="type">String</span>] = <span class="type">Array</span>(aa, aa, bb, cc, dd, aa, dd, ff)</span><br></pre></td></tr></table></figure></p>
<p><strong>java版本</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">    JavaRDD&lt;String&gt; RDD1 = sc.parallelize(Arrays.asList(<span class="string">"aa"</span>, <span class="string">"aa"</span>, <span class="string">"bb"</span>, <span class="string">"cc"</span>, <span class="string">"dd"</span>));</span><br><span class="line">    JavaRDD&lt;String&gt; RDD2 = sc.parallelize(Arrays.asList(<span class="string">"aa"</span>,<span class="string">"dd"</span>,<span class="string">"ff"</span>));</span><br><span class="line">    JavaRDD&lt;String&gt; unionRDD = RDD1.union(RDD2);</span><br><span class="line">    List&lt;String&gt; collect = unionRDD.collect();</span><br><span class="line">    <span class="keyword">for</span> (String str:collect) &#123;</span><br><span class="line">        System.out.print(str+<span class="string">", "</span>);</span><br><span class="line">    &#125;</span><br><span class="line">-----------输出---------</span><br><span class="line">aa, aa, bb, cc, dd, aa, dd, ff,</span><br></pre></td></tr></table></figure></p>
<h2 id="intersection"><a href="#intersection" class="headerlink" title="intersection"></a>intersection</h2><p>RDD1.intersection(RDD2) 返回两个RDD的交集，并且去重<br>intersection 需要混洗数据，比较浪费性能<br><strong>scala版本</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">var</span> <span class="type">RDD1</span> = sc.parallelize(<span class="type">List</span>(<span class="string">"aa"</span>,<span class="string">"aa"</span>,<span class="string">"bb"</span>,<span class="string">"cc"</span>,<span class="string">"dd"</span>))</span><br><span class="line">scala&gt; <span class="keyword">var</span> <span class="type">RDD2</span> = sc.parallelize(<span class="type">List</span>(<span class="string">"aa"</span>,<span class="string">"dd"</span>,<span class="string">"ff"</span>))</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="type">RDD1</span>.collect</span><br><span class="line">res6: <span class="type">Array</span>[<span class="type">String</span>] = <span class="type">Array</span>(aa, aa, bb, cc, dd)</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="type">RDD2</span>.collect</span><br><span class="line">res7: <span class="type">Array</span>[<span class="type">String</span>] = <span class="type">Array</span>(aa, dd, ff)</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">var</span> insertsectionRDD = <span class="type">RDD1</span>.intersection(<span class="type">RDD2</span>)</span><br><span class="line">scala&gt; insertsectionRDD.collect</span><br><span class="line"></span><br><span class="line">res9: <span class="type">Array</span>[<span class="type">String</span>] = <span class="type">Array</span>(aa, dd)</span><br></pre></td></tr></table></figure></p>
<p><strong>java版本</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">    JavaRDD&lt;String&gt; RDD1 = sc.parallelize(Arrays.asList(&quot;aa&quot;, &quot;aa&quot;, &quot;bb&quot;, &quot;cc&quot;, &quot;dd&quot;));</span><br><span class="line">    JavaRDD&lt;String&gt; RDD2 = sc.parallelize(Arrays.asList(&quot;aa&quot;,&quot;dd&quot;,&quot;ff&quot;));</span><br><span class="line">    JavaRDD&lt;String&gt; intersectionRDD = RDD1.intersection(RDD2);</span><br><span class="line">    List&lt;String&gt; collect = intersectionRDD.collect();</span><br><span class="line">    for (String str:collect) &#123;</span><br><span class="line">        System.out.print(str+&quot; &quot;);</span><br><span class="line">    &#125;</span><br><span class="line">-------------输出-----------</span><br><span class="line">aa dd</span><br></pre></td></tr></table></figure></p>
<h2 id="subtract"><a href="#subtract" class="headerlink" title="subtract"></a>subtract</h2><p>RDD1.subtract(RDD2),返回在RDD1中出现，但是不在RDD2中出现的元素，不去重<br><strong>scala版本</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">JavaRDD</span>&lt;<span class="type">String</span>&gt; <span class="type">RDD1</span> = sc.parallelize(<span class="type">Arrays</span>.asList(<span class="string">"aa"</span>, <span class="string">"aa"</span>,<span class="string">"bb"</span>, <span class="string">"cc"</span>, <span class="string">"dd"</span>));</span><br><span class="line"></span><br><span class="line"><span class="type">JavaRDD</span>&lt;<span class="type">String</span>&gt; <span class="type">RDD2</span> = sc.parallelize(<span class="type">Arrays</span>.asList(<span class="string">"aa"</span>,<span class="string">"dd"</span>,<span class="string">"ff"</span>));</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">var</span> substractRDD =<span class="type">RDD1</span>.subtract(<span class="type">RDD2</span>)</span><br><span class="line"></span><br><span class="line">scala&gt;  substractRDD.collect</span><br><span class="line">res10: <span class="type">Array</span>[<span class="type">String</span>] = <span class="type">Array</span>(bb, cc)</span><br></pre></td></tr></table></figure></p>
<p><strong>java版本</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">    JavaRDD&lt;String&gt; RDD1 = sc.parallelize(Arrays.asList(<span class="string">"aa"</span>, <span class="string">"aa"</span>, <span class="string">"bb"</span>,<span class="string">"cc"</span>, <span class="string">"dd"</span>));</span><br><span class="line">    JavaRDD&lt;String&gt; RDD2 = sc.parallelize(Arrays.asList(<span class="string">"aa"</span>,<span class="string">"dd"</span>,<span class="string">"ff"</span>));</span><br><span class="line">    JavaRDD&lt;String&gt; subtractRDD = RDD1.subtract(RDD2);</span><br><span class="line">    List&lt;String&gt; collect = subtractRDD.collect();</span><br><span class="line">    <span class="keyword">for</span> (String str:collect) &#123;</span><br><span class="line">        System.out.print(str+<span class="string">" "</span>);</span><br><span class="line">    &#125;</span><br><span class="line">------------输出-----------------</span><br><span class="line">bb  cc</span><br></pre></td></tr></table></figure></p>
<h2 id="cartesian"><a href="#cartesian" class="headerlink" title="cartesian"></a>cartesian</h2><p>RDD1.cartesian(RDD2) 返回RDD1和RDD2的笛卡儿积，这个开销非常大</p>
<p><strong>scala版本</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scala&gt;  <span class="keyword">var</span> <span class="type">RDD1</span> = sc.parallelize(<span class="type">List</span>(<span class="string">"1"</span>,<span class="string">"2"</span>,<span class="string">"3"</span>))</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">var</span> <span class="type">RDD2</span> = sc.parallelize(<span class="type">List</span>(<span class="string">"a"</span>,<span class="string">"b"</span>,<span class="string">"c"</span>))</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">var</span> cartesianRDD = <span class="type">RDD1</span>.cartesian(<span class="type">RDD2</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; cartesianRDD.collect</span><br><span class="line">res11: <span class="type">Array</span>[(<span class="type">String</span>, <span class="type">String</span>)] = <span class="type">Array</span>((<span class="number">1</span>,a), (<span class="number">1</span>,b), (<span class="number">1</span>,c), (<span class="number">2</span>,a), (<span class="number">2</span>,b), (<span class="number">2</span>,c), (<span class="number">3</span>,a), (<span class="number">3</span>,b), (<span class="number">3</span>,c))</span><br></pre></td></tr></table></figure></p>
<p><strong>java版本</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">    JavaRDD&lt;String&gt; RDD1 = sc.parallelize(Arrays.asList(<span class="string">"1"</span>, <span class="string">"2"</span>, <span class="string">"3"</span>));</span><br><span class="line">    JavaRDD&lt;String&gt; RDD2 = sc.parallelize(Arrays.asList(<span class="string">"a"</span>,<span class="string">"b"</span>,<span class="string">"c"</span>));</span><br><span class="line">    JavaPairRDD&lt;String, String&gt; cartesian = RDD1.cartesian(RDD2);</span><br><span class="line"></span><br><span class="line">    List&lt;Tuple2&lt;String, String&gt;&gt; collect1 = cartesian.collect();</span><br><span class="line">    <span class="keyword">for</span> (Tuple2&lt;String, String&gt; tp:collect1) &#123;</span><br><span class="line">        System.out.println(<span class="string">"("</span>+tp._1+<span class="string">" "</span>+tp._2+<span class="string">")"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">------------输出-----------------</span><br><span class="line">(<span class="number">1</span> a)</span><br><span class="line">(<span class="number">1</span> b)</span><br><span class="line">(<span class="number">1</span> c)</span><br><span class="line">(<span class="number">2</span> a)</span><br><span class="line">(<span class="number">2</span> b)</span><br><span class="line">(<span class="number">2</span> c)</span><br><span class="line">(<span class="number">3</span> a)</span><br><span class="line">(<span class="number">3</span> b)</span><br><span class="line">(<span class="number">3</span> c)</span><br></pre></td></tr></table></figure></p>
<hr>
<h1 id="创建键值对RDD-mapToPair-flatMapToPair"><a href="#创建键值对RDD-mapToPair-flatMapToPair" class="headerlink" title="创建键值对RDD mapToPair flatMapToPair"></a>创建键值对RDD mapToPair flatMapToPair</h1><h2 id="mapToPair"><a href="#mapToPair" class="headerlink" title="mapToPair"></a>mapToPair</h2><p>举例，在F:\sparktest\sample.txt 文件的内容如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">aa bb cc aa aa aa dd dd ee ee ee ee </span><br><span class="line">ff aa bb zks</span><br><span class="line">ee kks</span><br><span class="line">ee  zz zks</span><br></pre></td></tr></table></figure></p>
<p>将每一行的第一个单词作为键，1 作为value创建pairRDD<br><strong>scala版本</strong><br>scala是没有mapToPair函数的，scala版本只需要map就可以了<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> lines = sc.textFile(<span class="string">"F:\\sparktest\\sample.txt"</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> pairs = lines.map(x =&gt; (x.split(<span class="string">"\\s+"</span>)(<span class="number">0</span>), <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">scala&gt; pairs.collect</span><br><span class="line">res0: <span class="type">Array</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">Array</span>((aa,<span class="number">1</span>), (ff,<span class="number">1</span>), (ee,<span class="number">1</span>), (ee,<span class="number">1</span>))</span><br></pre></td></tr></table></figure></p>
<p><strong>java版本</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;String&gt; lines = sc.textFile(<span class="string">"F:\\sparktest\\sample.txt"</span>);</span><br><span class="line"><span class="comment">//输入的是一个string的字符串，输出的是一个(String, Integer) 的map</span></span><br><span class="line">JavaPairRDD&lt;String, Integer&gt; pairRDD = lines.mapToPair(<span class="keyword">new</span> PairFunction&lt;String, String, Integer&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Tuple2&lt;String, Integer&gt; <span class="title">call</span><span class="params">(String s)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> Tuple2&lt;String, Integer&gt;(s.split(<span class="string">"\\s+"</span>)[<span class="number">0</span>], <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure></p>
<h2 id="flatMapToPair"><a href="#flatMapToPair" class="headerlink" title="flatMapToPair"></a>flatMapToPair</h2><p>类似于xxx连接 mapToPair是一对一，一个元素返回一个元素，而flatMapToPair可以一个元素返回多个，相当于先flatMap,在mapToPair<br>例子: 将每一个单词都分成键为<br><strong>scala版本</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> lines = sc.textFile(<span class="string">"F:\\sparktest\\sample.txt"</span>)</span><br><span class="line"><span class="keyword">val</span> flatRDD = lines.flatMap(x =&gt; (x.split(<span class="string">"\\s+"</span>)))</span><br><span class="line"><span class="keyword">val</span> pairs = flatRDD.map(x=&gt;(x,<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">scala&gt; pairs.collect</span><br><span class="line">res1: <span class="type">Array</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">Array</span>((aa,<span class="number">1</span>), (bb,<span class="number">1</span>), (cc,<span class="number">1</span>), (aa,<span class="number">1</span>), (aa,<span class="number">1</span>), (aa,<span class="number">1</span>), (dd,<span class="number">1</span>), (dd,<span class="number">1</span>), (ee,<span class="number">1</span>), (ee,<span class="number">1</span>), (ee,<span class="number">1</span>), (ee,<span class="number">1</span>), (ff,<span class="number">1</span>), (aa,<span class="number">1</span>), (bb,<span class="number">1</span>), (zks,<span class="number">1</span>), (ee,<span class="number">1</span>), (kks,<span class="number">1</span>), (ee,<span class="number">1</span>), (zz,<span class="number">1</span>), (zks,<span class="number">1</span>))</span><br></pre></td></tr></table></figure></p>
<p><strong>java版本 spark2.0以下</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">JavaPairRDD&lt;String, Integer&gt; wordPairRDD = lines.flatMapToPair(<span class="keyword">new</span> PairFlatMapFunction&lt;String, String, Integer&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> Iterable&lt;Tuple2&lt;String, Integer&gt;&gt; call(String s) <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                ArrayList&lt;Tuple2&lt;String, Integer&gt;&gt; tpLists = <span class="keyword">new</span> ArrayList&lt;Tuple2&lt;String, Integer&gt;&gt;();</span><br><span class="line">                String[] split = s.split(<span class="string">"\\s+"</span>);</span><br><span class="line">                <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt;split.length ; i++) &#123;</span><br><span class="line">                    Tuple2 tp = <span class="keyword">new</span> Tuple2&lt;String,Integer&gt;(split[i], <span class="number">1</span>);</span><br><span class="line">                    tpLists.add(tp);</span><br><span class="line">                &#125;</span><br><span class="line">            <span class="keyword">return</span> tpLists;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br></pre></td></tr></table></figure></p>
<p><strong>java版本 spark2.0以上</strong><br>主要是iterator和iteratable的一些区别<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">JavaPairRDD&lt;String, Integer&gt; wordPairRDD = lines.flatMapToPair(<span class="keyword">new</span> PairFlatMapFunction&lt;String, String, Integer&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Iterator&lt;Tuple2&lt;String, Integer&gt;&gt; call(String s) <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        ArrayList&lt;Tuple2&lt;String, Integer&gt;&gt; tpLists = <span class="keyword">new</span> ArrayList&lt;Tuple2&lt;String, Integer&gt;&gt;();</span><br><span class="line">        String[] split = s.split(<span class="string">"\\s+"</span>);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt;split.length ; i++) &#123;</span><br><span class="line">            Tuple2 tp = <span class="keyword">new</span> Tuple2&lt;String,Integer&gt;(split[i], <span class="number">1</span>);</span><br><span class="line">            tpLists.add(tp);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> tpLists.iterator();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure></p>
<hr>
<h1 id="键值对聚合操作-combineByKey"><a href="#键值对聚合操作-combineByKey" class="headerlink" title="键值对聚合操作 combineByKey"></a>键值对聚合操作 combineByKey</h1><h2 id="combineByKey"><a href="#combineByKey" class="headerlink" title="combineByKey"></a>combineByKey</h2><p>聚合数据一般在集中式数据比较方便，如果涉及到分布式的数据集，该如何去实现呢。这里介绍一下combineByKey, 这个是各种聚集操作的鼻祖，应该要好好了解一下,参考<br><a href="http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.PairRDDFunctions" target="_blank" rel="noopener">scala API</a></p>
<h3 id="简要介绍"><a href="#简要介绍" class="headerlink" title="简要介绍"></a>简要介绍</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">combineByKey</span></span>[<span class="type">C</span>](createCombiner: (<span class="type">V</span>) =&gt; <span class="type">C</span>,  </span><br><span class="line">                    mergeValue: (<span class="type">C</span>, <span class="type">V</span>) =&gt; <span class="type">C</span>,   </span><br><span class="line">                    mergeCombiners: (<span class="type">C</span>, <span class="type">C</span>) =&gt; <span class="type">C</span>): <span class="type">RD</span></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>createCombiner:</strong> combineByKey() 会遍历分区中的所有元素，因此每个元素的键要么还没有遇到过，要么就和之前的某个元素的键相同。如果这是一个新的元素， combineByKey() 会使用一个叫做createCombiner() 的函数来创建那个键对应的累加器的初始值</li>
<li><strong>mergeValue:</strong> 如果这是一个在处理当前分区之前已经遇到的键，它会使用 mergeValue() 方法将该键的累加器对应的当前值与这个新的值进行合并</li>
<li><strong>mergeCombiners:</strong> 由于每个分区都是独立处理的， 因此对于同一个键可以有多个累加器。如果有两个或者更多的分区都有对应同一个键的累加器， 就需要使用用户提供的 mergeCombiners() 方法将各个分区的结果进行合并。</li>
</ul>
<h3 id="计算学生平均成绩例子"><a href="#计算学生平均成绩例子" class="headerlink" title="计算学生平均成绩例子"></a>计算学生平均成绩例子</h3><p>这里举一个计算学生平均成绩的例子,例子参考至<a href="https://www.edureka.co/blog/apache-spark-combinebykey-explained" target="_blank" rel="noopener">https://www.edureka.co/blog/apache-spark-combinebykey-explained</a>, <a href="https://github.com/prithvirajbose/spark-dev/blob/master/src/main/scala/examples/TestCombineByKey.scala" target="_blank" rel="noopener">github源码</a> 我对此进行了解析<br><strong>创建一个学生成绩说明的类</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">ScoreDetail</span>(<span class="params">studentName: <span class="type">String</span>, subject: <span class="type">String</span>, score: <span class="type">Float</span></span>)</span></span><br></pre></td></tr></table></figure></p>
<p>下面是一些测试数据，加载测试数据集合 key = Students name and value = ScoreDetail instance<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> scores = <span class="type">List</span>(</span><br><span class="line">  <span class="type">ScoreDetail</span>(<span class="string">"xiaoming"</span>, <span class="string">"Math"</span>, <span class="number">98</span>),</span><br><span class="line">  <span class="type">ScoreDetail</span>(<span class="string">"xiaoming"</span>, <span class="string">"English"</span>, <span class="number">88</span>),</span><br><span class="line">  <span class="type">ScoreDetail</span>(<span class="string">"wangwu"</span>, <span class="string">"Math"</span>, <span class="number">75</span>),</span><br><span class="line">  <span class="type">ScoreDetail</span>(<span class="string">"wangwu"</span>, <span class="string">"English"</span>, <span class="number">78</span>),</span><br><span class="line">  <span class="type">ScoreDetail</span>(<span class="string">"lihua"</span>, <span class="string">"Math"</span>, <span class="number">90</span>),</span><br><span class="line">  <span class="type">ScoreDetail</span>(<span class="string">"lihua"</span>, <span class="string">"English"</span>, <span class="number">80</span>),</span><br><span class="line">  <span class="type">ScoreDetail</span>(<span class="string">"zhangsan"</span>, <span class="string">"Math"</span>, <span class="number">91</span>),</span><br><span class="line">  <span class="type">ScoreDetail</span>(<span class="string">"zhangsan"</span>, <span class="string">"English"</span>, <span class="number">80</span>))</span><br></pre></td></tr></table></figure></p>
<p>将集合转换成二元组， 也可以理解成转换成一个map, 利用了for 和 yield的组合<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> scoresWithKey = <span class="keyword">for</span> &#123; i &lt;- scores &#125; <span class="keyword">yield</span> (i.studentName, i)</span><br></pre></td></tr></table></figure></p>
<p>创建RDD, 并且指定三个分区<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> scoresWithKeyRDD = sc.parallelize(scoresWithKey).partitionBy(<span class="keyword">new</span> <span class="type">HashPartitioner</span>(<span class="number">3</span>)).cache</span><br></pre></td></tr></table></figure></p>
<p>输出打印一下各个分区的长度和各个分区的一些数据<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">    println(<span class="string">"&gt;&gt;&gt;&gt; Elements in each partition"</span>)</span><br><span class="line"></span><br><span class="line">    scoresWithKeyRDD.foreachPartition(partition =&gt; println(partition.length))</span><br><span class="line"></span><br><span class="line">    <span class="comment">// explore each partition...</span></span><br><span class="line">    println(<span class="string">"&gt;&gt;&gt;&gt; Exploring partitions' data..."</span>)</span><br><span class="line"></span><br><span class="line">    scoresWithKeyRDD.foreachPartition(</span><br><span class="line">      partition =&gt; partition.foreach(</span><br><span class="line">        item =&gt; println(item._2)))</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">会输出 </span></span><br><span class="line"><span class="comment">&gt;&gt;&gt;&gt; Elements in each partition</span></span><br><span class="line"><span class="comment">6</span></span><br><span class="line"><span class="comment">2</span></span><br><span class="line"><span class="comment">0</span></span><br><span class="line"><span class="comment">&gt;&gt;&gt;&gt; Exploring partitions' data...</span></span><br><span class="line"><span class="comment">ScoreDetail(xiaoming,Math,98.0)</span></span><br><span class="line"><span class="comment">ScoreDetail(xiaoming,English,88.0)</span></span><br><span class="line"><span class="comment">ScoreDetail(lihua,Math,90.0)</span></span><br><span class="line"><span class="comment">ScoreDetail(lihua,English,80.0)</span></span><br><span class="line"><span class="comment">ScoreDetail(zhangsan,Math,91.0)</span></span><br><span class="line"><span class="comment">ScoreDetail(zhangsan,English,80.0)</span></span><br><span class="line"><span class="comment">ScoreDetail(wangwu,Math,75.0)</span></span><br><span class="line"><span class="comment">ScoreDetail(wangwu,English,78.0)</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure></p>
<p>聚合求平均值让后打印<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">      <span class="keyword">val</span> avgScoresRDD = scoresWithKeyRDD.combineByKey(</span><br><span class="line">      (x: <span class="type">ScoreDetail</span>) =&gt; (x.score, <span class="number">1</span>) <span class="comment">/*createCombiner*/</span>,</span><br><span class="line">      (acc: (<span class="type">Float</span>, <span class="type">Int</span>), x: <span class="type">ScoreDetail</span>) =&gt; (acc._1 + x.score, acc._2 + <span class="number">1</span>) <span class="comment">/*mergeValue*/</span>,</span><br><span class="line">      (acc1: (<span class="type">Float</span>, <span class="type">Int</span>), acc2: (<span class="type">Float</span>, <span class="type">Int</span>)) =&gt; (acc1._1 + acc2._1, acc1._2 + acc2._2) <span class="comment">/*mergeCombiners*/</span></span><br><span class="line">      <span class="comment">// calculate the average</span></span><br><span class="line">    ).map( &#123; <span class="keyword">case</span>(key, value) =&gt; (key, value._1/value._2) &#125;)</span><br><span class="line"></span><br><span class="line">    avgScoresRDD.collect.foreach(println)</span><br><span class="line"><span class="comment">/*输出:</span></span><br><span class="line"><span class="comment">(zhangsan,85.5)</span></span><br><span class="line"><span class="comment">(lihua,85.0)</span></span><br><span class="line"><span class="comment">(xiaoming,93.0)</span></span><br><span class="line"><span class="comment">(wangwu,76.5)</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure></p>
<p><strong>解释一下scoresWithKeyRDD.combineByKey</strong><br><strong>createCombiner:</strong> (x: ScoreDetail) =&gt; (x.score, 1)<br>这是第一次遇到zhangsan，创建一个函数，把map中的value转成另外一个类型 ，这里是把(zhangsan,(ScoreDetail类))转换成(zhangsan,(91,1))<br><strong>mergeValue:</strong> (acc: (Float, Int), x: ScoreDetail) =&gt; (acc._1 + x.score, acc._2 + 1) 再次碰到张三， 就把这两个合并, 这里是将(zhangsan,(91,1)) 这种类型 和 (zhangsan,(ScoreDetail类))这种类型合并，合并成了(zhangsan,(171,2))<br><strong>mergeCombiners:</strong> (acc1: (Float, Int), acc2: (Float, Int)) 这个是将多个分区中的zhangsan的数据进行合并， 我们这里zhansan在同一个分区，这个地方就没有用上</p>
<h3 id="java版本的介绍"><a href="#java版本的介绍" class="headerlink" title="java版本的介绍"></a>java版本的介绍</h3><p><strong>ScoreDetail类</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ScoreDetail</span> <span class="keyword">implements</span> <span class="title">Serializable</span></span>&#123;</span><br><span class="line">    <span class="comment">//case class ScoreDetail(studentName: String, subject: String, score: Float)</span></span><br><span class="line">    <span class="keyword">public</span> String studentName;</span><br><span class="line">    <span class="keyword">public</span> String subject;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">float</span> score;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">ScoreDetail</span><span class="params">(String studentName, String subject, <span class="keyword">float</span> score)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.studentName = studentName;</span><br><span class="line">        <span class="keyword">this</span>.subject = subject;</span><br><span class="line">        <span class="keyword">this</span>.score = score;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>CombineByKey的测试类<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CombineTest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        SparkConf sparkConf = <span class="keyword">new</span> SparkConf().setAppName(<span class="string">"JavaWordCount"</span>).setMaster(<span class="string">"local"</span>);</span><br><span class="line">        JavaSparkContext sc = <span class="keyword">new</span> JavaSparkContext(sparkConf);</span><br><span class="line">        ArrayList&lt;ScoreDetail&gt; scoreDetails = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        scoreDetails.add(<span class="keyword">new</span> ScoreDetail(<span class="string">"xiaoming"</span>, <span class="string">"Math"</span>, <span class="number">98</span>));</span><br><span class="line">        scoreDetails.add(<span class="keyword">new</span> ScoreDetail(<span class="string">"xiaoming"</span>, <span class="string">"English"</span>, <span class="number">88</span>));</span><br><span class="line">        scoreDetails.add(<span class="keyword">new</span> ScoreDetail(<span class="string">"wangwu"</span>, <span class="string">"Math"</span>, <span class="number">75</span>));</span><br><span class="line">        scoreDetails.add(<span class="keyword">new</span> ScoreDetail(<span class="string">"wangwu"</span>, <span class="string">"Englist"</span>, <span class="number">78</span>));</span><br><span class="line">        scoreDetails.add(<span class="keyword">new</span> ScoreDetail(<span class="string">"lihua"</span>, <span class="string">"Math"</span>, <span class="number">90</span>));</span><br><span class="line">        scoreDetails.add(<span class="keyword">new</span> ScoreDetail(<span class="string">"lihua"</span>, <span class="string">"English"</span>, <span class="number">80</span>));</span><br><span class="line">        scoreDetails.add(<span class="keyword">new</span> ScoreDetail(<span class="string">"zhangsan"</span>, <span class="string">"Math"</span>, <span class="number">91</span>));</span><br><span class="line">        scoreDetails.add(<span class="keyword">new</span> ScoreDetail(<span class="string">"zhangsan"</span>, <span class="string">"English"</span>, <span class="number">80</span>));</span><br><span class="line"></span><br><span class="line">        JavaRDD&lt;ScoreDetail&gt; scoreDetailsRDD = sc.parallelize(scoreDetails);</span><br><span class="line"></span><br><span class="line">        JavaPairRDD&lt;String, ScoreDetail&gt; pairRDD = scoreDetailsRDD.mapToPair(<span class="keyword">new</span> PairFunction&lt;ScoreDetail, String, ScoreDetail&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> Tuple2&lt;String, ScoreDetail&gt; <span class="title">call</span><span class="params">(ScoreDetail scoreDetail)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">new</span> Tuple2&lt;&gt;(scoreDetail.studentName, scoreDetail);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"><span class="comment">//        new Function&lt;ScoreDetail, Float,Integer&gt;();</span></span><br><span class="line"></span><br><span class="line">        Function&lt;ScoreDetail, Tuple2&lt;Float, Integer&gt;&gt; createCombine = <span class="keyword">new</span> Function&lt;ScoreDetail, Tuple2&lt;Float, Integer&gt;&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> Tuple2&lt;Float, Integer&gt; <span class="title">call</span><span class="params">(ScoreDetail scoreDetail)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">new</span> Tuple2&lt;&gt;(scoreDetail.score, <span class="number">1</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Function2传入两个值，返回一个值</span></span><br><span class="line">        Function2&lt;Tuple2&lt;Float, Integer&gt;, ScoreDetail, Tuple2&lt;Float, Integer&gt;&gt; mergeValue = <span class="keyword">new</span> Function2&lt;Tuple2&lt;Float, Integer&gt;, ScoreDetail, Tuple2&lt;Float, Integer&gt;&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> Tuple2&lt;Float, Integer&gt; <span class="title">call</span><span class="params">(Tuple2&lt;Float, Integer&gt; tp, ScoreDetail scoreDetail)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">new</span> Tuple2&lt;&gt;(tp._1 + scoreDetail.score, tp._2 + <span class="number">1</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line">        Function2&lt;Tuple2&lt;Float, Integer&gt;, Tuple2&lt;Float, Integer&gt;, Tuple2&lt;Float, Integer&gt;&gt; mergeCombiners = <span class="keyword">new</span> Function2&lt;Tuple2&lt;Float, Integer&gt;, Tuple2&lt;Float, Integer&gt;, Tuple2&lt;Float, Integer&gt;&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> Tuple2&lt;Float, Integer&gt; <span class="title">call</span><span class="params">(Tuple2&lt;Float, Integer&gt; tp1, Tuple2&lt;Float, Integer&gt; tp2)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">new</span> Tuple2&lt;&gt;(tp1._1 + tp2._1, tp1._2 + tp2._2);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line">        JavaPairRDD&lt;String, Tuple2&lt;Float,Integer&gt;&gt; combineByRDD  = pairRDD.combineByKey(createCombine,mergeValue,mergeCombiners);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//打印平均数</span></span><br><span class="line">        Map&lt;String, Tuple2&lt;Float, Integer&gt;&gt; stringTuple2Map = combineByRDD.collectAsMap();</span><br><span class="line">        <span class="keyword">for</span> ( String et:stringTuple2Map.keySet()) &#123;</span><br><span class="line">            System.out.println(et+<span class="string">" "</span>+stringTuple2Map.get(et)._1/stringTuple2Map.get(et)._2);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><strong>注意有个坑的地方</strong> createCombine方法必须是这样的<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Function&lt;ScoreDetail, Tuple2&lt;Float, Integer&gt;&gt; createCombine = <span class="keyword">new</span> Function&lt;ScoreDetail, Tuple2&lt;Float, Integer&gt;&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Tuple2&lt;Float, Integer&gt; <span class="title">call</span><span class="params">(ScoreDetail scoreDetail)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> Tuple2&lt;&gt;(scoreDetail.score, <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p>
<p>而不能是这样的, 即使最后的RDD都类似<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">PairFunction&lt;ScoreDetail, Float, Integer&gt; createCombine = <span class="keyword">new</span> PairFunction&lt;ScoreDetail, Float, Integer&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Tuple2&lt;Float, Integer&gt; <span class="title">call</span><span class="params">(ScoreDetail scoreDetail)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> Tuple2&lt;&gt;(scoreDetail.score, <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p>
<p>再推荐比较好的文章 <a href="http://lxw1234.com/archives/2015/07/358.htm" target="_blank" rel="noopener">LXW的大数据田地: combineByKey</a></p>
<hr>
<h1 id="键值对聚合操作reduceByKey，foldByKey，排序操作sortByKey"><a href="#键值对聚合操作reduceByKey，foldByKey，排序操作sortByKey" class="headerlink" title="键值对聚合操作reduceByKey，foldByKey，排序操作sortByKey"></a>键值对聚合操作reduceByKey，foldByKey，排序操作sortByKey</h1><h2 id="reduceByKey"><a href="#reduceByKey" class="headerlink" title="reduceByKey"></a>reduceByKey</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reduceByKey</span></span>(func: (<span class="type">V</span>, <span class="type">V</span>) =&gt; <span class="type">V</span>): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">V</span>)]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reduceByKey</span></span>(func: (<span class="type">V</span>, <span class="type">V</span>) =&gt; <span class="type">V</span>, numPartitions: <span class="type">Int</span>): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">V</span>)]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reduceByKey</span></span>(partitioner: <span class="type">Partitioner</span>, func: (<span class="type">V</span>, <span class="type">V</span>) =&gt; <span class="type">V</span>): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">V</span>)]</span><br></pre></td></tr></table></figure>
<p>接收一个函数，按照相同的key进行reduce操作，类似于scala的reduce的操作<br>例如RDD {(1, 2), (3, 4), (3, 6)}进行reduce<br><strong>scala版本</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">    <span class="keyword">var</span> mapRDD = sc.parallelize(<span class="type">List</span>((<span class="number">1</span>,<span class="number">2</span>),(<span class="number">3</span>,<span class="number">4</span>),(<span class="number">3</span>,<span class="number">6</span>)))</span><br><span class="line">    <span class="keyword">var</span> reduceRDD = mapRDD.reduceByKey((x,y)=&gt;x+y)</span><br><span class="line">    reduceRDD.foreach(x=&gt;println(x))</span><br><span class="line">------输出---------</span><br><span class="line">(<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">(<span class="number">3</span>,<span class="number">10</span>)</span><br></pre></td></tr></table></figure></p>
<p>再举例<br>单词计数<br>F:\sparktest\sample.txt中的内容如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">aa bb cc aa aa aa dd dd ee ee ee ee </span><br><span class="line">ff aa bb zks</span><br><span class="line">ee kks</span><br><span class="line">ee  zz zks</span><br></pre></td></tr></table></figure></p>
<p><strong>scala版本</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">    <span class="keyword">val</span> lines = sc.textFile(<span class="string">"F:\\sparktest\\sample.txt"</span>)</span><br><span class="line">    <span class="keyword">val</span> wordsRDD = lines.flatMap(x=&gt;x.split(<span class="string">"\\s+"</span>)).map(x=&gt;(x,<span class="number">1</span>))</span><br><span class="line">    <span class="keyword">val</span> wordCountRDD = wordsRDD.reduceByKey((x,y)=&gt;x+y)</span><br><span class="line">    wordCountRDD.foreach(x=&gt;println(x))</span><br><span class="line">---------输出-----------</span><br><span class="line">(ee,<span class="number">6</span>)</span><br><span class="line">(aa,<span class="number">5</span>)</span><br><span class="line">(dd,<span class="number">2</span>)</span><br><span class="line">(zz,<span class="number">1</span>)</span><br><span class="line">(zks,<span class="number">2</span>)</span><br><span class="line">(kks,<span class="number">1</span>)</span><br><span class="line">(ff,<span class="number">1</span>)</span><br><span class="line">(bb,<span class="number">2</span>)</span><br><span class="line">(cc,<span class="number">1</span>)</span><br></pre></td></tr></table></figure></p>
<p><strong>java版本</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"> JavaRDD&lt;String&gt; lines = sc.textFile(<span class="string">"F:\\sparktest\\sample.txt"</span>);</span><br><span class="line"></span><br><span class="line">        JavaPairRDD&lt;String, Integer&gt; wordPairRDD = lines.flatMapToPair(<span class="keyword">new</span> PairFlatMapFunction&lt;String, String, Integer&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> Iterable&lt;Tuple2&lt;String, Integer&gt;&gt; call(String s) <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                ArrayList&lt;Tuple2&lt;String, Integer&gt;&gt; tpLists = <span class="keyword">new</span> ArrayList&lt;Tuple2&lt;String, Integer&gt;&gt;();</span><br><span class="line">                String[] split = s.split(<span class="string">"\\s+"</span>);</span><br><span class="line">                <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt;split.length ; i++) &#123;</span><br><span class="line">                    Tuple2 tp = <span class="keyword">new</span> Tuple2&lt;String,Integer&gt;(split[i], <span class="number">1</span>);</span><br><span class="line">                    tpLists.add(tp);</span><br><span class="line">                &#125;</span><br><span class="line">            <span class="keyword">return</span> tpLists;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        JavaPairRDD&lt;String, Integer&gt; wordCountRDD = wordPairRDD.reduceByKey(<span class="keyword">new</span> Function2&lt;Integer, Integer, Integer&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> Integer <span class="title">call</span><span class="params">(Integer i1, Integer i2)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> i1 + i2;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        Map&lt;String, Integer&gt; collectAsMap = wordCountRDD.collectAsMap();</span><br><span class="line">        <span class="keyword">for</span> (String key:collectAsMap.keySet()) &#123;</span><br><span class="line">            System.out.println(<span class="string">"("</span>+key+<span class="string">","</span>+collectAsMap.get(key)+<span class="string">")"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">----------输出-------------------------------</span><br><span class="line">(kks,<span class="number">1</span>)</span><br><span class="line">(ee,<span class="number">6</span>)</span><br><span class="line">(bb,<span class="number">2</span>)</span><br><span class="line">(zz,<span class="number">1</span>)</span><br><span class="line">(ff,<span class="number">1</span>)</span><br><span class="line">(cc,<span class="number">1</span>)</span><br><span class="line">(zks,<span class="number">2</span>)</span><br><span class="line">(dd,<span class="number">2</span>)</span><br><span class="line">(aa,<span class="number">5</span>)</span><br></pre></td></tr></table></figure></p>
<h2 id="foldByKey"><a href="#foldByKey" class="headerlink" title="foldByKey"></a>foldByKey</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">foldByKey</span></span>(zeroValue: <span class="type">V</span>)(func: (<span class="type">V</span>, <span class="type">V</span>) =&gt; <span class="type">V</span>): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">V</span>)]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">foldByKey</span></span>(zeroValue: <span class="type">V</span>, numPartitions: <span class="type">Int</span>)(func: (<span class="type">V</span>, <span class="type">V</span>) =&gt; <span class="type">V</span>): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">V</span>)]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">foldByKey</span></span>(zeroValue: <span class="type">V</span>, partitioner: <span class="type">Partitioner</span>)(func: (<span class="type">V</span>, <span class="type">V</span>) =&gt; <span class="type">V</span>): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">V</span>)]</span><br></pre></td></tr></table></figure>
<p>该函数用于RDD[K,V]根据K将V做折叠、合并处理，其中的参数zeroValue表示先根据映射函数将zeroValue应用于V,进行初始化V,再将映射函数应用于初始化后的V.<br>foldByKey可以参考我之前的<a href="http://blog.csdn.net/t1dmzks/article/details/69858060#t27" target="_blank" rel="noopener">scala的fold的介绍</a><br>与reduce不同的是 foldByKey开始折叠的第一个元素不是集合中的第一个元素，而是传入的一个元素<br><a href="http://lxw1234.com/archives/2015/07/358.htm" target="_blank" rel="noopener">参考LXW的博客 scala的例子</a><br><strong>直接看例子</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">var</span> rdd1 = sc.makeRDD(<span class="type">Array</span>((<span class="string">"A"</span>,<span class="number">0</span>),(<span class="string">"A"</span>,<span class="number">2</span>),(<span class="string">"B"</span>,<span class="number">1</span>),(<span class="string">"B"</span>,<span class="number">2</span>),(<span class="string">"C"</span>,<span class="number">1</span>)))</span><br><span class="line">scala&gt; rdd1.foldByKey(<span class="number">0</span>)(_+_).collect</span><br><span class="line">res75: <span class="type">Array</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">Array</span>((<span class="type">A</span>,<span class="number">2</span>), (<span class="type">B</span>,<span class="number">3</span>), (<span class="type">C</span>,<span class="number">1</span>)) </span><br><span class="line"><span class="comment">//将rdd1中每个key对应的V进行累加，注意zeroValue=0,需要先初始化V,映射函数为+操</span></span><br><span class="line"><span class="comment">//作，比如("A",0), ("A",2)，先将zeroValue应用于每个V,得到：("A",0+0), ("A",2+0)，即：</span></span><br><span class="line"><span class="comment">//("A",0), ("A",2)，再将映射函数应用于初始化后的V，最后得到(A,0+2),即(A,2)</span></span><br></pre></td></tr></table></figure></p>
<p><strong>再看：</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; rdd1.foldByKey(<span class="number">2</span>)(_+_).collect</span><br><span class="line">res76: <span class="type">Array</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">Array</span>((<span class="type">A</span>,<span class="number">6</span>), (<span class="type">B</span>,<span class="number">7</span>), (<span class="type">C</span>,<span class="number">3</span>))</span><br><span class="line"><span class="comment">//先将zeroValue=2应用于每个V,得到：("A",0+2), ("A",2+2)，即：("A",2), ("A",4)，再将映射函</span></span><br><span class="line"><span class="comment">//数应用于初始化后的V，最后得到：(A,2+4)，即：(A,6)</span></span><br></pre></td></tr></table></figure></p>
<p><strong>再看乘法操作：</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; rdd1.foldByKey(<span class="number">0</span>)(_*_).collect</span><br><span class="line">res77: <span class="type">Array</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">Array</span>((<span class="type">A</span>,<span class="number">0</span>), (<span class="type">B</span>,<span class="number">0</span>), (<span class="type">C</span>,<span class="number">0</span>))</span><br><span class="line"><span class="comment">//先将zeroValue=0应用于每个V,注意，这次映射函数为乘法，得到：("A",0*0), ("A",2*0)，</span></span><br><span class="line"><span class="comment">//即：("A",0), ("A",0)，再将映射函//数应用于初始化后的V，最后得到：(A,0*0)，即：(A,0)</span></span><br><span class="line"><span class="comment">//其他K也一样，最终都得到了V=0</span></span><br><span class="line"></span><br><span class="line">scala&gt; rdd1.foldByKey(<span class="number">1</span>)(_*_).collect</span><br><span class="line">res78: <span class="type">Array</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">Array</span>((<span class="type">A</span>,<span class="number">0</span>), (<span class="type">B</span>,<span class="number">2</span>), (<span class="type">C</span>,<span class="number">1</span>))</span><br><span class="line"><span class="comment">//映射函数为乘法时，需要将zeroValue设为1，才能得到我们想要的结果。</span></span><br></pre></td></tr></table></figure></p>
<h2 id="SortByKey"><a href="#SortByKey" class="headerlink" title="SortByKey"></a>SortByKey</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sortByKey</span></span>(ascending : scala.<span class="type">Boolean</span> = &#123; <span class="comment">/* compiled code */</span> &#125;, numPartitions : scala.<span class="type">Int</span> = &#123; <span class="comment">/* compiled code */</span> &#125;) : org.apache.spark.rdd.<span class="type">RDD</span>[scala.<span class="type">Tuple2</span>[<span class="type">K</span>, <span class="type">V</span>]] = &#123; <span class="comment">/* compiled code */</span> &#125;</span><br></pre></td></tr></table></figure>
<p>SortByKey用于对pairRDD按照key进行排序，第一个参数可以设置true或者false，默认是true<br><strong>scala例子</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> rdd = sc.parallelize(<span class="type">Array</span>((<span class="number">3</span>, <span class="number">4</span>),(<span class="number">1</span>, <span class="number">2</span>),(<span class="number">4</span>,<span class="number">4</span>),(<span class="number">2</span>,<span class="number">5</span>), (<span class="number">6</span>,<span class="number">5</span>), (<span class="number">5</span>, <span class="number">6</span>)))  </span><br><span class="line"></span><br><span class="line"><span class="comment">// sortByKey不是Action操作，只能算是转换操作</span></span><br><span class="line">scala&gt; rdd.sortByKey()</span><br><span class="line">res9: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">Int</span>, <span class="type">Int</span>)] = <span class="type">ShuffledRDD</span>[<span class="number">28</span>] at sortByKey at &lt;console&gt;:<span class="number">24</span> </span><br><span class="line"></span><br><span class="line"><span class="comment">//看看sortByKey后是什么类型</span></span><br><span class="line">scala&gt; rdd.sortByKey().collect() </span><br><span class="line">res10: <span class="type">Array</span>[(<span class="type">Int</span>, <span class="type">Int</span>)] = <span class="type">Array</span>((<span class="number">1</span>,<span class="number">2</span>), (<span class="number">2</span>,<span class="number">5</span>), (<span class="number">3</span>,<span class="number">4</span>), (<span class="number">4</span>,<span class="number">4</span>), (<span class="number">5</span>,<span class="number">6</span>), (<span class="number">6</span>,<span class="number">5</span>)) </span><br><span class="line"></span><br><span class="line"><span class="comment">//降序排序</span></span><br><span class="line">scala&gt; rdd.sortByKey(<span class="literal">false</span>).collect() </span><br><span class="line">res12: <span class="type">Array</span>[(<span class="type">Int</span>, <span class="type">Int</span>)] = <span class="type">Array</span>((<span class="number">6</span>,<span class="number">5</span>), (<span class="number">5</span>,<span class="number">6</span>), (<span class="number">4</span>,<span class="number">4</span>), (<span class="number">3</span>,<span class="number">4</span>), (<span class="number">2</span>,<span class="number">5</span>), (<span class="number">1</span>,<span class="number">2</span>))</span><br></pre></td></tr></table></figure></p>
<p>java例子也是一样的，这里就不写了</p>
<hr>
<h1 id="键值对分组操作-groupByKey，cogroup"><a href="#键值对分组操作-groupByKey，cogroup" class="headerlink" title="键值对分组操作 groupByKey，cogroup"></a>键值对分组操作 groupByKey，cogroup</h1><h2 id="groupByKey"><a href="#groupByKey" class="headerlink" title="groupByKey"></a>groupByKey</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">groupByKey</span></span>(): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">Iterable</span>[<span class="type">V</span>])]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">groupByKey</span></span>(numPartitions: <span class="type">Int</span>): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">Iterable</span>[<span class="type">V</span>])]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">groupByKey</span></span>(partitioner: <span class="type">Partitioner</span>): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">Iterable</span>[<span class="type">V</span>])]</span><br></pre></td></tr></table></figure>
<p>groupByKey会将RDD[key,value] 按照相同的key进行分组，形成RDD[key,Iterable[value]]的形式， 有点类似于sql中的groupby，例如类似于mysql中的group_concat<br>例如这个例子， 我们对学生的成绩进行分组<br><strong>scala版本</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> scoreDetail = sc.parallelize(<span class="type">List</span>((<span class="string">"xiaoming"</span>,<span class="number">75</span>),(<span class="string">"xiaoming"</span>,<span class="number">90</span>),(<span class="string">"lihua"</span>,<span class="number">95</span>),(<span class="string">"lihua"</span>,<span class="number">100</span>),(<span class="string">"xiaofeng"</span>,<span class="number">85</span>)))</span><br><span class="line">scoreDetail.groupByKey().collect().foreach(println(_));</span><br><span class="line"><span class="comment">/*输出</span></span><br><span class="line"><span class="comment">(lihua,CompactBuffer(95, 100))</span></span><br><span class="line"><span class="comment">(xiaoming,CompactBuffer(75, 90))</span></span><br><span class="line"><span class="comment">(xiaofeng,CompactBuffer(85))</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure></p>
<p><strong>java版本</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;Tuple2&lt;String,Float&gt;&gt; scoreDetails = sc.parallelize(Arrays.asList(<span class="keyword">new</span> Tuple2(<span class="string">"xiaoming"</span>, <span class="number">75</span>)</span><br><span class="line">        , <span class="keyword">new</span> Tuple2(<span class="string">"xiaoming"</span>, <span class="number">90</span>)</span><br><span class="line">        , <span class="keyword">new</span> Tuple2(<span class="string">"lihua"</span>, <span class="number">95</span>)</span><br><span class="line">        , <span class="keyword">new</span> Tuple2(<span class="string">"lihua"</span>, <span class="number">188</span>)));</span><br><span class="line"><span class="comment">//将JavaRDD&lt;Tuple2&lt;String,Float&gt;&gt; 类型转换为 JavaPairRDD&lt;String, Float&gt;</span></span><br><span class="line">JavaPairRDD&lt;String, Float&gt; scoreMapRDD = JavaPairRDD.fromJavaRDD(scoreDetails);</span><br><span class="line">Map&lt;String, Iterable&lt;Float&gt;&gt; resultMap = scoreMapRDD.groupByKey().collectAsMap();</span><br><span class="line"><span class="keyword">for</span> (String key:resultMap.keySet()) &#123;</span><br><span class="line">    System.out.println(<span class="string">"("</span>+key+<span class="string">", "</span>+resultMap.get(key)+<span class="string">")"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="cogroup"><a href="#cogroup" class="headerlink" title="cogroup"></a>cogroup</h2><p>groupByKey是对单个 RDD 的数据进行分组，还可以使用一个叫作 cogroup() 的函数对多个共享同一个键的 RDD 进行分组<br>例如<br>RDD1.cogroup(RDD2) 会将RDD1和RDD2按照相同的key进行分组，得到(key,RDD[key,Iterable[value1],Iterable[value2]])的形式<br>cogroup也可以多个进行分组<br>例如RDD1.cogroup(RDD2,RDD3,…RDDN), 可以得到(key,Iterable[value1],Iterable[value2],Iterable[value3],…,Iterable[valueN])<br>案例,scoreDetail存放的是学生的优秀学科的分数，scoreDetai2存放的是刚刚及格的分数，scoreDetai3存放的是没有及格的科目的分数，我们要对每一个学生的优秀学科，刚及格和不及格的分数给分组统计出来<br><strong>scala版本</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> scoreDetail = sc.parallelize(<span class="type">List</span>((<span class="string">"xiaoming"</span>,<span class="number">95</span>),(<span class="string">"xiaoming"</span>,<span class="number">90</span>),(<span class="string">"lihua"</span>,<span class="number">95</span>),(<span class="string">"lihua"</span>,<span class="number">98</span>),(<span class="string">"xiaofeng"</span>,<span class="number">97</span>)))</span><br><span class="line">scala&gt; <span class="keyword">val</span> scoreDetai2 = sc.parallelize(<span class="type">List</span>((<span class="string">"xiaoming"</span>,<span class="number">65</span>),(<span class="string">"lihua"</span>,<span class="number">63</span>),(<span class="string">"lihua"</span>,<span class="number">62</span>),(<span class="string">"xiaofeng"</span>,<span class="number">67</span>)))</span><br><span class="line">scala&gt; <span class="keyword">val</span> scoreDetai3 = sc.parallelize(<span class="type">List</span>((<span class="string">"xiaoming"</span>,<span class="number">25</span>),(<span class="string">"xiaoming"</span>,<span class="number">15</span>),(<span class="string">"lihua"</span>,<span class="number">35</span>),(<span class="string">"lihua"</span>,<span class="number">28</span>),(<span class="string">"xiaofeng"</span>,<span class="number">36</span>)))</span><br><span class="line">scala&gt; scoreDetail.cogroup(scoreDetai2,scoreDetai3)</span><br><span class="line"></span><br><span class="line"><span class="comment">//输出</span></span><br><span class="line">res1: <span class="type">Array</span>[(<span class="type">String</span>, (<span class="type">Iterable</span>[<span class="type">Int</span>], <span class="type">Iterable</span>[<span class="type">Int</span>], <span class="type">Iterable</span>[<span class="type">Int</span>]))] = <span class="type">Array</span>((xiaoming,(<span class="type">CompactBuffer</span>(<span class="number">95</span>, <span class="number">90</span>),<span class="type">CompactBuffer</span>(<span class="number">65</span>),<span class="type">CompactBuffer</span>(<span class="number">25</span>, <span class="number">15</span>))), (lihua,(<span class="type">CompactBuffer</span>(<span class="number">95</span>, <span class="number">98</span>),<span class="type">CompactBuffer</span>(<span class="number">63</span>, <span class="number">62</span>),<span class="type">CompactBuffer</span>(<span class="number">35</span>, <span class="number">28</span>))), (xiaofeng,(<span class="type">CompactBuffer</span>(<span class="number">97</span>),<span class="type">CompactBuffer</span>(<span class="number">67</span>),<span class="type">CompactBuffer</span>(<span class="number">36</span>))))</span><br></pre></td></tr></table></figure></p>
<p><strong>java版本</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">        JavaRDD&lt;Tuple2&lt;String,Float&gt;&gt; scoreDetails1 = sc.parallelize(Arrays.asList(<span class="keyword">new</span> Tuple2(<span class="string">"xiaoming"</span>, <span class="number">75</span>)</span><br><span class="line">                , <span class="keyword">new</span> Tuple2(<span class="string">"xiaoming"</span>, <span class="number">90</span>)</span><br><span class="line">                , <span class="keyword">new</span> Tuple2(<span class="string">"lihua"</span>, <span class="number">95</span>)</span><br><span class="line">                , <span class="keyword">new</span> Tuple2(<span class="string">"lihua"</span>, <span class="number">96</span>)));</span><br><span class="line">        JavaRDD&lt;Tuple2&lt;String,Float&gt;&gt; scoreDetails2 = sc.parallelize(Arrays.asList(<span class="keyword">new</span> Tuple2(<span class="string">"xiaoming"</span>, <span class="number">75</span>)</span><br><span class="line">                , <span class="keyword">new</span> Tuple2(<span class="string">"lihua"</span>, <span class="number">60</span>)</span><br><span class="line">                , <span class="keyword">new</span> Tuple2(<span class="string">"lihua"</span>, <span class="number">62</span>)));</span><br><span class="line">        JavaRDD&lt;Tuple2&lt;String,Float&gt;&gt; scoreDetails3 = sc.parallelize(Arrays.asList(<span class="keyword">new</span> Tuple2(<span class="string">"xiaoming"</span>, <span class="number">75</span>)</span><br><span class="line">                , <span class="keyword">new</span> Tuple2(<span class="string">"xiaoming"</span>, <span class="number">45</span>)</span><br><span class="line">                , <span class="keyword">new</span> Tuple2(<span class="string">"lihua"</span>, <span class="number">24</span>)</span><br><span class="line">                , <span class="keyword">new</span> Tuple2(<span class="string">"lihua"</span>, <span class="number">57</span>)));</span><br><span class="line"></span><br><span class="line">        JavaPairRDD&lt;String, Float&gt; scoreMapRDD1 = JavaPairRDD.fromJavaRDD(scoreDetails1);</span><br><span class="line">        JavaPairRDD&lt;String, Float&gt; scoreMapRDD2 = JavaPairRDD.fromJavaRDD(scoreDetails2);</span><br><span class="line">        JavaPairRDD&lt;String, Float&gt; scoreMapRDD3 = JavaPairRDD.fromJavaRDD(scoreDetails2);</span><br><span class="line"></span><br><span class="line">        JavaPairRDD&lt;String, Tuple3&lt;Iterable&lt;Float&gt;, Iterable&lt;Float&gt;, Iterable&lt;Float&gt;&gt;&gt; cogroupRDD = (JavaPairRDD&lt;String, Tuple3&lt;Iterable&lt;Float&gt;, Iterable&lt;Float&gt;, Iterable&lt;Float&gt;&gt;&gt;) scoreMapRDD1.cogroup(scoreMapRDD2, scoreMapRDD3);</span><br><span class="line">        Map&lt;String, Tuple3&lt;Iterable&lt;Float&gt;, Iterable&lt;Float&gt;, Iterable&lt;Float&gt;&gt;&gt; tuple3 = cogroupRDD.collectAsMap();</span><br><span class="line">        <span class="keyword">for</span> (String key:tuple3.keySet()) &#123;</span><br><span class="line">            System.out.println(<span class="string">"("</span>+key+<span class="string">", "</span>+tuple3.get(key)+<span class="string">")"</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">-----输出----------</span><br><span class="line">(lihua, ([<span class="number">95</span>, <span class="number">96</span>],[<span class="number">60</span>, <span class="number">62</span>],[<span class="number">60</span>, <span class="number">62</span>]))</span><br><span class="line">(xiaoming, ([<span class="number">75</span>, <span class="number">90</span>],[<span class="number">75</span>],[<span class="number">75</span>]))</span><br></pre></td></tr></table></figure></p>
<hr>
<h1 id="键值对关联操作-subtractByKey-join-fullOuterJoin-rightOuterJoin-leftOuterJoin"><a href="#键值对关联操作-subtractByKey-join-fullOuterJoin-rightOuterJoin-leftOuterJoin" class="headerlink" title="键值对关联操作 subtractByKey, join,fullOuterJoin, rightOuterJoin, leftOuterJoin"></a>键值对关联操作 subtractByKey, join,fullOuterJoin, rightOuterJoin, leftOuterJoin</h1><p>github: <a href="https://github.com/zhaikaishun/spark_tutorial/tree/master/src/main/java/com/spark/rdd_tutorial/tutorial8" target="_blank" rel="noopener">https://github.com/zhaikaishun/spark_tutorial/tree/master/src/main/java/com/spark/rdd_tutorial/tutorial8</a><br>先从spark-learning中的一张图大致了解其功能<br><img src="https://raw.githubusercontent.com/zhaikaishun/blog_img/master/blog/spark_join/spark-join.png" alt="键值对操作"></p>
<h2 id="subtractByKey"><a href="#subtractByKey" class="headerlink" title="subtractByKey"></a>subtractByKey</h2><p><strong>函数定义</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">subtractByKey</span></span>[<span class="type">W</span>](other: <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">W</span>)])(<span class="keyword">implicit</span> arg0: <span class="type">ClassTag</span>[<span class="type">W</span>]): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">V</span>)]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">subtractByKey</span></span>[<span class="type">W</span>](other: <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">W</span>)], numPartitions: <span class="type">Int</span>)(<span class="keyword">implicit</span> arg0: <span class="type">ClassTag</span>[<span class="type">W</span>]): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">V</span>)]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">subtractByKey</span></span>[<span class="type">W</span>](other: <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">W</span>)], p: <span class="type">Partitioner</span>)(<span class="keyword">implicit</span> arg0: <span class="type">ClassTag</span>[<span class="type">W</span>]): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">V</span>)]</span><br></pre></td></tr></table></figure></p>
<p>类似于subtrac，删掉 RDD 中键与 other RDD 中的键相同的元素</p>
<h2 id="join"><a href="#join" class="headerlink" title="join"></a>join</h2><p><strong>函数定义</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">join</span></span>[<span class="type">W</span>](other: <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">W</span>)]): <span class="type">RDD</span>[(<span class="type">K</span>, (<span class="type">V</span>, <span class="type">W</span>))]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">join</span></span>[<span class="type">W</span>](other: <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">W</span>)], numPartitions: <span class="type">Int</span>): <span class="type">RDD</span>[(<span class="type">K</span>, (<span class="type">V</span>, <span class="type">W</span>))]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">join</span></span>[<span class="type">W</span>](other: <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">W</span>)], partitioner: <span class="type">Partitioner</span>): <span class="type">RDD</span>[(<span class="type">K</span>, (<span class="type">V</span>, <span class="type">W</span>))]</span><br></pre></td></tr></table></figure></p>
<p>RDD1.join(RDD2)<br>可以把RDD1,RDD2中的相同的key给连接起来，类似于sql中的join操作</p>
<h2 id="fullOuterJoin"><a href="#fullOuterJoin" class="headerlink" title="fullOuterJoin"></a>fullOuterJoin</h2><p>和join类似，不过这是全连接</p>
<h2 id="leftOuterJoin"><a href="#leftOuterJoin" class="headerlink" title="leftOuterJoin"></a>leftOuterJoin</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">leftOuterJoin</span></span>[<span class="type">W</span>](other: <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">W</span>)]): <span class="type">RDD</span>[(<span class="type">K</span>, (<span class="type">V</span>, <span class="type">Option</span>[<span class="type">W</span>]))]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">leftOuterJoin</span></span>[<span class="type">W</span>](other: <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">W</span>)], numPartitions: <span class="type">Int</span>): <span class="type">RDD</span>[(<span class="type">K</span>, (<span class="type">V</span>, <span class="type">Option</span>[<span class="type">W</span>]))]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">leftOuterJoin</span></span>[<span class="type">W</span>](other: <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">W</span>)], partitioner: <span class="type">Partitioner</span>): <span class="type">RDD</span>[(<span class="type">K</span>, (<span class="type">V</span>, <span class="type">Option</span>[<span class="type">W</span>]))]</span><br></pre></td></tr></table></figure>
<p>直接看图即可<br>对两个 RDD 进行连接操作，类似于sql中的左外连接</p>
<h2 id="rightOuterJoin"><a href="#rightOuterJoin" class="headerlink" title="rightOuterJoin"></a>rightOuterJoin</h2><p>对两个 RDD 进行连接操作，类似于sql中的右外连接，存在的话，value用的Some, 不存在用的None,具体的看上面的图和下面的代码即可</p>
<h3 id="代码示例"><a href="#代码示例" class="headerlink" title="代码示例"></a>代码示例</h3><p><strong>scala语言</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> rdd = sc.makeRDD(<span class="type">Array</span>((<span class="number">1</span>,<span class="number">2</span>),(<span class="number">3</span>,<span class="number">4</span>),(<span class="number">3</span>,<span class="number">6</span>)))</span><br><span class="line">scala&gt; <span class="keyword">val</span> other = sc.makeRDD(<span class="type">Array</span>((<span class="number">3</span>,<span class="number">9</span>)))</span><br><span class="line"></span><br><span class="line">scala&gt;  rdd.subtractByKey(other).collect()</span><br><span class="line">res0: <span class="type">Array</span>[(<span class="type">Int</span>, <span class="type">Int</span>)] = <span class="type">Array</span>((<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">scala&gt; rdd.join(other).collect()</span><br><span class="line">res1: <span class="type">Array</span>[(<span class="type">Int</span>, (<span class="type">Int</span>, <span class="type">Int</span>))] = <span class="type">Array</span>((<span class="number">3</span>,(<span class="number">4</span>,<span class="number">9</span>)), (<span class="number">3</span>,(<span class="number">6</span>,<span class="number">9</span>)))</span><br><span class="line"></span><br><span class="line">scala&gt; rdd.leftOuterJoin(other).collect()</span><br><span class="line">res2: <span class="type">Array</span>[(<span class="type">Int</span>, (<span class="type">Int</span>, <span class="type">Option</span>[<span class="type">Int</span>]))] = <span class="type">Array</span>((<span class="number">1</span>,(<span class="number">2</span>,<span class="type">None</span>)), (<span class="number">3</span>,(<span class="number">4</span>,<span class="type">Some</span>(<span class="number">9</span>))), (<span class="number">3</span>,(<span class="number">6</span>,<span class="type">Some</span>(<span class="number">9</span>))))</span><br><span class="line"></span><br><span class="line">scala&gt; rdd.rightOuterJoin(other).collect()</span><br><span class="line">res3: <span class="type">Array</span>[(<span class="type">Int</span>, (<span class="type">Option</span>[<span class="type">Int</span>], <span class="type">Int</span>))] = <span class="type">Array</span>((<span class="number">3</span>,(<span class="type">Some</span>(<span class="number">4</span>),<span class="number">9</span>)), (<span class="number">3</span>,(<span class="type">Some</span>(<span class="number">6</span>),<span class="number">9</span>)))</span><br></pre></td></tr></table></figure></p>
<p><strong>java语言</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.SparkConf;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaPairRDD;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaRDD;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaSparkContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.Optional;</span><br><span class="line"><span class="keyword">import</span> scala.Tuple2;</span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JoinRDD</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        SparkConf sparkConf = <span class="keyword">new</span> SparkConf().setAppName(<span class="string">"ReduceByKey"</span>).setMaster(<span class="string">"local"</span>);</span><br><span class="line">        JavaSparkContext sc = <span class="keyword">new</span> JavaSparkContext(sparkConf);</span><br><span class="line">        sc.setLogLevel(<span class="string">"WARN"</span>);</span><br><span class="line"></span><br><span class="line">        JavaRDD&lt;Tuple2&lt;Integer,Integer&gt;&gt; rddPre = sc.parallelize(Arrays.asList(<span class="keyword">new</span> Tuple2(<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">                , <span class="keyword">new</span> Tuple2(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">                , <span class="keyword">new</span> Tuple2(<span class="number">3</span>,<span class="number">6</span>)));</span><br><span class="line">        JavaRDD&lt;Tuple2&lt;Integer,Integer&gt;&gt; otherPre = sc.parallelize(Arrays.asList(<span class="keyword">new</span> Tuple2(<span class="number">3</span>,<span class="number">10</span>),<span class="keyword">new</span> Tuple2(<span class="number">4</span>,<span class="number">8</span>)));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//JavaRDD转换成JavaPairRDD</span></span><br><span class="line">        JavaPairRDD&lt;Integer, Integer&gt; rdd = JavaPairRDD.fromJavaRDD(rddPre);</span><br><span class="line">        JavaPairRDD&lt;Integer, Integer&gt; other = JavaPairRDD.fromJavaRDD(otherPre);</span><br><span class="line">        <span class="comment">//subtractByKey</span></span><br><span class="line">        JavaPairRDD&lt;Integer, Integer&gt; subRDD = rdd.subtractByKey(other);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//join</span></span><br><span class="line">        JavaPairRDD&lt;Integer, Tuple2&lt;Integer, Integer&gt;&gt; joinRDD =  rdd.join(other);</span><br><span class="line">        <span class="comment">//fullOutJoin</span></span><br><span class="line">        JavaPairRDD&lt;Integer, Tuple2&lt;Optional&lt;Integer&gt;, Optional&lt;Integer&gt;&gt;&gt; fullOutJoinRDD = rdd.fullOuterJoin(other);</span><br><span class="line">        <span class="comment">//leftOuterJoin</span></span><br><span class="line">        JavaPairRDD&lt;Integer, Tuple2&lt;Integer, Optional&lt;Integer&gt;&gt;&gt; leftOutJoinRDD = rdd.leftOuterJoin(other);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//rightOutJoin</span></span><br><span class="line">        JavaPairRDD&lt;Integer, Tuple2&lt;Optional&lt;Integer&gt;, Integer&gt;&gt; rightOutJoinRDD = rdd.rightOuterJoin(other);</span><br><span class="line">        <span class="comment">//输出看效果</span></span><br><span class="line">        Map&lt;Integer, Integer&gt; subMap = subRDD.collectAsMap();</span><br><span class="line">        System.out.println(<span class="string">"-------------subRDD-------------"</span>);</span><br><span class="line">        <span class="keyword">for</span> (Integer key : subMap.keySet()) &#123;</span><br><span class="line">            System.out.println(<span class="string">"subRDD: "</span>+key+<span class="string">", "</span>+subMap.get(key));</span><br><span class="line">        &#125;</span><br><span class="line">        Map&lt;Integer, Tuple2&lt;Integer, Integer&gt;&gt; joinMap = joinRDD.collectAsMap();</span><br><span class="line">        System.out.println(<span class="string">"-------------joinRDD-------------"</span>);</span><br><span class="line">        <span class="keyword">for</span> (Integer key : joinMap.keySet()) &#123;</span><br><span class="line">            System.out.println(<span class="string">"join: "</span>+key+<span class="string">", Tuple("</span>+joinMap.get(key)._1+<span class="string">","</span>+joinMap.get(key)._2+<span class="string">")"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        Map&lt;Integer, Tuple2&lt;Optional&lt;Integer&gt;, Optional&lt;Integer&gt;&gt;&gt; fullOutJoinMap = fullOutJoinRDD.collectAsMap();</span><br><span class="line">        System.out.println(<span class="string">"-------------fullOutJoinRDD-------------"</span>);</span><br><span class="line">        <span class="keyword">for</span> (Integer key : fullOutJoinMap.keySet()) &#123;</span><br><span class="line">            System.out.println(<span class="string">"fullOutJoinRDD: "</span>+key+<span class="string">", Tuple("</span>+fullOutJoinMap.get(key)._1+<span class="string">","</span>+fullOutJoinMap.get(key)._2+<span class="string">")"</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        Map&lt;Integer, Tuple2&lt;Integer, Optional&lt;Integer&gt;&gt;&gt; leftOutJoinMap = leftOutJoinRDD.collectAsMap();</span><br><span class="line">        System.out.println(<span class="string">"-------------leftOutJoinRDD-------------"</span>);</span><br><span class="line">        <span class="keyword">for</span> (Integer key : leftOutJoinMap.keySet()) &#123;</span><br><span class="line">            System.out.println(<span class="string">"leftOutJoinRDD: "</span>+key+<span class="string">", Tuple("</span>+leftOutJoinMap.get(key)._1+<span class="string">","</span>+leftOutJoinMap.get(key)._2+<span class="string">")"</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        Map&lt;Integer, Tuple2&lt;Optional&lt;Integer&gt;, Integer&gt;&gt; rightOutJoinMap = rightOutJoinRDD.collectAsMap();</span><br><span class="line">        System.out.println(<span class="string">"-------------rightOutJoinRDD-------------"</span>);</span><br><span class="line">        <span class="keyword">for</span> (Integer key : rightOutJoinMap.keySet()) &#123;</span><br><span class="line">            System.out.println(<span class="string">"rightOutJoinRDD: "</span>+key+<span class="string">", Tuple("</span>+rightOutJoinMap.get(key)._1+<span class="string">","</span>+rightOutJoinMap.get(key)._2+<span class="string">")"</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>运行后显示<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">-------------subRDD-------------</span><br><span class="line">subRDD: <span class="number">1</span>, <span class="number">2</span></span><br><span class="line">-------------joinRDD-------------</span><br><span class="line">join: <span class="number">3</span>, Tuple(<span class="number">6</span>,<span class="number">10</span>)</span><br><span class="line">-------------fullOutJoinRDD-------------</span><br><span class="line">fullOutJoinRDD: <span class="number">4</span>, Tuple(Optional.empty,Optional[<span class="number">8</span>])</span><br><span class="line">fullOutJoinRDD: <span class="number">1</span>, Tuple(Optional[<span class="number">2</span>],Optional.empty)</span><br><span class="line">fullOutJoinRDD: <span class="number">3</span>, Tuple(Optional[<span class="number">6</span>],Optional[<span class="number">10</span>])</span><br><span class="line">-------------leftOutJoinRDD-------------</span><br><span class="line">leftOutJoinRDD: <span class="number">1</span>, Tuple(<span class="number">2</span>,Optional.empty)</span><br><span class="line">leftOutJoinRDD: <span class="number">3</span>, Tuple(<span class="number">6</span>,Optional[<span class="number">10</span>])</span><br><span class="line">-------------rightOutJoinRDD-------------</span><br><span class="line">rightOutJoinRDD: <span class="number">4</span>, Tuple(Optional.empty,<span class="number">8</span>)</span><br><span class="line">rightOutJoinRDD: <span class="number">3</span>, Tuple(Optional[<span class="number">6</span>],<span class="number">10</span>)</span><br></pre></td></tr></table></figure></p>
<hr>
<h1 id="基本的Action操作-first-take-collect-count-countByValue-reduce-aggregate-fold-top"><a href="#基本的Action操作-first-take-collect-count-countByValue-reduce-aggregate-fold-top" class="headerlink" title="基本的Action操作 first, take, collect, count, countByValue, reduce, aggregate, fold,top"></a>基本的Action操作 first, take, collect, count, countByValue, reduce, aggregate, fold,top</h1><h2 id="first"><a href="#first" class="headerlink" title="first"></a>first</h2><p>返回第一个元素<br><strong>scala</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> rdd = sc.parallelize(<span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">scala&gt; rdd.first()</span><br><span class="line">res1: <span class="type">Int</span> = <span class="number">1</span></span><br></pre></td></tr></table></figure></p>
<p><strong>java</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;Integer&gt; rdd = sc.parallelize(Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>));</span><br><span class="line">Integer first = rdd.first();</span><br></pre></td></tr></table></figure></p>
<h2 id="take"><a href="#take" class="headerlink" title="take"></a>take</h2><p>rdd.take(n)返回第n个元素<br><strong>scala</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> rdd = sc.parallelize(<span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">scala&gt; rdd.take(<span class="number">2</span>)</span><br><span class="line">res3: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">1</span>, <span class="number">2</span>)</span><br></pre></td></tr></table></figure></p>
<p><strong>java</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;Integer&gt; rdd = sc.parallelize(Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>));</span><br><span class="line">List&lt;Integer&gt; take = rdd.take(<span class="number">2</span>);</span><br></pre></td></tr></table></figure></p>
<h2 id="collect"><a href="#collect" class="headerlink" title="collect"></a>collect</h2><p>rdd.collect() 返回 RDD 中的所有元素<br><strong>scala</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> rdd = sc.parallelize(<span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">scala&gt; rdd.collect()</span><br><span class="line">res4: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br></pre></td></tr></table></figure></p>
<p><strong>java</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;Integer&gt; rdd = sc.parallelize(Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>));</span><br><span class="line">List&lt;Integer&gt; collect = rdd.collect();</span><br></pre></td></tr></table></figure></p>
<h2 id="count"><a href="#count" class="headerlink" title="count"></a>count</h2><p>rdd.count() 返回 RDD 中的元素个数<br><strong>scala</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> rdd = sc.parallelize(<span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">scala&gt; rdd.count()</span><br><span class="line">res5: <span class="type">Long</span> = <span class="number">4</span></span><br></pre></td></tr></table></figure></p>
<p><strong>java</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;Integer&gt; rdd = sc.parallelize(Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>));</span><br><span class="line"><span class="keyword">long</span> count = rdd.count();</span><br></pre></td></tr></table></figure></p>
<h2 id="countByValue"><a href="#countByValue" class="headerlink" title="countByValue"></a>countByValue</h2><p>各元素在 RDD 中出现的次数 返回{(key1,次数),(key2,次数),…(keyn,次数)}<br><strong>scala</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> rdd = sc.parallelize(<span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">scala&gt; rdd.countByValue()</span><br><span class="line">res6: scala.collection.<span class="type">Map</span>[<span class="type">Int</span>,<span class="type">Long</span>] = <span class="type">Map</span>(<span class="number">1</span> -&gt; <span class="number">1</span>, <span class="number">2</span> -&gt; <span class="number">1</span>, <span class="number">3</span> -&gt; <span class="number">2</span>)</span><br></pre></td></tr></table></figure></p>
<p><strong>java</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;Integer&gt; rdd = sc.parallelize(Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>));</span><br><span class="line">Map&lt;Integer, Long&gt; integerLongMap = rdd.countByValue();</span><br></pre></td></tr></table></figure></p>
<h2 id="reduce"><a href="#reduce" class="headerlink" title="reduce"></a>reduce</h2><p>rdd.reduce(func)<br>并行整合RDD中所有数据， 类似于是scala中集合的reduce<br><strong>scala</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> rdd = sc.parallelize(<span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">scala&gt; rdd.reduce((x,y)=&gt;x+y)</span><br><span class="line">res7: <span class="type">Int</span> = <span class="number">9</span></span><br></pre></td></tr></table></figure></p>
<p><strong>java</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Integer reduce = rdd.reduce(<span class="keyword">new</span> Function2&lt;Integer, Integer, Integer&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Integer <span class="title">call</span><span class="params">(Integer integer, Integer integer2)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> integer + integer2;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure></p>
<h2 id="aggregate"><a href="#aggregate" class="headerlink" title="aggregate"></a>aggregate</h2><p>和 reduce() 相 似， 但 是 通 常<br>返回不同类型的函数 一般不用这个函数</p>
<p><strong>scala</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> rdd = sc.parallelize(<span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line"><span class="type">TODO</span></span><br></pre></td></tr></table></figure></p>
<p><strong>java</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">TODO</span><br></pre></td></tr></table></figure></p>
<h2 id="fold"><a href="#fold" class="headerlink" title="fold"></a>fold</h2><p>rdd.fold(num)(func) 一般不用这个函数<br>和 reduce() 一 样， 但是提供了初始值num,每个元素计算时，先要合这个初始值进行折叠, 注意，这里会按照每个分区进行fold，然后分区之间还会再次进行fold<br>提供初始值<br><strong>scala</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 解释 TODO </span></span><br><span class="line">scala&gt; <span class="keyword">val</span> rdd = sc.parallelize(<span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">3</span>)，<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; rdd.fold(<span class="number">1</span>)((x,y)=&gt;x+y)</span><br><span class="line">res8: <span class="type">Int</span> = <span class="number">12</span></span><br></pre></td></tr></table></figure></p>
<p><strong>java</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">    JavaRDD&lt;Integer&gt; rdd = sc.parallelize(Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>),<span class="number">2</span>);</span><br><span class="line">    Integer fold = rdd.fold(<span class="number">1</span>, <span class="keyword">new</span> Function2&lt;Integer, Integer, Integer&gt;() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> Integer <span class="title">call</span><span class="params">(Integer integer, Integer integer2)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> integer + integer2;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">    System.out.println(fold);</span><br><span class="line">-------输出-----</span><br><span class="line"><span class="number">12</span></span><br></pre></td></tr></table></figure></p>
<h2 id="top"><a href="#top" class="headerlink" title="top"></a>top</h2><p>rdd.top(n)<br>按照降序的或者指定的排序规则，返回前n个元素<br><strong>scala</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> rdd = sc.parallelize(<span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">scala&gt; rdd.top(<span class="number">2</span>)</span><br><span class="line">res9: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">3</span>, <span class="number">3</span>)</span><br></pre></td></tr></table></figure></p>
<p><strong>java</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">JavaRDD</span>&lt;<span class="type">Integer</span>&gt; rdd = sc.parallelize(<span class="type">Arrays</span>.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>),<span class="number">2</span>);</span><br><span class="line"><span class="type">List</span>&lt;<span class="type">Integer</span>&gt; top = rdd.top(<span class="number">2</span>);</span><br></pre></td></tr></table></figure></p>
<h2 id="takeOrdered"><a href="#takeOrdered" class="headerlink" title="takeOrdered"></a>takeOrdered</h2><p>rdd.take(n)<br>对RDD元素进行升序排序,取出前n个元素并返回，也可以自定义比较器（这里不介绍），类似于top的相反的方法<br><strong>scala</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> rdd = sc.parallelize(<span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">scala&gt; rdd.takeOrdered(<span class="number">2</span>)</span><br><span class="line">res10: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">1</span>, <span class="number">2</span>)</span><br></pre></td></tr></table></figure></p>
<p><strong>java</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;Integer&gt; rdd = sc.parallelize(Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>),<span class="number">2</span>);</span><br><span class="line">List&lt;Integer&gt; integers = rdd.takeOrdered(<span class="number">2</span>);</span><br></pre></td></tr></table></figure></p>
<h2 id="foreach"><a href="#foreach" class="headerlink" title="foreach"></a>foreach</h2><p>对 RDD 中的每个元素使用给<br>定的函数<br><strong>scala</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">    <span class="keyword">val</span> rdd = sc.parallelize(<span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line">    rdd.foreach(print(_))</span><br><span class="line">-----输出-----------</span><br><span class="line"><span class="number">1233</span></span><br></pre></td></tr></table></figure></p>
<p><strong>java</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">rdd.foreach(<span class="keyword">new</span> VoidFunction&lt;Integer&gt;() &#123;</span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">call</span><span class="params">(Integer integer)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">       System.out.println(integer);</span><br><span class="line">   &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure></p>
<hr>
<h1 id="PairRDD的Action操作countByKey-collectAsMap"><a href="#PairRDD的Action操作countByKey-collectAsMap" class="headerlink" title="PairRDD的Action操作countByKey, collectAsMap"></a>PairRDD的Action操作countByKey, collectAsMap</h1><h2 id="countByKey"><a href="#countByKey" class="headerlink" title="countByKey"></a>countByKey</h2><p>def countByKey(): Map[K, Long]<br>以RDD{(1, 2),(2,4),(2,5), (3, 4),(3,5), (3, 6)}为例 rdd.countByKey会返回{(1,1),(2,2),(3,3)}<br><strong>scala例子</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> rdd = sc.parallelize(<span class="type">Array</span>((<span class="number">1</span>, <span class="number">2</span>),(<span class="number">2</span>,<span class="number">4</span>),(<span class="number">2</span>,<span class="number">5</span>), (<span class="number">3</span>, <span class="number">4</span>),(<span class="number">3</span>,<span class="number">5</span>), (<span class="number">3</span>, <span class="number">6</span>)))</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> countbyKeyRDD = rdd.countByKey()</span><br><span class="line">countbyKeyRDD: scala.collection.<span class="type">Map</span>[<span class="type">Int</span>,<span class="type">Long</span>] = <span class="type">Map</span>(<span class="number">1</span> -&gt; <span class="number">1</span>, <span class="number">2</span> -&gt; <span class="number">2</span>, <span class="number">3</span> -&gt; <span class="number">3</span>)</span><br></pre></td></tr></table></figure></p>
<p><strong>java例子</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">    JavaRDD&lt;Tuple2&lt;Integer, Integer&gt;&gt; tupleRDD =</span><br><span class="line">            sc.parallelize(Arrays.asList(<span class="keyword">new</span> Tuple2&lt;&gt;(<span class="number">1</span>, <span class="number">2</span>),</span><br><span class="line">            <span class="keyword">new</span> Tuple2&lt;&gt;(<span class="number">2</span>, <span class="number">4</span>),</span><br><span class="line">            <span class="keyword">new</span> Tuple2&lt;&gt;(<span class="number">2</span>, <span class="number">5</span>),</span><br><span class="line">            <span class="keyword">new</span> Tuple2&lt;&gt;(<span class="number">3</span>, <span class="number">4</span>),</span><br><span class="line">            <span class="keyword">new</span> Tuple2&lt;&gt;(<span class="number">3</span>, <span class="number">5</span>),</span><br><span class="line">            <span class="keyword">new</span> Tuple2&lt;&gt;(<span class="number">3</span>, <span class="number">6</span>)));</span><br><span class="line">    JavaPairRDD&lt;Integer, Integer&gt; mapRDD = JavaPairRDD.fromJavaRDD(tupleRDD);</span><br><span class="line">    <span class="comment">//countByKey</span></span><br><span class="line">    Map&lt;Integer, Object&gt; countByKeyRDD = mapRDD.countByKey();</span><br><span class="line">    <span class="keyword">for</span> (Integer i:countByKeyRDD.keySet()) &#123;</span><br><span class="line">        System.out.println(<span class="string">"("</span>+i+<span class="string">", "</span>+countByKeyRDD.get(i)+<span class="string">")"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">输出  </span></span><br><span class="line"><span class="comment">(1, 1)</span></span><br><span class="line"><span class="comment">(3, 3)</span></span><br><span class="line"><span class="comment">(2, 2)</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure></p>
<h2 id="collectAsMap"><a href="#collectAsMap" class="headerlink" title="collectAsMap"></a>collectAsMap</h2><p>将pair类型(键值对类型)的RDD转换成map, 还是上面的例子</p>
<p><strong>scala例子</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> rdd = sc.parallelize(<span class="type">Array</span>((<span class="number">1</span>, <span class="number">2</span>),(<span class="number">2</span>,<span class="number">4</span>),(<span class="number">2</span>,<span class="number">5</span>), (<span class="number">3</span>, <span class="number">4</span>),(<span class="number">3</span>,<span class="number">5</span>), (<span class="number">3</span>, <span class="number">6</span>)))</span><br><span class="line"></span><br><span class="line">scala&gt; rdd.collectAsMap()</span><br><span class="line">res1: scala.collection.<span class="type">Map</span>[<span class="type">Int</span>,<span class="type">Int</span>] = <span class="type">Map</span>(<span class="number">2</span> -&gt; <span class="number">5</span>, <span class="number">1</span> -&gt; <span class="number">2</span>, <span class="number">3</span> -&gt; <span class="number">6</span>)</span><br></pre></td></tr></table></figure></p>
<p><strong>java例子</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;Tuple2&lt;Integer, Integer&gt;&gt; tupleRDD =</span><br><span class="line">        sc.parallelize(Arrays.asList(<span class="keyword">new</span> Tuple2&lt;&gt;(<span class="number">1</span>, <span class="number">2</span>),</span><br><span class="line">        <span class="keyword">new</span> Tuple2&lt;&gt;(<span class="number">2</span>, <span class="number">4</span>),</span><br><span class="line">        <span class="keyword">new</span> Tuple2&lt;&gt;(<span class="number">2</span>, <span class="number">5</span>),</span><br><span class="line">        <span class="keyword">new</span> Tuple2&lt;&gt;(<span class="number">3</span>, <span class="number">4</span>),</span><br><span class="line">        <span class="keyword">new</span> Tuple2&lt;&gt;(<span class="number">3</span>, <span class="number">5</span>),</span><br><span class="line">        <span class="keyword">new</span> Tuple2&lt;&gt;(<span class="number">3</span>, <span class="number">6</span>)));</span><br><span class="line">JavaPairRDD&lt;Integer, Integer&gt; mapRDD = JavaPairRDD.fromJavaRDD(tupleRDD);</span><br><span class="line"></span><br><span class="line">Map&lt;Integer, Integer&gt; collectMap = mapRDD.collectAsMap();</span><br></pre></td></tr></table></figure></p>
<hr>
<h1 id="RDD-Action-保存操作saveAsTextFile-saveAsSequenceFile-saveAsObjectFile-saveAsHadoopFile-等"><a href="#RDD-Action-保存操作saveAsTextFile-saveAsSequenceFile-saveAsObjectFile-saveAsHadoopFile-等" class="headerlink" title="RDD Action 保存操作saveAsTextFile,saveAsSequenceFile,saveAsObjectFile,saveAsHadoopFile 等"></a>RDD Action 保存操作saveAsTextFile,saveAsSequenceFile,saveAsObjectFile,saveAsHadoopFile 等</h1><p><strong>关键字:Spark算子、Spark函数、Spark RDD行动Action、Spark RDD存储操作、saveAsTextFile、saveAsSequenceFile、saveAsObjectFile,saveAsHadoopFile、saveAsHadoopDataset,saveAsNewAPIHadoopFile、saveAsNewAPIHadoopDataset</strong></p>
<h2 id="saveAsTextFile"><a href="#saveAsTextFile" class="headerlink" title="saveAsTextFile"></a>saveAsTextFile</h2><p>def saveAsTextFile(path: String): Unit</p>
<p>def saveAsTextFile(path: String, codec: Class[_ &lt;: CompressionCodec]): Unit</p>
<p>saveAsTextFile用于将RDD以文本文件的格式存储到文件系统中。</p>
<p>codec参数可以指定压缩的类名。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> rdd1 = sc.makeRDD(<span class="number">1</span> to <span class="number">10</span>,<span class="number">2</span>)</span><br><span class="line">scala&gt; rdd1.saveAsTextFile(<span class="string">"hdfs://cdh5/tmp/lxw1234.com/"</span>) <span class="comment">//保存到HDFS</span></span><br><span class="line">hadoop fs -ls /tmp/lxw1234.com</span><br><span class="line"><span class="type">Found</span> <span class="number">2</span> items</span><br><span class="line">-rw-r--r--   <span class="number">2</span> lxw1234 supergroup        <span class="number">0</span> <span class="number">2015</span><span class="number">-07</span><span class="number">-10</span> <span class="number">09</span>:<span class="number">15</span> /tmp/lxw1234.com/_SUCCESS</span><br><span class="line">-rw-r--r--   <span class="number">2</span> lxw1234 supergroup        <span class="number">21</span> <span class="number">2015</span><span class="number">-07</span><span class="number">-10</span> <span class="number">09</span>:<span class="number">15</span> /tmp/lxw1234.com/part<span class="number">-00000</span></span><br><span class="line"></span><br><span class="line">hadoop fs -cat /tmp/lxw1234.com/part<span class="number">-00000</span></span><br></pre></td></tr></table></figure></p>
<p>注意：如果使用rdd1.saveAsTextFile(“file:///tmp/lxw1234.com”)将文件保存到本地文件系统，那么只会保存在Executor所在机器的本地目录。<br><strong>指定压缩格式保存</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">rdd1.saveAsTextFile(<span class="string">"hdfs://cdh5/tmp/lxw1234.com/"</span>,classOf[com.hadoop.compression.lzo.<span class="type">LzopCodec</span>])</span><br><span class="line"></span><br><span class="line">hadoop fs -ls /tmp/lxw1234.com</span><br><span class="line">-rw-r--r--   <span class="number">2</span> lxw1234 supergroup    <span class="number">0</span> <span class="number">2015</span><span class="number">-07</span><span class="number">-10</span> <span class="number">09</span>:<span class="number">20</span> /tmp/lxw1234.com/_SUCCESS</span><br><span class="line">-rw-r--r--   <span class="number">2</span> lxw1234 supergroup    <span class="number">71</span> <span class="number">2015</span><span class="number">-07</span><span class="number">-10</span> <span class="number">09</span>:<span class="number">20</span> /tmp/lxw1234.com/part<span class="number">-00000.</span>lzo</span><br><span class="line"></span><br><span class="line">hadoop fs -text /tmp/lxw1234.com/part<span class="number">-00000.</span>lzo</span><br></pre></td></tr></table></figure></p>
<h2 id="saveAsSequenceFile"><a href="#saveAsSequenceFile" class="headerlink" title="saveAsSequenceFile"></a>saveAsSequenceFile</h2><p>saveAsSequenceFile用于将RDD以SequenceFile的文件格式保存到HDFS上。<br>用法同saveAsTextFile。</p>
<h2 id="saveAsObjectFile"><a href="#saveAsObjectFile" class="headerlink" title="saveAsObjectFile"></a>saveAsObjectFile</h2><p>def saveAsObjectFile(path: String): Unit<br>saveAsObjectFile用于将RDD中的元素序列化成对象，存储到文件中。<br>对于HDFS，默认采用SequenceFile保存。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> rdd1 = sc.makeRDD(<span class="number">1</span> to <span class="number">10</span>,<span class="number">2</span>)</span><br><span class="line">rdd1.saveAsObjectFile(<span class="string">"hdfs://cdh5/tmp/lxw1234.com/"</span>)</span><br><span class="line"></span><br><span class="line">hadoop fs -cat /tmp/lxw1234.com/part<span class="number">-00000</span></span><br><span class="line"><span class="type">SEQ</span> !org.apache.hadoop.io.<span class="type">NullWritable</span><span class="string">"org.apache.hadoop.io.BytesWritableT</span></span><br></pre></td></tr></table></figure></p>
<h2 id="saveAsHadoopFile"><a href="#saveAsHadoopFile" class="headerlink" title="saveAsHadoopFile"></a>saveAsHadoopFile</h2><p>def saveAsHadoopFile(path: String, keyClass: Class[], valueClass: Class[], outputFormatClass: Class[_ &lt;: OutputFormat[, ]], codec: Class[_ &lt;: CompressionCodec]): Unit</p>
<p>def saveAsHadoopFile(path: String, keyClass: Class[], valueClass: Class[], outputFormatClass: Class[_ &lt;: OutputFormat[, ]], conf: JobConf = …, codec: Option[Class[_ &lt;: CompressionCodec]] = None): Unit</p>
<p>saveAsHadoopFile是将RDD存储在HDFS上的文件中，支持老版本Hadoop API。</p>
<p>可以指定outputKeyClass、outputValueClass以及压缩格式。</p>
<p>每个分区输出一个文件。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> rdd1 = sc.makeRDD(<span class="type">Array</span>((<span class="string">"A"</span>,<span class="number">2</span>),(<span class="string">"A"</span>,<span class="number">1</span>),(<span class="string">"B"</span>,<span class="number">6</span>),(<span class="string">"B"</span>,<span class="number">3</span>),(<span class="string">"B"</span>,<span class="number">7</span>)))</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapred.<span class="type">TextOutputFormat</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.<span class="type">Text</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.<span class="type">IntWritable</span></span><br><span class="line"></span><br><span class="line">rdd1.saveAsHadoopFile(<span class="string">"/tmp/lxw1234.com/"</span>,classOf[<span class="type">Text</span>],classOf[<span class="type">IntWritable</span>],classOf[<span class="type">TextOutputFormat</span>[<span class="type">Text</span>,<span class="type">IntWritable</span>]])</span><br><span class="line"></span><br><span class="line">rdd1.saveAsHadoopFile(<span class="string">"/tmp/lxw1234.com/"</span>,classOf[<span class="type">Text</span>],classOf[<span class="type">IntWritable</span>],classOf[<span class="type">TextOutputFormat</span>[<span class="type">Text</span>,<span class="type">IntWritable</span>]],</span><br><span class="line">                      classOf[com.hadoop.compression.lzo.<span class="type">LzopCodec</span>])</span><br></pre></td></tr></table></figure></p>
<h2 id="saveAsHadoopDataset"><a href="#saveAsHadoopDataset" class="headerlink" title="saveAsHadoopDataset"></a>saveAsHadoopDataset</h2><p>def saveAsHadoopDataset(conf: JobConf): Unit</p>
<p>saveAsHadoopDataset用于将RDD保存到除了HDFS的其他存储中，比如HBase。</p>
<p>在JobConf中，通常需要关注或者设置五个参数：</p>
<p>文件的保存路径、key值的class类型、value值的class类型、RDD的输出格式(OutputFormat)、以及压缩相关的参数。<br><strong>##使用saveAsHadoopDataset将RDD保存到HDFS中</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkContext</span></span><br><span class="line"><span class="keyword">import</span> <span class="type">SparkContext</span>._</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapred.<span class="type">TextOutputFormat</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.<span class="type">Text</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.<span class="type">IntWritable</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapred.<span class="type">JobConf</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> rdd1 = sc.makeRDD(<span class="type">Array</span>((<span class="string">"A"</span>,<span class="number">2</span>),(<span class="string">"A"</span>,<span class="number">1</span>),(<span class="string">"B"</span>,<span class="number">6</span>),(<span class="string">"B"</span>,<span class="number">3</span>),(<span class="string">"B"</span>,<span class="number">7</span>)))</span><br><span class="line"><span class="keyword">var</span> jobConf = <span class="keyword">new</span> <span class="type">JobConf</span>()</span><br><span class="line">jobConf.setOutputFormat(classOf[<span class="type">TextOutputFormat</span>[<span class="type">Text</span>,<span class="type">IntWritable</span>]])</span><br><span class="line">jobConf.setOutputKeyClass(classOf[<span class="type">Text</span>])</span><br><span class="line">jobConf.setOutputValueClass(classOf[<span class="type">IntWritable</span>])</span><br><span class="line">jobConf.set(<span class="string">"mapred.output.dir"</span>,<span class="string">"/tmp/lxw1234/"</span>)</span><br><span class="line">rdd1.saveAsHadoopDataset(jobConf)</span><br><span class="line"></span><br><span class="line">结果：</span><br><span class="line">hadoop fs -cat /tmp/lxw1234/part<span class="number">-00000</span></span><br><span class="line"><span class="type">A</span>       <span class="number">2</span></span><br><span class="line"><span class="type">A</span>       <span class="number">1</span></span><br><span class="line">hadoop fs -cat /tmp/lxw1234/part<span class="number">-00001</span></span><br><span class="line"><span class="type">B</span>       <span class="number">6</span></span><br><span class="line"><span class="type">B</span>       <span class="number">3</span></span><br><span class="line"><span class="type">B</span>       <span class="number">7</span></span><br></pre></td></tr></table></figure></p>
<p><strong>##保存数据到HBASE</strong><br>HBase建表：</p>
<p>create ‘lxw1234′,{NAME =&gt; ‘f1′,VERSIONS =&gt; 1},{NAME =&gt; ‘f2′,VERSIONS =&gt; 1},{NAME =&gt; ‘f3′,VERSIONS =&gt; 1}<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkContext</span></span><br><span class="line"><span class="keyword">import</span> <span class="type">SparkContext</span>._</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapred.<span class="type">TextOutputFormat</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.<span class="type">Text</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.<span class="type">IntWritable</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapred.<span class="type">JobConf</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.<span class="type">HBaseConfiguration</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.mapred.<span class="type">TableOutputFormat</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.<span class="type">Put</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.util.<span class="type">Bytes</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.io.<span class="type">ImmutableBytesWritable</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> conf = <span class="type">HBaseConfiguration</span>.create()</span><br><span class="line">    <span class="keyword">var</span> jobConf = <span class="keyword">new</span> <span class="type">JobConf</span>(conf)</span><br><span class="line">    jobConf.set(<span class="string">"hbase.zookeeper.quorum"</span>,<span class="string">"zkNode1,zkNode2,zkNode3"</span>)</span><br><span class="line">    jobConf.set(<span class="string">"zookeeper.znode.parent"</span>,<span class="string">"/hbase"</span>)</span><br><span class="line">    jobConf.set(<span class="type">TableOutputFormat</span>.<span class="type">OUTPUT_TABLE</span>,<span class="string">"lxw1234"</span>)</span><br><span class="line">    jobConf.setOutputFormat(classOf[<span class="type">TableOutputFormat</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">var</span> rdd1 = sc.makeRDD(<span class="type">Array</span>((<span class="string">"A"</span>,<span class="number">2</span>),(<span class="string">"B"</span>,<span class="number">6</span>),(<span class="string">"C"</span>,<span class="number">7</span>)))</span><br><span class="line">    rdd1.map(x =&gt; </span><br><span class="line">      &#123;</span><br><span class="line">        <span class="keyword">var</span> put = <span class="keyword">new</span> <span class="type">Put</span>(<span class="type">Bytes</span>.toBytes(x._1))</span><br><span class="line">        put.add(<span class="type">Bytes</span>.toBytes(<span class="string">"f1"</span>), <span class="type">Bytes</span>.toBytes(<span class="string">"c1"</span>), <span class="type">Bytes</span>.toBytes(x._2))</span><br><span class="line">        (<span class="keyword">new</span> <span class="type">ImmutableBytesWritable</span>,put)</span><br><span class="line">      &#125;</span><br><span class="line">    ).saveAsHadoopDataset(jobConf)</span><br><span class="line"></span><br><span class="line">##结果：</span><br><span class="line">hbase(main):<span class="number">005</span>:<span class="number">0</span>&gt; scan <span class="symbol">'lxw123</span>4'</span><br><span class="line"><span class="type">ROW</span>     <span class="type">COLUMN</span>+<span class="type">CELL</span>                                                                                                </span><br><span class="line"> <span class="type">A</span>       column=f1:c1, timestamp=<span class="number">1436504941187</span>, value=\x00\x00\x00\x02                                              </span><br><span class="line"> <span class="type">B</span>       column=f1:c1, timestamp=<span class="number">1436504941187</span>, value=\x00\x00\x00\x06                                              </span><br><span class="line"> <span class="type">C</span>       column=f1:c1, timestamp=<span class="number">1436504941187</span>, value=\x00\x00\x00\x07                                              </span><br><span class="line"><span class="number">3</span> row(s) in <span class="number">0.0550</span> seconds</span><br></pre></td></tr></table></figure></p>
<p>注意：保存到HBase，运行时候需要在SPARK_CLASSPATH中加入HBase相关的jar包。</p>
<p>可参考：<a href="http://lxw1234.com/archives/2015/07/332.htm" target="_blank" rel="noopener">http://lxw1234.com/archives/2015/07/332.htm</a></p>
<h2 id="saveAsNewAPIHadoopFile"><a href="#saveAsNewAPIHadoopFile" class="headerlink" title="saveAsNewAPIHadoopFile"></a>saveAsNewAPIHadoopFile</h2><p>def saveAsNewAPIHadoopFile<a href="path: String" target="_blank" rel="noopener">F &lt;: OutputFormat[K, V]</a>(implicit fm: ClassTag[F]): Unit</p>
<p>def saveAsNewAPIHadoopFile(path: String, keyClass: Class[], valueClass: Class[], outputFormatClass: Class[_ &lt;: OutputFormat[, ]], conf: Configuration = self.context.hadoopConfiguration): Unit</p>
<p>saveAsNewAPIHadoopFile用于将RDD数据保存到HDFS上，使用新版本Hadoop API。</p>
<p>用法基本同saveAsHadoopFile。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkContext</span></span><br><span class="line"><span class="keyword">import</span> <span class="type">SparkContext</span>._</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.<span class="type">TextOutputFormat</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.<span class="type">Text</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.<span class="type">IntWritable</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> rdd1 = sc.makeRDD(<span class="type">Array</span>((<span class="string">"A"</span>,<span class="number">2</span>),(<span class="string">"A"</span>,<span class="number">1</span>),(<span class="string">"B"</span>,<span class="number">6</span>),(<span class="string">"B"</span>,<span class="number">3</span>),(<span class="string">"B"</span>,<span class="number">7</span>)))</span><br><span class="line">rdd1.saveAsNewAPIHadoopFile(<span class="string">"/tmp/lxw1234/"</span>,classOf[<span class="type">Text</span>],classOf[<span class="type">IntWritable</span>],classOf[<span class="type">TextOutputFormat</span>[<span class="type">Text</span>,<span class="type">IntWritable</span>]])</span><br></pre></td></tr></table></figure></p>
<h2 id="saveAsNewAPIHadoopDataset"><a href="#saveAsNewAPIHadoopDataset" class="headerlink" title="saveAsNewAPIHadoopDataset"></a>saveAsNewAPIHadoopDataset</h2><p>def saveAsNewAPIHadoopDataset(conf: Configuration): Unit</p>
<p>作用同saveAsHadoopDataset,只不过采用新版本Hadoop API。</p>
<p>以写入HBase为例：</p>
<p>HBase建表：</p>
<p>create ‘lxw1234′,{NAME =&gt; ‘f1′,VERSIONS =&gt; 1},{NAME =&gt; ‘f2′,VERSIONS =&gt; 1},{NAME =&gt; ‘f3′,VERSIONS =&gt; 1}</p>
<p>完整的Spark应用程序：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.lxw1234.test</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkContext</span></span><br><span class="line"><span class="keyword">import</span> <span class="type">SparkContext</span>._</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.<span class="type">HBaseConfiguration</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.<span class="type">Job</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.mapreduce.<span class="type">TableOutputFormat</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.io.<span class="type">ImmutableBytesWritable</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.<span class="type">Result</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.util.<span class="type">Bytes</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.<span class="type">Put</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Test</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args : <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">   <span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"spark://lxw1234.com:7077"</span>).setAppName(<span class="string">"lxw1234.com"</span>)</span><br><span class="line">   <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(sparkConf);</span><br><span class="line">   <span class="keyword">var</span> rdd1 = sc.makeRDD(<span class="type">Array</span>((<span class="string">"A"</span>,<span class="number">2</span>),(<span class="string">"B"</span>,<span class="number">6</span>),(<span class="string">"C"</span>,<span class="number">7</span>)))</span><br><span class="line"></span><br><span class="line">    sc.hadoopConfiguration.set(<span class="string">"hbase.zookeeper.quorum "</span>,<span class="string">"zkNode1,zkNode2,zkNode3"</span>)</span><br><span class="line">    sc.hadoopConfiguration.set(<span class="string">"zookeeper.znode.parent"</span>,<span class="string">"/hbase"</span>)</span><br><span class="line">    sc.hadoopConfiguration.set(<span class="type">TableOutputFormat</span>.<span class="type">OUTPUT_TABLE</span>,<span class="string">"lxw1234"</span>)</span><br><span class="line">    <span class="keyword">var</span> job = <span class="keyword">new</span> <span class="type">Job</span>(sc.hadoopConfiguration)</span><br><span class="line">    job.setOutputKeyClass(classOf[<span class="type">ImmutableBytesWritable</span>])</span><br><span class="line">    job.setOutputValueClass(classOf[<span class="type">Result</span>])</span><br><span class="line">    job.setOutputFormatClass(classOf[<span class="type">TableOutputFormat</span>[<span class="type">ImmutableBytesWritable</span>]])</span><br><span class="line"></span><br><span class="line">    rdd1.map(</span><br><span class="line">      x =&gt; &#123;</span><br><span class="line">        <span class="keyword">var</span> put = <span class="keyword">new</span> <span class="type">Put</span>(<span class="type">Bytes</span>.toBytes(x._1))</span><br><span class="line">        put.add(<span class="type">Bytes</span>.toBytes(<span class="string">"f1"</span>), <span class="type">Bytes</span>.toBytes(<span class="string">"c1"</span>), <span class="type">Bytes</span>.toBytes(x._2))</span><br><span class="line">        (<span class="keyword">new</span> <span class="type">ImmutableBytesWritable</span>,put)</span><br><span class="line">      &#125;    </span><br><span class="line">    ).saveAsNewAPIHadoopDataset(job.getConfiguration)</span><br><span class="line"></span><br><span class="line">    sc.stop()   </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>注意：保存到HBase，运行时候需要在SPARK_CLASSPATH中加入HBase相关的jar包。</p>
<p>可参考：<a href="http://lxw1234.com/archives/2015/07/332.htm" target="_blank" rel="noopener">http://lxw1234.com/archives/2015/07/332.htm</a></p>
<p>感谢原作者的总结<br>本文转自: lxw的大数据田地<br><a href="http://lxw1234.com/archives/2015/07/402.htm" target="_blank" rel="noopener">http://lxw1234.com/archives/2015/07/402.htm</a><br><a href="http://lxw1234.com/archives/2015/07/404.htm" target="_blank" rel="noopener">http://lxw1234.com/archives/2015/07/404.htm</a><br><a href="http://lxw1234.com/archives/2015/07/406.htm" target="_blank" rel="noopener">http://lxw1234.com/archives/2015/07/406.htm</a></p>
<hr>
<h1 id="RDD-分区操作上mapPartitions-mapPartitionsWithIndex"><a href="#RDD-分区操作上mapPartitions-mapPartitionsWithIndex" class="headerlink" title="RDD 分区操作上mapPartitions, mapPartitionsWithIndex"></a>RDD 分区操作上mapPartitions, mapPartitionsWithIndex</h1><h2 id="mapPartitions"><a href="#mapPartitions" class="headerlink" title="mapPartitions"></a>mapPartitions</h2><p>mapPartition可以倒过来理解，先partition，再把每个partition进行map函数，<br><strong>适用场景</strong><br>如果在映射的过程中需要频繁创建额外的对象，使用mapPartitions要比map高效的过。</p>
<p>比如，将RDD中的所有数据通过JDBC连接写入数据库，如果使用map函数，可能要为每一个元素都创建一个connection，这样开销很大，如果使用mapPartitions，那么只需要针对每一个分区建立一个connection。<br>下面的例子，把每一个元素平方<br><strong>java 每一个元素平方</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">        JavaRDD&lt;Integer&gt; rdd = sc.parallelize(</span><br><span class="line">                Arrays.asList(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">10</span>));</span><br><span class="line">        JavaRDD&lt;Integer&gt; mapPartitionRDD = rdd.mapPartitions(<span class="keyword">new</span> FlatMapFunction&lt;Iterator&lt;Integer&gt;, Integer&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> Iterable&lt;Integer&gt; <span class="title">call</span><span class="params">(Iterator&lt;Integer&gt; it)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                ArrayList&lt;Integer&gt; results = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">                <span class="keyword">while</span> (it.hasNext()) &#123;</span><br><span class="line">                    <span class="keyword">int</span> i = it.next();</span><br><span class="line">                    results.add(i*i);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">return</span> results;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        mapPartitionRDD.foreach(<span class="keyword">new</span> VoidFunction&lt;Integer&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">call</span><span class="params">(Integer integer)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                System.out.println(integer);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">----------输出-------------</span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">4</span></span><br><span class="line"><span class="number">9</span></span><br><span class="line"><span class="number">16</span></span><br><span class="line"><span class="number">25</span></span><br><span class="line"><span class="number">36</span></span><br><span class="line"><span class="number">49</span></span><br><span class="line"><span class="number">64</span></span><br><span class="line"><span class="number">81</span></span><br><span class="line"><span class="number">100</span></span><br></pre></td></tr></table></figure></p>
<p><strong>把每一个数字i变成一个map(i,i*i)的形式</strong></p>
<p><strong>java，把每一个元素变成map(i,i*i)</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">        JavaRDD&lt;Tuple2&lt;Integer, Integer&gt;&gt; tuple2JavaRDD = rdd.mapPartitions(<span class="keyword">new</span> FlatMapFunction&lt;Iterator&lt;Integer&gt;, Tuple2&lt;Integer, Integer&gt;&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> Iterable&lt;Tuple2&lt;Integer, Integer&gt;&gt; call(Iterator&lt;Integer&gt; it) <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                ArrayList&lt;Tuple2&lt;Integer, Integer&gt;&gt; tuple2s = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">                <span class="keyword">while</span> (it.hasNext()) &#123;</span><br><span class="line">                    Integer next = it.next();</span><br><span class="line">                    tuple2s.add(<span class="keyword">new</span> Tuple2&lt;Integer, Integer&gt;(next, next * next));</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">return</span> tuple2s;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        tuple2JavaRDD.foreach(<span class="keyword">new</span> VoidFunction&lt;Tuple2&lt;Integer, Integer&gt;&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">call</span><span class="params">(Tuple2&lt;Integer, Integer&gt; tp2)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                System.out.println(tp2);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">---------输出---------------</span><br><span class="line">(<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">(<span class="number">2</span>,<span class="number">4</span>)</span><br><span class="line">(<span class="number">3</span>,<span class="number">9</span>)</span><br><span class="line">(<span class="number">4</span>,<span class="number">16</span>)</span><br><span class="line">(<span class="number">5</span>,<span class="number">25</span>)</span><br><span class="line">(<span class="number">6</span>,<span class="number">36</span>)</span><br><span class="line">(<span class="number">7</span>,<span class="number">49</span>)</span><br><span class="line">(<span class="number">8</span>,<span class="number">64</span>)</span><br><span class="line">(<span class="number">9</span>,<span class="number">81</span>)</span><br><span class="line">(<span class="number">10</span>,<span class="number">100</span>)</span><br></pre></td></tr></table></figure></p>
<p><strong>scala 把每一个元素变成map(i,i*i)</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">    <span class="keyword">val</span> rdd = sc.parallelize(<span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">10</span>),<span class="number">3</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mapPartFunc</span></span>(iter: <span class="type">Iterator</span>[<span class="type">Int</span>]):<span class="type">Iterator</span>[(<span class="type">Int</span>,<span class="type">Int</span>)]=&#123;</span><br><span class="line">      <span class="keyword">var</span> res = <span class="type">List</span>[(<span class="type">Int</span>,<span class="type">Int</span>)]()</span><br><span class="line">      <span class="keyword">while</span> (iter.hasNext)&#123;</span><br><span class="line">        <span class="keyword">val</span> cur = iter.next</span><br><span class="line">        res=res.::(cur,cur*cur)</span><br><span class="line">      &#125;</span><br><span class="line">       res.iterator</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">val</span> mapPartRDD = rdd.mapPartitions(mapPartFunc)</span><br><span class="line">    mapPartRDD.foreach(maps=&gt;println(maps))</span><br><span class="line">----------输出-----------</span><br><span class="line">(<span class="number">3</span>,<span class="number">9</span>)</span><br><span class="line">(<span class="number">2</span>,<span class="number">4</span>)</span><br><span class="line">(<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">(<span class="number">6</span>,<span class="number">36</span>)</span><br><span class="line">(<span class="number">5</span>,<span class="number">25</span>)</span><br><span class="line">(<span class="number">4</span>,<span class="number">16</span>)</span><br><span class="line">(<span class="number">10</span>,<span class="number">100</span>)</span><br><span class="line">(<span class="number">9</span>,<span class="number">81</span>)</span><br><span class="line">(<span class="number">8</span>,<span class="number">64</span>)</span><br><span class="line">(<span class="number">7</span>,<span class="number">49</span>)</span><br></pre></td></tr></table></figure></p>
<p><strong>mapPartitions操作键值对 把(i,j) 变成(i,j*j)</strong><br><strong>scala版本</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> rdd = sc.parallelize(<span class="type">List</span>((<span class="number">1</span>,<span class="number">1</span>), (<span class="number">1</span>,<span class="number">2</span>), (<span class="number">1</span>,<span class="number">3</span>), (<span class="number">2</span>,<span class="number">1</span>), (<span class="number">2</span>,<span class="number">2</span>), (<span class="number">2</span>,<span class="number">3</span>)))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mapPartFunc</span></span>(iter: <span class="type">Iterator</span>[(<span class="type">Int</span>,<span class="type">Int</span>)]):<span class="type">Iterator</span>[(<span class="type">Int</span>,<span class="type">Int</span>)]=&#123;</span><br><span class="line">  <span class="keyword">var</span> res = <span class="type">List</span>[(<span class="type">Int</span>,<span class="type">Int</span>)]()</span><br><span class="line">  <span class="keyword">while</span> (iter.hasNext)&#123;</span><br><span class="line">    <span class="keyword">val</span> cur = iter.next</span><br><span class="line">    res=res.::(cur._1,cur._2*cur._2)</span><br><span class="line">  &#125;</span><br><span class="line">  res.iterator</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">val</span> mapPartionsRDD = rdd.mapPartitions(mapPartFunc)</span><br><span class="line">mapPartionsRDD.foreach(println( _))</span><br></pre></td></tr></table></figure></p>
<p><strong>java版本</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">        JavaRDD&lt;Tuple2&lt;Integer, Integer&gt;&gt; rdd = sc.parallelize(Arrays.asList(<span class="keyword">new</span> Tuple2&lt;Integer, Integer&gt;(<span class="number">1</span>, <span class="number">1</span>), <span class="keyword">new</span> Tuple2&lt;Integer, Integer&gt;(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">                , <span class="keyword">new</span> Tuple2&lt;Integer, Integer&gt;(<span class="number">1</span>, <span class="number">3</span>), <span class="keyword">new</span> Tuple2&lt;Integer, Integer&gt;(<span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">                , <span class="keyword">new</span> Tuple2&lt;Integer, Integer&gt;(<span class="number">2</span>, <span class="number">2</span>), <span class="keyword">new</span> Tuple2&lt;Integer, Integer&gt;(<span class="number">2</span>, <span class="number">3</span>)), <span class="number">3</span>);</span><br><span class="line">        JavaPairRDD&lt;Integer, Integer&gt; pairRDD = JavaPairRDD.fromJavaRDD(rdd);</span><br><span class="line">        JavaRDD&lt;Tuple2&lt;Integer, Integer&gt;&gt; tuple2JavaRDD = pairRDD.mapPartitions(<span class="keyword">new</span> FlatMapFunction&lt;Iterator&lt;Tuple2&lt;Integer, Integer&gt;&gt;, Tuple2&lt;Integer, Integer&gt;&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> Iterable&lt;Tuple2&lt;Integer, Integer&gt;&gt; call(Iterator&lt;Tuple2&lt;Integer, Integer&gt;&gt; tp2It) <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                ArrayList&lt;Tuple2&lt;Integer, Integer&gt;&gt; tuple2s = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">                <span class="keyword">while</span> (tp2It.hasNext())&#123;</span><br><span class="line">                    Tuple2&lt;Integer, Integer&gt; next = tp2It.next();</span><br><span class="line">                    tuple2s.add(<span class="keyword">new</span> Tuple2&lt;Integer, Integer&gt;(next._1,next._2*next._2));</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">return</span> tuple2s;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        tuple2JavaRDD.foreach(<span class="keyword">new</span> VoidFunction&lt;Tuple2&lt;Integer, Integer&gt;&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">call</span><span class="params">(Tuple2&lt;Integer, Integer&gt; tp2)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                System.out.println(tp2);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">-----------------输出---------------</span><br><span class="line">(<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">(<span class="number">1</span>,<span class="number">4</span>)</span><br><span class="line">(<span class="number">1</span>,<span class="number">9</span>)</span><br><span class="line">(<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">(<span class="number">2</span>,<span class="number">4</span>)</span><br><span class="line">(<span class="number">2</span>,<span class="number">9</span>)</span><br></pre></td></tr></table></figure></p>
<h2 id="mapPartitionsWithIndex"><a href="#mapPartitionsWithIndex" class="headerlink" title="mapPartitionsWithIndex"></a>mapPartitionsWithIndex</h2><p>与mapPartitionWithIndex类似，也是按照分区进行的map操作，不过mapPartitionsWithIndex传入的参数多了一个分区的值，下面举个例子,为统计各个分区中的元素 (稍加修改可以做统计各个分区的数量)</p>
<p><strong>java</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;Integer&gt; rdd = sc.parallelize(Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>), <span class="number">3</span>);</span><br><span class="line">        JavaRDD&lt;Tuple2&lt;Integer, Integer&gt;&gt; tuple2JavaRDD = rdd.mapPartitionsWithIndex(<span class="keyword">new</span> Function2&lt;Integer, Iterator&lt;Integer&gt;, Iterator&lt;Tuple2&lt;Integer, Integer&gt;&gt;&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> Iterator&lt;Tuple2&lt;Integer, Integer&gt;&gt; call(Integer partIndex, Iterator&lt;Integer&gt; it) <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                ArrayList&lt;Tuple2&lt;Integer, Integer&gt;&gt; tuple2s = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">                <span class="keyword">while</span> (it.hasNext()) &#123;</span><br><span class="line">                    <span class="keyword">int</span> next = it.next();</span><br><span class="line">                    tuple2s.add(<span class="keyword">new</span> Tuple2&lt;&gt;(partIndex, next));</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">return</span> tuple2s.iterator();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;, <span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line">        tuple2JavaRDD.foreach(<span class="keyword">new</span> VoidFunction&lt;Tuple2&lt;Integer, Integer&gt;&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">call</span><span class="params">(Tuple2&lt;Integer, Integer&gt; tp2)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                System.out.println(tp2);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">-------输出-------------</span><br><span class="line">(<span class="number">0</span>,<span class="number">1</span>)</span><br><span class="line">(<span class="number">0</span>,<span class="number">2</span>)</span><br><span class="line">(<span class="number">0</span>,<span class="number">3</span>)</span><br><span class="line">(<span class="number">1</span>,<span class="number">4</span>)</span><br><span class="line">(<span class="number">1</span>,<span class="number">5</span>)</span><br><span class="line">(<span class="number">1</span>,<span class="number">6</span>)</span><br><span class="line">(<span class="number">2</span>,<span class="number">7</span>)</span><br><span class="line">(<span class="number">2</span>,<span class="number">8</span>)</span><br><span class="line">(<span class="number">2</span>,<span class="number">9</span>)</span><br><span class="line">(<span class="number">2</span>,<span class="number">10</span>)</span><br></pre></td></tr></table></figure></p>
<p><strong>scala</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">    <span class="keyword">val</span> rdd = sc.parallelize(<span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">10</span>),<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mapPartIndexFunc</span></span>(i1:<span class="type">Int</span>,iter: <span class="type">Iterator</span>[<span class="type">Int</span>]):<span class="type">Iterator</span>[(<span class="type">Int</span>,<span class="type">Int</span>)]=&#123;</span><br><span class="line">      <span class="keyword">var</span> res = <span class="type">List</span>[(<span class="type">Int</span>,<span class="type">Int</span>)]()</span><br><span class="line">      <span class="keyword">while</span>(iter.hasNext)&#123;</span><br><span class="line">        <span class="keyword">var</span> next = iter.next()</span><br><span class="line">        res=res.::(i1,next)</span><br><span class="line">      &#125;</span><br><span class="line">      res.iterator</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">var</span> mapPartIndexRDDs = rdd.mapPartitionsWithIndex(mapPartIndexFunc)</span><br><span class="line"></span><br><span class="line">    mapPartIndexRDDs.foreach(println( _))</span><br><span class="line">------------输出-------</span><br><span class="line">(<span class="number">0</span>,<span class="number">3</span>)</span><br><span class="line">(<span class="number">0</span>,<span class="number">2</span>)</span><br><span class="line">(<span class="number">0</span>,<span class="number">1</span>)</span><br><span class="line">(<span class="number">1</span>,<span class="number">6</span>)</span><br><span class="line">(<span class="number">1</span>,<span class="number">5</span>)</span><br><span class="line">(<span class="number">1</span>,<span class="number">4</span>)</span><br><span class="line">(<span class="number">2</span>,<span class="number">10</span>)</span><br><span class="line">(<span class="number">2</span>,<span class="number">9</span>)</span><br><span class="line">(<span class="number">2</span>,<span class="number">8</span>)</span><br><span class="line">(<span class="number">2</span>,<span class="number">7</span>)</span><br></pre></td></tr></table></figure></p>
<p><strong>mapPartitionsWithIndex 统计键值对中的各个分区的元素</strong><br><strong>scala版本</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> rdd = sc.parallelize(<span class="type">List</span>((<span class="number">1</span>,<span class="number">1</span>), (<span class="number">1</span>,<span class="number">2</span>), (<span class="number">2</span>,<span class="number">3</span>), (<span class="number">2</span>,<span class="number">4</span>), (<span class="number">3</span>,<span class="number">5</span>), (<span class="number">3</span>,<span class="number">6</span>),(<span class="number">4</span>,<span class="number">7</span>), (<span class="number">4</span>,<span class="number">8</span>),(<span class="number">5</span>,<span class="number">9</span>), (<span class="number">5</span>,<span class="number">10</span>)),<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mapPartIndexFunc</span></span>(i1:<span class="type">Int</span>,iter: <span class="type">Iterator</span>[(<span class="type">Int</span>,<span class="type">Int</span>)]):<span class="type">Iterator</span>[(<span class="type">Int</span>,(<span class="type">Int</span>,<span class="type">Int</span>))]=&#123;</span><br><span class="line">      <span class="keyword">var</span> res = <span class="type">List</span>[(<span class="type">Int</span>,(<span class="type">Int</span>,<span class="type">Int</span>))]()</span><br><span class="line">      <span class="keyword">while</span>(iter.hasNext)&#123;</span><br><span class="line">        <span class="keyword">var</span> next = iter.next()</span><br><span class="line">        res=res.::(i1,next)</span><br><span class="line">      &#125;</span><br><span class="line">      res.iterator</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">val</span> mapPartIndexRDD = rdd.mapPartitionsWithIndex(mapPartIndexFunc)</span><br><span class="line"></span><br><span class="line">    mapPartIndexRDD.foreach(println( _))</span><br><span class="line">-----------输出---------</span><br><span class="line">(<span class="number">0</span>,(<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line">(<span class="number">0</span>,(<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line">(<span class="number">0</span>,(<span class="number">2</span>,<span class="number">3</span>))</span><br><span class="line">(<span class="number">1</span>,(<span class="number">2</span>,<span class="number">4</span>))</span><br><span class="line">(<span class="number">1</span>,(<span class="number">3</span>,<span class="number">5</span>))</span><br><span class="line">(<span class="number">1</span>,(<span class="number">3</span>,<span class="number">6</span>))</span><br><span class="line">(<span class="number">2</span>,(<span class="number">4</span>,<span class="number">7</span>))</span><br><span class="line">(<span class="number">2</span>,(<span class="number">4</span>,<span class="number">8</span>))</span><br><span class="line">(<span class="number">2</span>,(<span class="number">5</span>,<span class="number">9</span>))</span><br><span class="line">(<span class="number">2</span>,(<span class="number">5</span>,<span class="number">10</span>))</span><br></pre></td></tr></table></figure></p>
<p><strong>java版本</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">        JavaRDD&lt;Tuple2&lt;Integer, Integer&gt;&gt; rdd = sc.parallelize(Arrays.asList(<span class="keyword">new</span> Tuple2&lt;Integer, Integer&gt;(<span class="number">1</span>, <span class="number">1</span>), <span class="keyword">new</span> Tuple2&lt;Integer, Integer&gt;(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">                , <span class="keyword">new</span> Tuple2&lt;Integer, Integer&gt;(<span class="number">2</span>, <span class="number">3</span>), <span class="keyword">new</span> Tuple2&lt;Integer, Integer&gt;(<span class="number">2</span>, <span class="number">4</span>)</span><br><span class="line">                , <span class="keyword">new</span> Tuple2&lt;Integer, Integer&gt;(<span class="number">3</span>, <span class="number">5</span>), <span class="keyword">new</span> Tuple2&lt;Integer, Integer&gt;(<span class="number">3</span>, <span class="number">6</span>)</span><br><span class="line">                , <span class="keyword">new</span> Tuple2&lt;Integer, Integer&gt;(<span class="number">4</span>, <span class="number">7</span>), <span class="keyword">new</span> Tuple2&lt;Integer, Integer&gt;(<span class="number">4</span>, <span class="number">8</span>)</span><br><span class="line">                , <span class="keyword">new</span> Tuple2&lt;Integer, Integer&gt;(<span class="number">5</span>, <span class="number">9</span>), <span class="keyword">new</span> Tuple2&lt;Integer, Integer&gt;(<span class="number">5</span>, <span class="number">10</span>)</span><br><span class="line">                ), <span class="number">3</span>);</span><br><span class="line">        JavaPairRDD&lt;Integer, Integer&gt; pairRDD = JavaPairRDD.fromJavaRDD(rdd);</span><br><span class="line"></span><br><span class="line">        JavaRDD&lt;Tuple2&lt;Integer, Tuple2&lt;Integer, Integer&gt;&gt;&gt; mapPartitionIndexRDD = pairRDD.mapPartitionsWithIndex(<span class="keyword">new</span> Function2&lt;Integer, Iterator&lt;Tuple2&lt;Integer, Integer&gt;&gt;, Iterator&lt;Tuple2&lt;Integer, Tuple2&lt;Integer, Integer&gt;&gt;&gt;&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> Iterator&lt;Tuple2&lt;Integer, Tuple2&lt;Integer, Integer&gt;&gt;&gt; call(Integer partIndex, Iterator&lt;Tuple2&lt;Integer, Integer&gt;&gt; tuple2Iterator) &#123;</span><br><span class="line">                ArrayList&lt;Tuple2&lt;Integer, Tuple2&lt;Integer, Integer&gt;&gt;&gt; tuple2s = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line"></span><br><span class="line">                <span class="keyword">while</span> (tuple2Iterator.hasNext()) &#123;</span><br><span class="line">                    Tuple2&lt;Integer, Integer&gt; next = tuple2Iterator.next();</span><br><span class="line">                    tuple2s.add(<span class="keyword">new</span> Tuple2&lt;Integer, Tuple2&lt;Integer, Integer&gt;&gt;(partIndex, next));</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">return</span> tuple2s.iterator();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;, <span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line">        mapPartitionIndexRDD.foreach(<span class="keyword">new</span> VoidFunction&lt;Tuple2&lt;Integer, Tuple2&lt;Integer, Integer&gt;&gt;&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">call</span><span class="params">(Tuple2&lt;Integer, Tuple2&lt;Integer, Integer&gt;&gt; integerTuple2Tuple2)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                System.out.println(integerTuple2Tuple2);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">--------------输出---------</span><br><span class="line">(<span class="number">0</span>,(<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line">(<span class="number">0</span>,(<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line">(<span class="number">0</span>,(<span class="number">2</span>,<span class="number">3</span>))</span><br><span class="line">(<span class="number">1</span>,(<span class="number">2</span>,<span class="number">4</span>))</span><br><span class="line">(<span class="number">1</span>,(<span class="number">3</span>,<span class="number">5</span>))</span><br><span class="line">(<span class="number">1</span>,(<span class="number">3</span>,<span class="number">6</span>))</span><br><span class="line">(<span class="number">2</span>,(<span class="number">4</span>,<span class="number">7</span>))</span><br><span class="line">(<span class="number">2</span>,(<span class="number">4</span>,<span class="number">8</span>))</span><br><span class="line">(<span class="number">2</span>,(<span class="number">5</span>,<span class="number">9</span>))</span><br><span class="line">(<span class="number">2</span>,(<span class="number">5</span>,<span class="number">10</span>))</span><br></pre></td></tr></table></figure></p>
<p>mapPartitionsWithIndex 中 第二个参数，true还是false<br>这篇文章有些探讨,<a href="http://stackoverflow.com/questions/38048904/how-to-use-function-mappartitionswithindex-in-spark/38049239" target="_blank" rel="noopener">http://stackoverflow.com/questions/38048904/how-to-use-function-mappartitionswithindex-in-spark/38049239</a>，个人还未理解 TODO</p>
<p>补充： 打印各个分区的操作，可以使用 glom 的方法<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;Tuple2&lt;Integer, Integer&gt;&gt; rdd1 = sc.parallelize(Arrays.asList(<span class="keyword">new</span> Tuple2&lt;Integer, Integer&gt;(<span class="number">1</span>, <span class="number">1</span>), <span class="keyword">new</span> Tuple2&lt;Integer, Integer&gt;(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">                , <span class="keyword">new</span> Tuple2&lt;Integer, Integer&gt;(<span class="number">2</span>, <span class="number">3</span>), <span class="keyword">new</span> Tuple2&lt;Integer, Integer&gt;(<span class="number">2</span>, <span class="number">4</span>)</span><br><span class="line">                , <span class="keyword">new</span> Tuple2&lt;Integer, Integer&gt;(<span class="number">3</span>, <span class="number">5</span>), <span class="keyword">new</span> Tuple2&lt;Integer, Integer&gt;(<span class="number">3</span>, <span class="number">6</span>)</span><br><span class="line">                , <span class="keyword">new</span> Tuple2&lt;Integer, Integer&gt;(<span class="number">4</span>, <span class="number">7</span>), <span class="keyword">new</span> Tuple2&lt;Integer, Integer&gt;(<span class="number">4</span>, <span class="number">8</span>)</span><br><span class="line">                , <span class="keyword">new</span> Tuple2&lt;Integer, Integer&gt;(<span class="number">5</span>, <span class="number">9</span>), <span class="keyword">new</span> Tuple2&lt;Integer, Integer&gt;(<span class="number">5</span>, <span class="number">10</span>)</span><br><span class="line">        ), <span class="number">3</span>);</span><br><span class="line">        JavaPairRDD&lt;Integer, Integer&gt; pairRDD = JavaPairRDD.fromJavaRDD(rdd1);</span><br><span class="line">        <span class="comment">/*补充：打印各个分区的操作，可以使用 glom 的方法*/</span></span><br><span class="line">        System.out.println(<span class="string">"打印各个分区的操作，可以使用 glom 的方法"</span>);</span><br><span class="line">        JavaRDD&lt;List&lt;Tuple2&lt;Integer, Integer&gt;&gt;&gt; glom = pairRDD.glom();</span><br><span class="line">        glom.foreach(<span class="keyword">new</span> VoidFunction&lt;List&lt;Tuple2&lt;Integer, Integer&gt;&gt;&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">call</span><span class="params">(List&lt;Tuple2&lt;Integer, Integer&gt;&gt; tuple2s)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                System.out.println(tuple2s);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">//************************* 输出 </span></span><br><span class="line">打印各个分区的操作，可以使用 glom 的方法</span><br><span class="line">[(<span class="number">1</span>,<span class="number">1</span>), (<span class="number">1</span>,<span class="number">2</span>), (<span class="number">2</span>,<span class="number">3</span>)]</span><br><span class="line">[(<span class="number">2</span>,<span class="number">4</span>), (<span class="number">3</span>,<span class="number">5</span>), (<span class="number">3</span>,<span class="number">6</span>)]</span><br><span class="line">[(<span class="number">4</span>,<span class="number">7</span>), (<span class="number">4</span>,<span class="number">8</span>), (<span class="number">5</span>,<span class="number">9</span>), (<span class="number">5</span>,<span class="number">10</span>)]</span><br></pre></td></tr></table></figure></p>
<hr>
<h1 id="RDD-分区-HashPartitioner，RangePartitioner，自定义分区"><a href="#RDD-分区-HashPartitioner，RangePartitioner，自定义分区" class="headerlink" title="RDD 分区 HashPartitioner，RangePartitioner，自定义分区"></a>RDD 分区 HashPartitioner，RangePartitioner，自定义分区</h1><p><strong>关键字:</strong> spark分区方式，java HashPartitioner分区，scala HashPartitioner分区， java RangePartitioner 分区，scala RangePartitioner分区， java 自定义分区，scala自定义分区</p>
<h2 id="默认分区和HashPartitioner分区"><a href="#默认分区和HashPartitioner分区" class="headerlink" title="默认分区和HashPartitioner分区"></a>默认分区和HashPartitioner分区</h2><p>默认的分区就是HashPartition分区,默认分区不再介绍，下面介绍HashPartition的使用</p>
<p>通过上一章 mapPartitionsWithIndex的例子，我们可以构建一个方法，用来查看RDD的分区<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mapPartIndexFunc</span></span>(i1:<span class="type">Int</span>,iter: <span class="type">Iterator</span>[(<span class="type">Int</span>,<span class="type">Int</span>)]):<span class="type">Iterator</span>[(<span class="type">Int</span>,(<span class="type">Int</span>,<span class="type">Int</span>))]=&#123;</span><br><span class="line">  <span class="keyword">var</span> res = <span class="type">List</span>[(<span class="type">Int</span>,(<span class="type">Int</span>,<span class="type">Int</span>))]()</span><br><span class="line">  <span class="keyword">while</span>(iter.hasNext)&#123;</span><br><span class="line">    <span class="keyword">var</span> next = iter.next()</span><br><span class="line">    res=res.::(i1,next)</span><br><span class="line">  &#125;</span><br><span class="line">  res.iterator</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printRDDPart</span></span>(rdd:<span class="type">RDD</span>[(<span class="type">Int</span>,<span class="type">Int</span>)]): <span class="type">Unit</span> =&#123;</span><br><span class="line">  <span class="keyword">var</span> mapPartIndexRDDs = rdd.mapPartitionsWithIndex(mapPartIndexFunc)</span><br><span class="line">  mapPartIndexRDDs.foreach(println( _))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><strong>HashPartitioner分区 scala</strong><br>使用pairRdd.partitionBy(new spark.HashPartitioner(n)), 可以分为n个区<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">    <span class="keyword">var</span> pairRdd = sc.parallelize(<span class="type">List</span>((<span class="number">1</span>,<span class="number">1</span>), (<span class="number">1</span>,<span class="number">2</span>), (<span class="number">2</span>,<span class="number">3</span>), (<span class="number">2</span>,<span class="number">4</span>), (<span class="number">3</span>,<span class="number">5</span>), (<span class="number">3</span>,<span class="number">6</span>),(<span class="number">4</span>,<span class="number">7</span>), (<span class="number">4</span>,<span class="number">8</span>),(<span class="number">5</span>,<span class="number">9</span>), (<span class="number">5</span>,<span class="number">10</span>)))</span><br><span class="line">    <span class="comment">//未分区的输出</span></span><br><span class="line">    printRDDPart(pairRdd)</span><br><span class="line">    println(<span class="string">"========================="</span>)</span><br><span class="line">    <span class="keyword">val</span> partitioned = pairRdd.partitionBy(<span class="keyword">new</span> spark.<span class="type">HashPartitioner</span>(<span class="number">3</span>))</span><br><span class="line">    <span class="comment">//分区后的输出</span></span><br><span class="line">    printRDDPart(partitioned)</span><br><span class="line">-----------输出------------</span><br><span class="line">(<span class="number">0</span>,(<span class="number">5</span>,<span class="number">10</span>))</span><br><span class="line">(<span class="number">0</span>,(<span class="number">5</span>,<span class="number">9</span>))</span><br><span class="line">(<span class="number">0</span>,(<span class="number">4</span>,<span class="number">8</span>))</span><br><span class="line">(<span class="number">0</span>,(<span class="number">4</span>,<span class="number">7</span>))</span><br><span class="line">(<span class="number">0</span>,(<span class="number">3</span>,<span class="number">6</span>))</span><br><span class="line">(<span class="number">0</span>,(<span class="number">3</span>,<span class="number">5</span>))</span><br><span class="line">(<span class="number">0</span>,(<span class="number">2</span>,<span class="number">4</span>))</span><br><span class="line">(<span class="number">0</span>,(<span class="number">2</span>,<span class="number">3</span>))</span><br><span class="line">(<span class="number">0</span>,(<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line">(<span class="number">0</span>,(<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line">=========================</span><br><span class="line">(<span class="number">0</span>,(<span class="number">3</span>,<span class="number">6</span>))</span><br><span class="line">(<span class="number">0</span>,(<span class="number">3</span>,<span class="number">5</span>))</span><br><span class="line">(<span class="number">1</span>,(<span class="number">4</span>,<span class="number">8</span>))</span><br><span class="line">(<span class="number">1</span>,(<span class="number">4</span>,<span class="number">7</span>))</span><br><span class="line">(<span class="number">1</span>,(<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line">(<span class="number">1</span>,(<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line">(<span class="number">2</span>,(<span class="number">5</span>,<span class="number">10</span>))</span><br><span class="line">(<span class="number">2</span>,(<span class="number">5</span>,<span class="number">9</span>))</span><br><span class="line">(<span class="number">2</span>,(<span class="number">2</span>,<span class="number">4</span>))</span><br><span class="line">(<span class="number">2</span>,(<span class="number">2</span>,<span class="number">3</span>))</span><br></pre></td></tr></table></figure></p>
<p><strong>HashPartitioner是如何分区的：</strong> 国内很多说法都是有问题的，参考国外的一个说法 Uses Java’s Object.hashCodemethod to determine the partition as partition = key.hashCode() % numPartitions. 翻译过来就是使用java对象的hashCode来决定是哪个分区，对于piarRDD, 分区就是key.hashCode() % numPartitions, 3%3=0，所以 (3,6) 这个元素在0 分区， 4%3=1，所以元素(4,8) 在1 分区。 </p>
<h2 id="RangePartitioner"><a href="#RangePartitioner" class="headerlink" title="RangePartitioner"></a>RangePartitioner</h2><p>我理解成范围分区器<br>使用一个范围，将范围内的键分配给相应的分区。这种方法适用于键中有自然排序，键不为负。本文主要介绍如何使用，原理以后再仔细研究,以下代码片段显示了RangePartitioner的用法</p>
<p><strong>RangePartitioner 分区 scala</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">    <span class="keyword">var</span> pairRdd = sc.parallelize(<span class="type">List</span>((<span class="number">1</span>,<span class="number">1</span>), (<span class="number">5</span>,<span class="number">10</span>), (<span class="number">5</span>,<span class="number">9</span>), (<span class="number">2</span>,<span class="number">4</span>), (<span class="number">3</span>,<span class="number">5</span>), (<span class="number">3</span>,<span class="number">6</span>),(<span class="number">4</span>,<span class="number">7</span>), (<span class="number">4</span>,<span class="number">8</span>),(<span class="number">2</span>,<span class="number">3</span>), (<span class="number">1</span>,<span class="number">2</span>)))</span><br><span class="line">    printRDDPart(pairRdd)</span><br><span class="line">    println(<span class="string">"========================="</span>)</span><br><span class="line">    <span class="keyword">val</span> partitioned = pairRdd.partitionBy(<span class="keyword">new</span> <span class="type">RangePartitioner</span>(<span class="number">3</span>,pairRdd))</span><br><span class="line">    printRDDPart(partitioned)</span><br><span class="line">  &#125;</span><br><span class="line">-------------------输出------------------</span><br><span class="line">(<span class="number">0</span>,(<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line">(<span class="number">0</span>,(<span class="number">2</span>,<span class="number">3</span>))</span><br><span class="line">(<span class="number">0</span>,(<span class="number">4</span>,<span class="number">8</span>))</span><br><span class="line">(<span class="number">0</span>,(<span class="number">4</span>,<span class="number">7</span>))</span><br><span class="line">(<span class="number">0</span>,(<span class="number">3</span>,<span class="number">6</span>))</span><br><span class="line">(<span class="number">0</span>,(<span class="number">3</span>,<span class="number">5</span>))</span><br><span class="line">(<span class="number">0</span>,(<span class="number">2</span>,<span class="number">4</span>))</span><br><span class="line">(<span class="number">0</span>,(<span class="number">5</span>,<span class="number">9</span>))</span><br><span class="line">(<span class="number">0</span>,(<span class="number">5</span>,<span class="number">10</span>))</span><br><span class="line">(<span class="number">0</span>,(<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line">=========================</span><br><span class="line">(<span class="number">0</span>,(<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line">(<span class="number">0</span>,(<span class="number">2</span>,<span class="number">3</span>))</span><br><span class="line">(<span class="number">0</span>,(<span class="number">2</span>,<span class="number">4</span>))</span><br><span class="line">(<span class="number">0</span>,(<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line">(<span class="number">1</span>,(<span class="number">4</span>,<span class="number">8</span>))</span><br><span class="line">(<span class="number">1</span>,(<span class="number">4</span>,<span class="number">7</span>))</span><br><span class="line">(<span class="number">1</span>,(<span class="number">3</span>,<span class="number">6</span>))</span><br><span class="line">(<span class="number">1</span>,(<span class="number">3</span>,<span class="number">5</span>))</span><br><span class="line">(<span class="number">2</span>,(<span class="number">5</span>,<span class="number">9</span>))</span><br><span class="line">(<span class="number">2</span>,(<span class="number">5</span>,<span class="number">10</span>))</span><br></pre></td></tr></table></figure></p>
<p>上面的RDD生成的时候是乱的，但是我们让他分成三个范围，按照范围，key值为1,2的划分到第一个分区，key值为3，4的划分到第二个分区，key值为5的划分到第三个分区</p>
<h2 id="自定义分区"><a href="#自定义分区" class="headerlink" title="自定义分区"></a>自定义分区</h2><p>要实现自定义的分区器，你需要继承 org.apache.spark.Partitioner 类并实现下面三个方法 </p>
<ul>
<li><strong>numPartitions:</strong> Int：返回创建出来的分区数。 </li>
<li><strong>getPartition(key: Any):</strong> Int：返回给定键的分区编号（ 0 到 numPartitions-1）。<br>下面我自定义一个分区，让key大于等于4的落在第一个分区，key&gt;=2并且key&lt;4的落在第二个分区，其余的落在第一个分区。<br><strong>scala版本</strong><br>自定义分区器<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CustomPartitioner</span>(<span class="params">numParts: <span class="type">Int</span></span>) <span class="keyword">extends</span> <span class="title">Partitioner</span></span>&#123;</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">numPartitions</span></span>: <span class="type">Int</span> = numParts</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getPartition</span></span>(key: <span class="type">Any</span>): <span class="type">Int</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span>(key.toString.toInt&gt;=<span class="number">4</span>)&#123;</span><br><span class="line">       <span class="number">0</span></span><br><span class="line">    &#125;<span class="keyword">else</span> <span class="keyword">if</span>(key.toString.toInt&gt;=<span class="number">2</span>&amp;&amp;key.toString.toInt&lt;<span class="number">4</span>)&#123;</span><br><span class="line">      <span class="number">1</span></span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">      <span class="number">2</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>分区, 然后调用前面我们写的printRDDPart方法把各个分区中的RDD打印出来<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">    <span class="keyword">var</span> pairRdd = sc.parallelize(<span class="type">List</span>((<span class="number">1</span>,<span class="number">1</span>), (<span class="number">5</span>,<span class="number">10</span>), (<span class="number">5</span>,<span class="number">9</span>), (<span class="number">2</span>,<span class="number">4</span>), (<span class="number">3</span>,<span class="number">5</span>), (<span class="number">3</span>,<span class="number">6</span>),(<span class="number">4</span>,<span class="number">7</span>), (<span class="number">4</span>,<span class="number">8</span>),(<span class="number">2</span>,<span class="number">3</span>), (<span class="number">1</span>,<span class="number">2</span>)))</span><br><span class="line">    <span class="keyword">val</span> partitionedRdd = pairRdd.partitionBy(<span class="keyword">new</span> <span class="type">CustomPartitioner</span>(<span class="number">3</span>))</span><br><span class="line">    printRDDPart(partitionedRdd)</span><br><span class="line">----------输出-----------------</span><br><span class="line">(<span class="number">0</span>,(<span class="number">4</span>,<span class="number">8</span>))</span><br><span class="line">(<span class="number">0</span>,(<span class="number">4</span>,<span class="number">7</span>))</span><br><span class="line">(<span class="number">0</span>,(<span class="number">5</span>,<span class="number">9</span>))</span><br><span class="line">(<span class="number">0</span>,(<span class="number">5</span>,<span class="number">10</span>))</span><br><span class="line">(<span class="number">1</span>,(<span class="number">2</span>,<span class="number">3</span>))</span><br><span class="line">(<span class="number">1</span>,(<span class="number">3</span>,<span class="number">6</span>))</span><br><span class="line">(<span class="number">1</span>,(<span class="number">3</span>,<span class="number">5</span>))</span><br><span class="line">(<span class="number">1</span>,(<span class="number">2</span>,<span class="number">4</span>))</span><br><span class="line">(<span class="number">2</span>,(<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line">(<span class="number">2</span>,(<span class="number">1</span>,<span class="number">1</span>))</span><br></pre></td></tr></table></figure></p>
<h2 id="java-分区的用法"><a href="#java-分区的用法" class="headerlink" title="==java 分区的用法=="></a>==java 分区的用法==</h2><p>同样，写个方法，该方法能打印RDD下的每个分区下的各个元素</p>
<p><strong>打印每个分区下的各个元素的printPartRDD函数</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">printPartRDD</span><span class="params">(JavaPairRDD&lt;Integer, Integer&gt; pairRDD)</span> </span>&#123;</span><br><span class="line">    JavaRDD&lt;Tuple2&lt;Integer, Tuple2&lt;Integer, Integer&gt;&gt;&gt; mapPartitionIndexRDD = pairRDD.mapPartitionsWithIndex(<span class="keyword">new</span> Function2&lt;Integer, Iterator&lt;Tuple2&lt;Integer, Integer&gt;&gt;, Iterator&lt;Tuple2&lt;Integer, Tuple2&lt;Integer, Integer&gt;&gt;&gt;&gt;() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> Iterator&lt;Tuple2&lt;Integer, Tuple2&lt;Integer, Integer&gt;&gt;&gt; call(Integer partIndex, Iterator&lt;Tuple2&lt;Integer, Integer&gt;&gt; tuple2Iterator) &#123;</span><br><span class="line">            ArrayList&lt;Tuple2&lt;Integer, Tuple2&lt;Integer, Integer&gt;&gt;&gt; tuple2s = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line"></span><br><span class="line">            <span class="keyword">while</span> (tuple2Iterator.hasNext()) &#123;</span><br><span class="line">                Tuple2&lt;Integer, Integer&gt; next = tuple2Iterator.next();</span><br><span class="line">                tuple2s.add(<span class="keyword">new</span> Tuple2&lt;Integer, Tuple2&lt;Integer, Integer&gt;&gt;(partIndex, next));</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> tuple2s.iterator();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;, <span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line">    mapPartitionIndexRDD.foreach(<span class="keyword">new</span> VoidFunction&lt;Tuple2&lt;Integer, Tuple2&lt;Integer, Integer&gt;&gt;&gt;() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">call</span><span class="params">(Tuple2&lt;Integer, Tuple2&lt;Integer, Integer&gt;&gt; integerTuple2Tuple2)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">            System.out.println(integerTuple2Tuple2);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><strong>java HashPartitioner 分区</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">        JavaRDD&lt;Tuple2&lt;Integer, Integer&gt;&gt; tupRdd = sc.parallelize(Arrays.asList(<span class="keyword">new</span> Tuple2&lt;Integer, Integer&gt;(<span class="number">1</span>, <span class="number">1</span>), <span class="keyword">new</span> Tuple2&lt;Integer, Integer&gt;(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">                , <span class="keyword">new</span> Tuple2&lt;Integer, Integer&gt;(<span class="number">2</span>, <span class="number">3</span>), <span class="keyword">new</span> Tuple2&lt;Integer, Integer&gt;(<span class="number">2</span>, <span class="number">4</span>)</span><br><span class="line">                , <span class="keyword">new</span> Tuple2&lt;Integer, Integer&gt;(<span class="number">3</span>, <span class="number">5</span>), <span class="keyword">new</span> Tuple2&lt;Integer, Integer&gt;(<span class="number">3</span>, <span class="number">6</span>)</span><br><span class="line">                , <span class="keyword">new</span> Tuple2&lt;Integer, Integer&gt;(<span class="number">4</span>, <span class="number">7</span>), <span class="keyword">new</span> Tuple2&lt;Integer, Integer&gt;(<span class="number">4</span>, <span class="number">8</span>)</span><br><span class="line">                , <span class="keyword">new</span> Tuple2&lt;Integer, Integer&gt;(<span class="number">5</span>, <span class="number">9</span>), <span class="keyword">new</span> Tuple2&lt;Integer, Integer&gt;(<span class="number">5</span>, <span class="number">10</span>)</span><br><span class="line">        ), <span class="number">3</span>);</span><br><span class="line">        JavaPairRDD&lt;Integer, Integer&gt; pairRDD = JavaPairRDD.fromJavaRDD(tupRdd);</span><br><span class="line"></span><br><span class="line">        JavaPairRDD&lt;Integer, Integer&gt; partitioned = pairRDD.partitionBy(<span class="keyword">new</span> HashPartitioner(<span class="number">3</span>));</span><br><span class="line">        System.out.println(<span class="string">"============HashPartitioner=================="</span>);</span><br><span class="line">        printPartRDD(partitioned);</span><br><span class="line">--------------打印--------------------</span><br><span class="line">============HashPartitioner==================</span><br><span class="line">(<span class="number">0</span>,(<span class="number">3</span>,<span class="number">5</span>))</span><br><span class="line">(<span class="number">0</span>,(<span class="number">3</span>,<span class="number">6</span>))</span><br><span class="line">(<span class="number">1</span>,(<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line">(<span class="number">1</span>,(<span class="number">4</span>,<span class="number">8</span>))</span><br><span class="line">(<span class="number">1</span>,(<span class="number">4</span>,<span class="number">7</span>))</span><br><span class="line">(<span class="number">1</span>,(<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line">(<span class="number">2</span>,(<span class="number">5</span>,<span class="number">10</span>))</span><br><span class="line">(<span class="number">2</span>,(<span class="number">2</span>,<span class="number">4</span>))</span><br><span class="line">(<span class="number">2</span>,(<span class="number">2</span>,<span class="number">3</span>))</span><br><span class="line">(<span class="number">2</span>,(<span class="number">5</span>,<span class="number">9</span>))</span><br></pre></td></tr></table></figure></p>
<p><strong>java 自定义分区</strong><br><strong>自定义分区器</strong> ，key大于4的落在第一个分区，[2,4)之间的落在第二个分区，其余的落在第三个分区<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JavaCustomPart</span>  <span class="keyword">extends</span> <span class="title">Partitioner</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i = <span class="number">1</span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">JavaCustomPart</span><span class="params">(<span class="keyword">int</span> i)</span></span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.i=i;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">JavaCustomPart</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">numPartitions</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> i;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getPartition</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> keyCode = Integer.parseInt(key.toString());</span><br><span class="line">        <span class="keyword">if</span>(keyCode&gt;=<span class="number">4</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span>(keyCode&gt;=<span class="number">2</span>&amp;&amp;keyCode&lt;<span class="number">4</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">2</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><strong>分区并打印</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">        System.out.println(<span class="string">"============CustomPartition=================="</span>);</span><br><span class="line">        JavaPairRDD&lt;Integer, Integer&gt; customPart = pairRDD.partitionBy(<span class="keyword">new</span> JavaCustomPart(<span class="number">3</span>));</span><br><span class="line">        printPartRDD(customPart);</span><br><span class="line">--------------打印---------------</span><br><span class="line">============CustomPartition==================</span><br><span class="line">(<span class="number">0</span>,(<span class="number">5</span>,<span class="number">10</span>))</span><br><span class="line">(<span class="number">0</span>,(<span class="number">4</span>,<span class="number">8</span>))</span><br><span class="line">(<span class="number">0</span>,(<span class="number">4</span>,<span class="number">7</span>))</span><br><span class="line">(<span class="number">0</span>,(<span class="number">5</span>,<span class="number">9</span>))</span><br><span class="line">(<span class="number">1</span>,(<span class="number">2</span>,<span class="number">4</span>))</span><br><span class="line">(<span class="number">1</span>,(<span class="number">3</span>,<span class="number">5</span>))</span><br><span class="line">(<span class="number">1</span>,(<span class="number">3</span>,<span class="number">6</span>))</span><br><span class="line">(<span class="number">1</span>,(<span class="number">2</span>,<span class="number">3</span>))</span><br><span class="line">(<span class="number">2</span>,(<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line">(<span class="number">2</span>,(<span class="number">1</span>,<span class="number">1</span>))</span><br></pre></td></tr></table></figure></p>
<p><strong>java RangePartitioner</strong><br>TODO</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://ryanlic.github.io/RyanLi.github.io/2018/07/31/2018-07-31 Spark2-1-3集群搭建/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ryan Li">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/RyanLi.github.io/uploads/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ryan Li God">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/RyanLi.github.io/2018/07/31/2018-07-31 Spark2-1-3集群搭建/" itemprop="url">Spark学习笔记（六）：Spark 2.1.3集群搭建</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-07-31T15:03:43+10:00">
                2018-07-31
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="安装Spark包"><a href="#安装Spark包" class="headerlink" title="安装Spark包"></a>安装Spark包</h2><ol>
<li>将spark-2.1.3-bin-hadoop2.4.tgz使用SFTP上传到/usr/local目录下。</li>
<li><p>解压缩spark包：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar zxvf spark-2.1.3-bin-hadoop2.4.tgz</span><br></pre></td></tr></table></figure>
</li>
<li><p>更改spark目录名：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv spark-2.1.3-bin-hadoop2.4 spark</span><br></pre></td></tr></table></figure>
</li>
<li><p>设置spark环境变量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">vi .bashrc</span><br><span class="line">export SPARK_HOME=/usr/local/spark</span><br><span class="line">export PATH=$SPARK_HOME/bin</span><br><span class="line">export CLASSPATH=.:$CLASSPATH:$JAVA_HOME/lib:$JAVA_HOME/jre/lib</span><br><span class="line"></span><br><span class="line">source .bashrc</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="修改spark-env-sh文件"><a href="#修改spark-env-sh文件" class="headerlink" title="修改spark-env.sh文件"></a>修改spark-env.sh文件</h2><ol>
<li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/spark/conf</span><br></pre></td></tr></table></figure>
</li>
<li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp spark-env.sh.template spark-env.sh</span><br></pre></td></tr></table></figure>
</li>
<li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">vi spark-env.sh</span><br><span class="line">export JAVA_HOME=/usr/java/latest</span><br><span class="line">export SCALA_HOME=/usr/local/scala</span><br><span class="line">export SPARK_MASTER_IP=10.211.55.24</span><br><span class="line">export SPARK_WORKER_MEMORY=2g</span><br><span class="line">export HADOOP_CONF_DIR=/usr/local/hadoop/etc/hadoop</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="修改slaves文件"><a href="#修改slaves文件" class="headerlink" title="修改slaves文件"></a>修改slaves文件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">spark1</span><br><span class="line">spark2</span><br><span class="line">spark3</span><br></pre></td></tr></table></figure>
<h2 id="安装spark集群"><a href="#安装spark集群" class="headerlink" title="安装spark集群"></a>安装spark集群</h2><p>在另外两个节点进行一模一样的配置，使用scp将spark和.bashrc拷贝到spark2和spark3即可。</p>
<h2 id="启动spark集群"><a href="#启动spark集群" class="headerlink" title="启动spark集群"></a>启动spark集群</h2><ol>
<li>在spark目录下的sbin目录</li>
<li><p>执行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./start-all.sh</span><br></pre></td></tr></table></figure>
</li>
<li><p>使用jsp和8080端口可以检查集群是否启动成功</p>
</li>
<li>进入spark-shell查看是否正常</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://ryanlic.github.io/RyanLi.github.io/2018/07/31/2018-07-31 kafka-2-9-2-0-8-1集群搭建/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ryan Li">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/RyanLi.github.io/uploads/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ryan Li God">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/RyanLi.github.io/2018/07/31/2018-07-31 kafka-2-9-2-0-8-1集群搭建/" itemprop="url">Spark学习笔记（五）：Kafka 2.9.2-0.8.1集群搭建（包括scala安装）</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-07-31T14:41:58+10:00">
                2018-07-31
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="安装scala-2-11-8"><a href="#安装scala-2-11-8" class="headerlink" title="安装scala 2.11.8"></a>安装scala 2.11.8</h2><blockquote><p>注意，scala的版本和之后要安装的spark版本密切关联，必须要和spark/jars中的scala-compiler-2.11.8.jar版本一致，而且之后用IDE打包的时候，选择scala版本也要一致</p>
</blockquote>
<ol>
<li>将scala-2.11.8.tgz使用WinSCP拷贝到spark1的/usr/local目录下。</li>
<li><p>对scala-2.11.8.tgz进行解压缩：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf scala-2.11.8.tgz</span><br></pre></td></tr></table></figure>
</li>
<li><p>对scala目录进行重命名：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv scala-2.11.8 scala</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置scala相关的环境变量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vi .bashrc</span><br><span class="line">export SCALA_HOME=/usr/local/scala</span><br><span class="line">export PATH=$SCALA_HOME/bin</span><br><span class="line"></span><br><span class="line">source .bashrc</span><br></pre></td></tr></table></figure>
</li>
<li><p>查看scala是否安装成功：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scala -version</span><br></pre></td></tr></table></figure>
</li>
<li><p>按照上述步骤在spark2和spark3机器上都安装好scala。使用scp将scala和.bashrc拷贝到spark2和spark3上即可</p>
</li>
</ol>
<h2 id="安装Kafka包"><a href="#安装Kafka包" class="headerlink" title="安装Kafka包"></a>安装Kafka包</h2><ol>
<li>将kafka_2.9.2-0.8.1.tgz使用SFTP工具拷贝到spark1的/usr/local目录下</li>
<li><p>对kafka_2.9.2-0.8.1.tgz进行解压缩：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf kafka_2.9.2-0.8.1.tgz</span><br></pre></td></tr></table></figure>
</li>
<li><p>对kafka目录进行改名：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv kafka_2.9.2-0.8.1 kafka</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置kafka</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vi /usr/local/kafka/config/server.properties</span><br><span class="line"># broker.id：依次增长的整数，0、1、2、3、4，集群中Broker的唯一id</span><br><span class="line"></span><br><span class="line">zookeeper.connect=10.211.55.24:2181,10.211.55.25:2181,10.211.55.26:2181</span><br><span class="line"># 这里填写自己的 spark1:2181,spark2:2181,spark3:2181</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装slf4j<br>将slf4j-1.7.6.zip上传到/usr/local目录下，再把slf4j中的slf4j-nop-1.7.6.jar复制到kafka的libs目录下面</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">unzip slf4j-1.7.6.zip</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="搭建kafka集群"><a href="#搭建kafka集群" class="headerlink" title="搭建kafka集群"></a>搭建kafka集群</h2><ol>
<li>按照上述步骤在spark2和spark3分别安装kafka。用scp把kafka拷贝到spark2和spark3即可。</li>
<li>唯一区别的，就是server.properties中的broker.id，要设置为1和2</li>
</ol>
<h2 id="启动kafka集群"><a href="#启动kafka集群" class="headerlink" title="启动kafka集群"></a>启动kafka集群</h2><ol>
<li><p>在三台机器上分别执行以下命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup bin/kafka-server-start.sh config/server.properties &amp;</span><br></pre></td></tr></table></figure>
</li>
<li><p>使用jps检查启动是否成功</p>
</li>
</ol>
<h2 id="测试kafka集群"><a href="#测试kafka集群" class="headerlink" title="测试kafka集群"></a>测试kafka集群</h2><p>使用基本命令检查kafka是否搭建成功<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --zookeeper 10.211.55.24:2181,10.211.55.25:2181,10.211.55.26:2181 --topic TestTopic --replication-factor 1 --partitions 1 --create</span><br><span class="line"></span><br><span class="line">bin/kafka-console-producer.sh --broker-list 10.211.55.24:9092,10.211.55.25:9092,10.211.55.26:9092 --topic TestTopic</span><br><span class="line"></span><br><span class="line">bin/kafka-console-consumer.sh --zookeeper 10.211.55.24:2181,10.211.55.25:2181,10.211.55.26:2181 --topic TestTopic --from-beginning</span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://ryanlic.github.io/RyanLi.github.io/2018/07/31/2018-07-31 ZooKeeper3-4-5集群搭建/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ryan Li">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/RyanLi.github.io/uploads/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ryan Li God">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/RyanLi.github.io/2018/07/31/2018-07-31 ZooKeeper3-4-5集群搭建/" itemprop="url">Spark学习笔记（四）：ZooKeeper 3.4.5集群搭建</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-07-31T14:32:43+10:00">
                2018-07-31
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="安装ZooKeeper包"><a href="#安装ZooKeeper包" class="headerlink" title="安装ZooKeeper包"></a>安装ZooKeeper包</h2><ol>
<li>将zookeeper-3.4.5.tar.gz使用SFTP工具拷贝到spark1的/usr/local目录下</li>
<li><p>对zookeeper-3.4.5.tar.gz进行解压缩：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf zookeeper-3.4.5.tar.gz</span><br></pre></td></tr></table></figure>
</li>
<li><p>对zookeeper目录进行重命名：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv zookeeper-3.4.5 zk</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置zookeeper相关的环境变量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vi .bashrc</span><br><span class="line">export ZOOKEEPER_HOME=/usr/local/zk</span><br><span class="line">export PATH=$ZOOKEEPER_HOME/bin</span><br><span class="line">source .bashrc</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="配置zoo-cfg"><a href="#配置zoo-cfg" class="headerlink" title="配置zoo.cfg"></a>配置zoo.cfg</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cd zk/conf</span><br><span class="line">mv zoo_sample.cfg zoo.cfg</span><br><span class="line"></span><br><span class="line">vi zoo.cfg</span><br><span class="line">修改：dataDir=/usr/local/zk/data</span><br><span class="line">新增：</span><br><span class="line">server.0=spark1:2888:3888	</span><br><span class="line">server.1=spark2:2888:3888</span><br><span class="line">server.2=spark3:2888:3888</span><br></pre></td></tr></table></figure>
<h2 id="设置zk节点标识"><a href="#设置zk节点标识" class="headerlink" title="设置zk节点标识"></a>设置zk节点标识</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cd zk</span><br><span class="line">mkdir data</span><br><span class="line">cd data</span><br><span class="line"></span><br><span class="line">vi myid</span><br><span class="line">0</span><br></pre></td></tr></table></figure>
<h2 id="搭建zk集群"><a href="#搭建zk集群" class="headerlink" title="搭建zk集群"></a>搭建zk集群</h2><ol>
<li>在另外两个节点上按照上述步骤配置ZooKeeper，使用scp将zk和~/.bashrc拷贝到spark2和spark3上即可，记得source ~/.bashrc</li>
<li>唯一的区别是spark2和spark3的标识号分别设置为1和2</li>
</ol>
<h2 id="启动ZooKeeper集群"><a href="#启动ZooKeeper集群" class="headerlink" title="启动ZooKeeper集群"></a>启动ZooKeeper集群</h2><ol>
<li><p>分别在三台机器上执行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zkServer.sh start</span><br></pre></td></tr></table></figure>
</li>
<li><p>检查ZooKeeper状态：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zkServer.sh status</span><br></pre></td></tr></table></figure></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://ryanlic.github.io/RyanLi.github.io/2018/07/31/2018-07-31 Hive0-13搭建/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ryan Li">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/RyanLi.github.io/uploads/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ryan Li God">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/RyanLi.github.io/2018/07/31/2018-07-31 Hive0-13搭建/" itemprop="url">Spark学习笔记（三）：Hive 0.13搭建</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-07-31T14:24:55+10:00">
                2018-07-31
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="安装hive包"><a href="#安装hive包" class="headerlink" title="安装hive包"></a>安装hive包</h2><ol>
<li>将apache-hive-0.13.1-bin.tar.gz使用SFTP工具上传到spark1的/usr/local目录下。</li>
<li><p>解压缩hive安装包：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf apache-hive-0.13.1-bin.tar.gz</span><br></pre></td></tr></table></figure>
</li>
<li><p>重命名hive目录：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv apache-hive-0.13.1-bin hive</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置hive相关的环境变量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vi .bashrc</span><br><span class="line">export HIVE_HOME=/usr/local/hive</span><br><span class="line">export PATH=$HIVE_HOME/bin</span><br><span class="line">source .bashrc</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="安装mysql"><a href="#安装mysql" class="headerlink" title="安装mysql"></a>安装mysql</h2><ol>
<li>在spark1上安装mysql</li>
<li><p>使用yum安装mysql server</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yum install -y mysql-server</span><br><span class="line">service mysqld start</span><br><span class="line">chkconfig mysqld on</span><br></pre></td></tr></table></figure>
</li>
<li><p>使用yum安装mysql connector</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y mysql-connector-java</span><br></pre></td></tr></table></figure>
</li>
<li><p>将mysql connector拷贝到hive的lib包中</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp /usr/share/java/mysql-connector-java-5.1.17.jar /usr/local/hive/lib</span><br></pre></td></tr></table></figure>
</li>
<li><p>在mysql上创建hive元数据库，并对hive进行授权</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">create database if not exists hive_metadata;</span><br><span class="line">grant all privileges on hive_metadata.* to &apos;hive&apos;@&apos;%&apos; identified by &apos;hive&apos;;</span><br><span class="line">grant all privileges on hive_metadata.* to &apos;hive&apos;@&apos;localhost&apos; identified by &apos;hive&apos;;</span><br><span class="line">grant all privileges on hive_metadata.* to &apos;hive&apos;@&apos;spark1&apos; identified by &apos;hive&apos;;</span><br><span class="line">flush privileges;</span><br><span class="line">use hive_metadata;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="配置hive-site-xml"><a href="#配置hive-site-xml" class="headerlink" title="配置hive-site.xml"></a>配置hive-site.xml</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mv hive-default.xml.template hive-site.xml</span><br><span class="line">vi hive-site.xml</span><br></pre></td></tr></table></figure>
<p>更改如下项目：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;jdbc:mysql://spark1:3306/hive_metadata?createDatabaseIfNotExist=true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;hive&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;hive&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;/user/hive/warehouse&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></p>
<h2 id="配置hive-env-sh和hive-config-sh"><a href="#配置hive-env-sh和hive-config-sh" class="headerlink" title="配置hive-env.sh和hive-config.sh"></a>配置hive-env.sh和hive-config.sh</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mv hive-env.sh.template hive-env.sh</span><br><span class="line">vi /usr/local/hive/bin/hive-config.sh</span><br><span class="line"></span><br><span class="line">export JAVA_HOME=/usr/java/latest</span><br><span class="line">export HIVE_HOME=/usr/local/hive</span><br><span class="line">export HADOOP_HOME=/usr/local/hadoop</span><br></pre></td></tr></table></figure>
<h2 id="验证hive是否安装成功"><a href="#验证hive是否安装成功" class="headerlink" title="验证hive是否安装成功"></a>验证hive是否安装成功</h2><p>直接输入hive命令，可以进入hive命令行</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://ryanlic.github.io/RyanLi.github.io/2018/07/31/2018-07-31 Hadoop2-4-1集群搭建/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ryan Li">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/RyanLi.github.io/uploads/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ryan Li God">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/RyanLi.github.io/2018/07/31/2018-07-31 Hadoop2-4-1集群搭建/" itemprop="url">Spark学习笔记（二）：Hadoop 2.4.1集群搭建</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-07-31T13:32:07+10:00">
                2018-07-31
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="安装hadoop包"><a href="#安装hadoop包" class="headerlink" title="安装hadoop包"></a>安装hadoop包</h2><ol>
<li>下载好hadoop-2.4.1.tar.gz，使用SFTP工具上传到CentOS的/usr/local目录下</li>
<li><p>将hadoop包进行解压缩：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf hadoop-2.4.1.tar.gz</span><br></pre></td></tr></table></figure>
</li>
<li><p>对hadoop目录进行重命名：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv hadoop-2.4.1 hadoop</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置hadoop相关环境变量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vi .bashrc</span><br><span class="line">export HADOOP_HOME=/usr/local/hadoop</span><br><span class="line">export PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin</span><br><span class="line">source .bashrc</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="配置Hadoop"><a href="#配置Hadoop" class="headerlink" title="配置Hadoop"></a>配置Hadoop</h2><h3 id="修改core-site-xml"><a href="#修改core-site-xml" class="headerlink" title="修改core-site.xml"></a>修改core-site.xml</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;fs.default.name&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;hdfs://spark1:9000&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>
<h3 id="修改hdfs-site-xml"><a href="#修改hdfs-site-xml" class="headerlink" title="修改hdfs-site.xml"></a>修改hdfs-site.xml</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.name.dir&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;/usr/local/data/namenode&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.data.dir&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;/usr/local/data/datanode&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.tmp.dir&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;/usr/local/data/tmp&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;3&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>
<h3 id="修改mapred-site-xml"><a href="#修改mapred-site-xml" class="headerlink" title="修改mapred-site.xml"></a>修改mapred-site.xml</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>
<h3 id="修改yarn-site-xml"><a href="#修改yarn-site-xml" class="headerlink" title="修改yarn-site.xml"></a>修改yarn-site.xml</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;spark1&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>
<h3 id="修改slaves文件"><a href="#修改slaves文件" class="headerlink" title="修改slaves文件"></a>修改slaves文件</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">spark1</span><br><span class="line">spark2</span><br><span class="line">spark3</span><br></pre></td></tr></table></figure>
<h3 id="在另外两台机器上搭建hadoop"><a href="#在另外两台机器上搭建hadoop" class="headerlink" title="在另外两台机器上搭建hadoop"></a>在另外两台机器上搭建hadoop</h3><ol>
<li>使用如上配置在另外两台机器上搭建hadoop，可以使用scp命令将spark1上面的hadoop安装包和.bashrc配置文件都拷贝过去</li>
<li>要记得对.bashrc文件进行source，以让它生效</li>
<li>记得在spark2和spark3的/usr/local目录下创建data目录</li>
</ol>
<h2 id="启动hdfs集群"><a href="#启动hdfs集群" class="headerlink" title="启动hdfs集群"></a>启动hdfs集群</h2><ol>
<li><p>格式化namenode：在spark1上执行以下命令(不要执行多次，不然会导致datanode的ID不一致，以后都只要直接第二步):</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode -format</span><br></pre></td></tr></table></figure>
</li>
<li><p>启动hdfs集群：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-dfs.sh</span><br></pre></td></tr></table></figure>
</li>
<li><p>验证启动是否成功：jps、50070端口<br>spark1：namenode、datanode、secondarynamenode<br>spark2：datanode<br>spark3：datanode</p>
</li>
</ol>
<h2 id="启动yarn集群"><a href="#启动yarn集群" class="headerlink" title="启动yarn集群"></a>启动yarn集群</h2><ol>
<li><p>启动yarn集群：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/hadoop/sbin/start-yarn.sh</span><br></pre></td></tr></table></figure>
</li>
<li><p>验证启动是否成功：jps、8088端口<br>spark1：resourcemanager、nodemanager<br>spark2：nodemanager<br>spark3：nodemanager</p>
</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://ryanlic.github.io/RyanLi.github.io/2018/07/31/2018-07-31 CentOS6-5集群搭建/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ryan Li">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/RyanLi.github.io/uploads/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ryan Li God">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/RyanLi.github.io/2018/07/31/2018-07-31 CentOS6-5集群搭建/" itemprop="url">Spark学习笔记（一）：CentOS 6.5集群搭建</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-07-31T12:46:36+10:00">
                2018-07-31
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="运行环境"><a href="#运行环境" class="headerlink" title="运行环境"></a>运行环境</h2><ol>
<li>CentOS 6.5</li>
<li>JDK 1.7</li>
<li>Hadoop 2.4.1</li>
<li>Hive 0.13</li>
<li>ZooKeeper 3.4.5</li>
<li>kafka_2.9.2-0.8.1</li>
<li>Spark 2.1.3</li>
<li>scala 2.11.8</li>
</ol>
<h2 id="安装CentOS-6-5"><a href="#安装CentOS-6-5" class="headerlink" title="安装CentOS 6.5"></a>安装CentOS 6.5</h2><ol>
<li>在macOS下，使用<strong><em>Parallels Desktop</em></strong>直接安装，CentOS 6.5使用的只需要官网的一个DVD1.iso文件。</li>
<li>启动以后使用<strong><em>Termius</em></strong>连接三台机器，使用<strong><em>Transmit</em></strong>传文件。<h2 id="CentOS-6-5防火墙配置"><a href="#CentOS-6-5防火墙配置" class="headerlink" title="CentOS 6.5防火墙配置"></a>CentOS 6.5防火墙配置</h2>关闭防火墙<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">service iptables stop</span><br><span class="line">chkconfig iptables off</span><br><span class="line">vi /etc/selinux/config</span><br><span class="line">SELINUX=disabled</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="JDK-1-7安装"><a href="#JDK-1-7安装" class="headerlink" title="JDK 1.7安装"></a>JDK 1.7安装</h2><p>我下载的CentOS自带，所以不用安装，装之前用java -version测试是否自带JDK。</p>
<ol>
<li>将jdk-7u60-linux-i586.rpm通过WinSCP上传到虚拟机中</li>
<li><p>安装JDK：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpm -ivh jdk-7u65-linux-i586.rpm</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置jdk相关的环境变量</p>
</li>
<li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vi .bashrc</span><br><span class="line">export JAVA_HOME=/usr/java/latest</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br><span class="line">source .bashrc</span><br></pre></td></tr></table></figure>
</li>
<li><p>测试jdk安装是否成功：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -version</span><br></pre></td></tr></table></figure>
</li>
<li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rm -f /etc/udev/rules.d/70-persistent-net.rules</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="安装第二台和第三台虚拟机"><a href="#安装第二台和第三台虚拟机" class="headerlink" title="安装第二台和第三台虚拟机"></a>安装第二台和第三台虚拟机</h2><ol>
<li>安装上述步骤，再安装两台一模一样环境的虚拟机，因为后面hadoop和spark都是要搭建集群的。</li>
<li>集群的最小环境就是三台。因为后面要搭建ZooKeeper、kafka等集群。</li>
<li>另外两台机器的hostname分别设置为spark2和spark3即可，通过终端输入ifconfig查看ip，记下。</li>
<li><p>安装好之后，记得要在三台机器的/etc/hosts文件中，配置全三台机器的ip地址到hostname的映射，而不能只配置本机。比如我的：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[spark1@spark1 Desktop]$ cat /etc/hosts</span><br><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line">10.211.55.24 spark1</span><br><span class="line">10.211.55.25 spark2</span><br><span class="line">10.211.55.26 spark3</span><br></pre></td></tr></table></figure>
</li>
<li><p>mac中Parallels Desktop会自动配置到虚拟机的地址映射，开启虚拟机以后在mac中可以直接ssh root@spark1进行连接</p>
</li>
</ol>
<h2 id="配置集群ssh免密码登录"><a href="#配置集群ssh免密码登录" class="headerlink" title="配置集群ssh免密码登录"></a>配置集群ssh免密码登录</h2><ol>
<li><p>首先在三台机器上配置对本机的ssh免密码登录<br>生成本机的公钥，过程中不断敲回车即可，ssh-keygen命令默认会将公钥放在/root/.ssh目录下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa</span><br></pre></td></tr></table></figure>
</li>
<li><p>将公钥复制为authorized_keys文件，此时使用ssh连接本机就不需要输入密码了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /root/.ssh</span><br><span class="line">cp id_rsa.pub authorized_keys</span><br></pre></td></tr></table></figure>
</li>
<li><p>接着配置三台机器互相之间的ssh免密码登录，使用ssh-copy-id -i spark{N}命令将本机的公钥拷贝到指定机器的authorized_keys文件中：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@spark1 ~]# ssh-copy-id -i spark2</span><br><span class="line">[root@spark1 ~]# ssh-copy-id -i spark3</span><br><span class="line">[root@spark2 ~]# ssh-copy-id -i spark1</span><br><span class="line">[root@spark2 ~]# ssh-copy-id -i spark3</span><br><span class="line">[root@spark3 ~]# ssh-copy-id -i spark1</span><br><span class="line">[root@spark3 ~]# ssh-copy-id -i spark2</span><br></pre></td></tr></table></figure></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://ryanlic.github.io/RyanLi.github.io/2018/07/25/2018-07-25 启动Hadoop、Spark等环境步骤记录/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ryan Li">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/RyanLi.github.io/uploads/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ryan Li God">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/RyanLi.github.io/2018/07/25/2018-07-25 启动Hadoop、Spark等环境步骤记录/" itemprop="url">启动Hadoop、Spark等环境步骤记录</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-07-25T14:19:06+10:00">
                2018-07-25
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h2><ol>
<li><p>启动hdfs集群：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-dfs.sh</span><br></pre></td></tr></table></figure>
</li>
<li><p>验证启动是否成功：jps、50070端口<br>spark1：namenode、datanode、secondarynamenode<br>spark2：datanode<br>spark3：datanode</p>
</li>
</ol>
<h2 id="YARN"><a href="#YARN" class="headerlink" title="YARN"></a>YARN</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/hadoop/sbin/start-yarn.sh</span><br></pre></td></tr></table></figure>
<h2 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h2><p>在spark1中，直接输入:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive</span><br></pre></td></tr></table></figure></p>
<h2 id="ZooKeeper"><a href="#ZooKeeper" class="headerlink" title="ZooKeeper"></a>ZooKeeper</h2><ol>
<li><p>分别在三台机器上执行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zkServer.sh start</span><br></pre></td></tr></table></figure>
</li>
<li><p>检查ZooKeeper状态：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zkServer.sh status</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="kafka"><a href="#kafka" class="headerlink" title="kafka"></a>kafka</h2><ol>
<li><p>在三台机器上分别执行以下命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/kafka/</span><br></pre></td></tr></table></figure>
</li>
<li><p>执行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup bin/kafka-server-start.sh config/server.properties &amp;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h2><ol>
<li><p>在spark目录下的sbin目录</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/spark/sbin</span><br></pre></td></tr></table></figure>
</li>
<li><p>执行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./start-all.sh</span><br></pre></td></tr></table></figure>
</li>
<li><p>使用jsp和8080端口可以检查集群是否启动成功</p>
</li>
<li>进入spark-shell查看是否正常</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://ryanlic.github.io/RyanLi.github.io/2018/07/24/2018-07-24 MarkDown语法/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ryan Li">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/RyanLi.github.io/uploads/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ryan Li God">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/RyanLi.github.io/2018/07/24/2018-07-24 MarkDown语法/" itemprop="url">MarkDown语法</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-07-24T15:25:35+10:00">
                2018-07-24
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <h2 id="Markdown-的设计哲学"><a href="#Markdown-的设计哲学" class="headerlink" title="Markdown 的设计哲学"></a>Markdown 的设计哲学</h2><blockquote>
<p>Markdown 的目標是實現「易讀易寫」<br>不過最需要強調的便是它的可讀性。一份使用 Markdown 格式撰寫的文件應該可以直接以純文字發佈，並且看起來不會像是由許多標籤或是格式指令所構成。<br>Markdown 的語法有個主要的目的：用來作為一種網路內容的<em>寫作</em>用語言。</p>
</blockquote>
<h2 id="标题"><a href="#标题" class="headerlink" title="标题"></a>标题</h2><p>Markdown 语法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 第一级标题 `&lt;h1&gt;` </span><br><span class="line">## 第二级标题 `&lt;h2&gt;` </span><br><span class="line">###### 第六级标题 `&lt;h6&gt;`</span><br></pre></td></tr></table></figure>
<p>效果如下：</p>
<h1 id="第一级标题-lt-h1-gt"><a href="#第一级标题-lt-h1-gt" class="headerlink" title="第一级标题 &lt;h1&gt;"></a>第一级标题 <code>&lt;h1&gt;</code></h1><h2 id="第二级标题-lt-h2-gt"><a href="#第二级标题-lt-h2-gt" class="headerlink" title="第二级标题 &lt;h2&gt;"></a>第二级标题 <code>&lt;h2&gt;</code></h2><h6 id="第六级标题-lt-h6-gt"><a href="#第六级标题-lt-h6-gt" class="headerlink" title="第六级标题 &lt;h6&gt;"></a>第六级标题 <code>&lt;h6&gt;</code></h6><h2 id="强调"><a href="#强调" class="headerlink" title="强调"></a>强调</h2><p>Markdown 语法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">*这些文字会生成`&lt;em&gt;`*</span><br><span class="line">_这些文字会生成`&lt;u&gt;`_</span><br><span class="line"></span><br><span class="line">**这些文字会生成`&lt;strong&gt;`**</span><br><span class="line">__这些文字会生成`&lt;strong&gt;`__</span><br></pre></td></tr></table></figure>
<p>效果如下：</p>
<p><em>这些文字会生成<code>&lt;em&gt;</code></em><br><em>这些文字会生成<code>&lt;u&gt;</code></em></p>
<p><strong>这些文字会生成<code>&lt;strong&gt;</code></strong><br><strong>这些文字会生成<code>&lt;strong&gt;</code></strong></p>
<h2 id="换行"><a href="#换行" class="headerlink" title="换行"></a>换行</h2><p>四个及以上空格加回车。</p>
<h2 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h2><h3 id="无序列表"><a href="#无序列表" class="headerlink" title="无序列表"></a>无序列表</h3><p>Markdown 语法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">* 项目一 无序列表 `* + 空格键`</span><br><span class="line">* 项目二</span><br><span class="line">	* 项目二的子项目一 无序列表 `TAB + * + 空格键`</span><br><span class="line">	* 项目二的子项目二</span><br></pre></td></tr></table></figure>
<p>效果如下：</p>
<ul>
<li>项目一 无序列表 <code>* + 空格键</code></li>
<li>项目二<ul>
<li>项目二的子项目一 无序列表 <code>TAB + * + 空格键</code></li>
<li>项目二的子项目二</li>
</ul>
</li>
</ul>
<h3 id="有序列表"><a href="#有序列表" class="headerlink" title="有序列表"></a>有序列表</h3><p>Markdown 语法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1. 项目一 有序列表 `数字 + . + 空格键`</span><br><span class="line">2. 项目二 </span><br><span class="line">3. 项目三</span><br><span class="line">	1. 项目三的子项目一 有序列表 `TAB + 数字 + . + 空格键`</span><br><span class="line">	2. 项目三的子项目二</span><br></pre></td></tr></table></figure>
<p>效果如下：</p>
<ol>
<li>项目一 有序列表 <code>数字 + . + 空格键</code></li>
<li>项目二 </li>
<li>项目三<ol>
<li>项目三的子项目一 有序列表 <code>TAB + 数字 + . + 空格键</code></li>
<li>项目三的子项目二</li>
</ol>
</li>
</ol>
<h3 id="任务列表（Task-lists）"><a href="#任务列表（Task-lists）" class="headerlink" title="任务列表（Task lists）"></a>任务列表（Task lists）</h3><p>Markdown 语法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">- [ ] 任务一 未做任务 `- + 空格 + [ ]`</span><br><span class="line">- [x] 任务二 已做任务 `- + 空格 + [x]`</span><br></pre></td></tr></table></figure>
<p>效果如下：</p>
<ul>
<li style="list-style: none"><input type="checkbox"> 任务一 未做任务 <code>- + 空格 + [ ]</code></li>
<li style="list-style: none"><input type="checkbox" checked> 任务二 已做任务 <code>- + 空格 + [x]</code></li>
</ul>
<h2 id="图片"><a href="#图片" class="headerlink" title="图片"></a>图片</h2><p>Markdown 语法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">![GitHub set up](http://zh.mweb.im/asset/img/set-up-git.gif)</span><br><span class="line">格式: ![Alt Text](url)</span><br></pre></td></tr></table></figure>
<h2 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h2><p>Markdown 语法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">email &lt;example@example.com&gt;</span><br><span class="line">[GitHub](http://github.com)</span><br><span class="line">自动生成连接  &lt;http://www.github.com/&gt;</span><br></pre></td></tr></table></figure>
<p>效果如下：</p>
<p>Email 连接： <a href="mailto:&#x65;&#x78;&#97;&#x6d;&#x70;&#108;&#x65;&#64;&#101;&#x78;&#97;&#109;&#112;&#108;&#x65;&#x2e;&#99;&#x6f;&#x6d;" target="_blank" rel="noopener">&#x65;&#x78;&#97;&#x6d;&#x70;&#108;&#x65;&#64;&#101;&#x78;&#97;&#109;&#112;&#108;&#x65;&#x2e;&#99;&#x6f;&#x6d;</a><br><a href="http://github.com" target="_blank" rel="noopener">连接标题Github网站</a><br>自动生成连接像： <a href="http://www.github.com/" target="_blank" rel="noopener">http://www.github.com/</a> 这样</p>
<h2 id="区块引用"><a href="#区块引用" class="headerlink" title="区块引用"></a>区块引用</h2><p>Markdown 语法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">某某说:</span><br><span class="line">&gt; 第一行引用</span><br><span class="line">&gt; 第二行费用文字</span><br></pre></td></tr></table></figure>
<p>效果如下：</p>
<p>某某说:</p>
<blockquote>
<p>第一行引用<br>第二行费用文字</p>
</blockquote>
<h2 id="行内代码"><a href="#行内代码" class="headerlink" title="行内代码"></a>行内代码</h2><p>Markdown 语法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">像这样即可：`&lt;addr&gt;` `code`</span><br></pre></td></tr></table></figure>
<p>效果如下：</p>
<p>像这样即可：<code>&lt;addr&gt;</code> <code>code</code></p>
<h2 id="多行或者一段代码"><a href="#多行或者一段代码" class="headerlink" title="多行或者一段代码"></a>多行或者一段代码</h2><p>Markdown 语法：</p>
<pre><code><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">fancyAlert</span>(<span class="params">arg</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">if</span>(arg) &#123;</span><br><span class="line">    $.facebox(&#123;<span class="attr">div</span>:<span class="string">'#foo'</span>&#125;)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</code></pre><p>效果如下：</p>
<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">fancyAlert</span>(<span class="params">arg</span>) </span>&#123;</span><br><span class="line">	<span class="keyword">if</span>(arg) &#123;</span><br><span class="line">		$.facebox(&#123;<span class="attr">div</span>:<span class="string">'#foo'</span>&#125;)</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="顺序图或流程图"><a href="#顺序图或流程图" class="headerlink" title="顺序图或流程图"></a>顺序图或流程图</h2><p>Markdown 语法：</p>
<pre><code><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">张三-&gt;李四: 嘿，小四儿, 写博客了没?</span><br><span class="line">Note right of 李四: 李四愣了一下，说：</span><br><span class="line">李四--&gt;张三: 忙得吐血，哪有时间写。</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">st=&gt;start: 开始</span><br><span class="line">e=&gt;end: 结束</span><br><span class="line">op=&gt;operation: 我的操作</span><br><span class="line">cond=&gt;condition: 确认？</span><br><span class="line"></span><br><span class="line">st-&gt;op-&gt;cond</span><br><span class="line">cond(yes)-&gt;e</span><br><span class="line">cond(no)-&gt;op</span><br></pre></td></tr></table></figure>
</code></pre><p>效果如下（ <code>Preferences</code> - <code>Themes</code> - <code>Enable sequence &amp; flow chart</code> 才会看到效果 ）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">张三-&gt;李四: 嘿，小四儿, 写博客了没?</span><br><span class="line">Note right of 李四: 李四愣了一下，说：</span><br><span class="line">李四--&gt;张三: 忙得吐血，哪有时间写。</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">st=&gt;start: 开始</span><br><span class="line">e=&gt;end: 结束</span><br><span class="line">op=&gt;operation: 我的操作</span><br><span class="line">cond=&gt;condition: 确认？</span><br><span class="line"></span><br><span class="line">st-&gt;op-&gt;cond</span><br><span class="line">cond(yes)-&gt;e</span><br><span class="line">cond(no)-&gt;op</span><br></pre></td></tr></table></figure>
<p>更多请参考：<a href="http://bramp.github.io/js-sequence-diagrams/" target="_blank" rel="noopener">http://bramp.github.io/js-sequence-diagrams/</a>, <a href="http://adrai.github.io/flowchart.js/" target="_blank" rel="noopener">http://adrai.github.io/flowchart.js/</a></p>
<h2 id="表格"><a href="#表格" class="headerlink" title="表格"></a>表格</h2><p>Markdown 语法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">第一格表头 | 第二格表头</span><br><span class="line">--------- | -------------</span><br><span class="line">内容单元格 第一列第一格 | 内容单元格第二列第一格</span><br><span class="line">内容单元格 第一列第二格 多加文字 | 内容单元格第二列第二格</span><br></pre></td></tr></table></figure>
<p>效果如下：</p>
<table>
<thead>
<tr>
<th>第一格表头</th>
<th>第二格表头</th>
</tr>
</thead>
<tbody>
<tr>
<td>内容单元格 第一列第一格</td>
<td>内容单元格第二列第一格</td>
</tr>
<tr>
<td>内容单元格 第一列第二格 多加文字</td>
<td>内容单元格第二列第二格</td>
</tr>
</tbody>
</table>
<h2 id="删除线"><a href="#删除线" class="headerlink" title="删除线"></a>删除线</h2><p>Markdown 语法：</p>
<pre><code>加删除线像这样用： ~~删除这些~~
</code></pre><p>效果如下：</p>
<p>加删除线像这样用： <del>删除这些</del></p>
<h2 id="分隔线"><a href="#分隔线" class="headerlink" title="分隔线"></a>分隔线</h2><p>以下三种方式都可以生成分隔线：</p>
<pre><code>***

*****

- - -
</code></pre><p>效果如下：</p>
<hr>
<hr>
<hr>
<h2 id="MathJax"><a href="#MathJax" class="headerlink" title="MathJax"></a>MathJax</h2><p>Markdown 语法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">块级公式：</span><br><span class="line">$$	x = \dfrac&#123;-b \pm \sqrt&#123;b^2 - 4ac&#125;&#125;&#123;2a&#125; $$</span><br><span class="line"></span><br><span class="line">\\[ \frac&#123;1&#125;&#123;\Bigl(\sqrt&#123;\phi \sqrt&#123;5&#125;&#125;-\phi\Bigr) e^&#123;\frac25 \pi&#125;&#125; =</span><br><span class="line">1+\frac&#123;e^&#123;-2\pi&#125;&#125; &#123;1+\frac&#123;e^&#123;-4\pi&#125;&#125; &#123;1+\frac&#123;e^&#123;-6\pi&#125;&#125;</span><br><span class="line">&#123;1+\frac&#123;e^&#123;-8\pi&#125;&#125; &#123;1+\ldots&#125; &#125; &#125; &#125; \\]</span><br><span class="line"></span><br><span class="line">行内公式： $\Gamma(n) = (n-1)!\quad\forall n\in\mathbb N$</span><br></pre></td></tr></table></figure>
<p>效果如下（<code>Preferences</code> - <code>Themes</code> - <code>Enable MathJax</code> 才会看到效果）：</p>
<p>块级公式：<br>$$    x = \dfrac{-b \pm \sqrt{b^2 - 4ac}}{2a} $$</p>
<p>\[ \frac{1}{\Bigl(\sqrt{\phi \sqrt{5}}-\phi\Bigr) e^{\frac25 \pi}} =<br>1+\frac{e^{-2\pi}} {1+\frac{e^{-4\pi}} {1+\frac{e^{-6\pi}}<br>{1+\frac{e^{-8\pi}} {1+\ldots} } } } \]</p>
<p>行内公式： $\Gamma(n) = (n-1)!\quad\forall n\in\mathbb N$</p>
<h2 id="脚注（Footnote）"><a href="#脚注（Footnote）" class="headerlink" title="脚注（Footnote）"></a>脚注（Footnote）</h2><p>Markdown 语法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">这是一个脚注：[^sample_footnote]</span><br></pre></td></tr></table></figure>
<p>效果如下：</p>
<p>这是一个脚注：<a href="这里是脚注信息">^sample_footnote</a></p>
<h2 id="注释和阅读更多"><a href="#注释和阅读更多" class="headerlink" title="注释和阅读更多"></a>注释和阅读更多</h2><!-- comment -->
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/RyanLi.github.io/2018/07/24/2018-07-24 MarkDown语法/#more" rel="contents">
              Read more &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  


          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/RyanLi.github.io/uploads/avatar.jpeg"
                alt="Ryan Li" />
            
              <p class="site-author-name" itemprop="name">Ryan Li</p>
              <p class="site-description motion-element" itemprop="description">I miss u.</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/RyanLi.github.io/archives/">
              
                  <span class="site-state-item-count">9</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Ryan Li</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/RyanLi.github.io/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/RyanLi.github.io/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/RyanLi.github.io/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/RyanLi.github.io/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/RyanLi.github.io/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/RyanLi.github.io/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/RyanLi.github.io/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/RyanLi.github.io/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/RyanLi.github.io/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/RyanLi.github.io/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
