<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/RyanLi.github.io/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/RyanLi.github.io/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/RyanLi.github.io/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/RyanLi.github.io/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/RyanLi.github.io/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/RyanLi.github.io/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/RyanLi.github.io/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="I miss u.">
<meta property="og:type" content="website">
<meta property="og:title" content="Ryan Li God">
<meta property="og:url" content="https://ryanlic.github.io/page/2/index.html">
<meta property="og:site_name" content="Ryan Li God">
<meta property="og:description" content="I miss u.">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Ryan Li God">
<meta name="twitter:description" content="I miss u.">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/RyanLi.github.io/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":true,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://ryanlic.github.io/page/2/"/>





  <title>Ryan Li God</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/RyanLi.github.io/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Ryan Li God</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/RyanLi.github.io/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/RyanLi.github.io/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://ryanlic.github.io/RyanLi.github.io/2018/08/03/2018-08-03 Spark RDD常用算子操作（三） distinct，union，intersection，subtract，cartesian/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ryan Li">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/RyanLi.github.io/uploads/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ryan Li God">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/RyanLi.github.io/2018/08/03/2018-08-03 Spark RDD常用算子操作（三） distinct，union，intersection，subtract，cartesian/" itemprop="url">Spark RDD常用算子操作（三） distinct，union，intersection，subtract，cartesian</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-08-03T21:23:50+10:00">
                2018-08-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>本文作者：翟开顺<br>首发：CSDN<br>本人仅为自己方便查阅做了摘抄，请支持原作者<br>原文地址：<a href="https://blog.csdn.net/t1dmzks/article/details/72077428" target="_blank" rel="noopener">https://blog.csdn.net/t1dmzks/article/details/72077428</a></p>
</blockquote>
<h1 id="distinct，union，intersection，subtract，cartesian"><a href="#distinct，union，intersection，subtract，cartesian" class="headerlink" title="distinct，union，intersection，subtract，cartesian"></a>distinct，union，intersection，subtract，cartesian</h1><p><strong>spark伪集合</strong><br>尽管 RDD 本身不是严格意义上的集合，但它也支持许多数学上的集合操作，比如合并和相交操作, 下图展示了这四种操作 </p>
<h2 id="distinct"><a href="#distinct" class="headerlink" title="distinct"></a>distinct</h2><p>distinct用于去重， 我们生成的RDD可能有重复的元素，使用distinct方法可以去掉重复的元素, 不过此方法涉及到混洗，操作开销很大<br><strong>scala版本</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">var</span> <span class="type">RDD1</span> = sc.parallelize(<span class="type">List</span>(<span class="string">"aa"</span>,<span class="string">"aa"</span>,<span class="string">"bb"</span>,<span class="string">"cc"</span>,<span class="string">"dd"</span>))</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="type">RDD1</span>.collect</span><br><span class="line">res3: <span class="type">Array</span>[<span class="type">String</span>] = <span class="type">Array</span>(aa, aa, bb, cc, dd)</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">var</span> distinctRDD = <span class="type">RDD1</span>.distinct</span><br><span class="line"></span><br><span class="line">scala&gt; distinctRDD.collect</span><br><span class="line">res5: <span class="type">Array</span>[<span class="type">String</span>] = <span class="type">Array</span>(aa, dd, bb, cc)</span><br></pre></td></tr></table></figure></p>
<p><strong>java版本</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">    JavaRDD&lt;String&gt; RDD1 = sc.parallelize(Arrays.asList(<span class="string">"aa"</span>, <span class="string">"aa"</span>, <span class="string">"bb"</span>, <span class="string">"cc"</span>, <span class="string">"dd"</span>));</span><br><span class="line">    JavaRDD&lt;String&gt; distinctRDD = RDD1.distinct();</span><br><span class="line">    List&lt;String&gt; collect = distinctRDD.collect();</span><br><span class="line">    <span class="keyword">for</span> (String str:collect) &#123;</span><br><span class="line">        System.out.print(str+<span class="string">", "</span>);</span><br><span class="line">    &#125;</span><br><span class="line">---------输出----------</span><br><span class="line">aa, dd, bb, cc,</span><br></pre></td></tr></table></figure></p>
<h2 id="union"><a href="#union" class="headerlink" title="union"></a>union</h2><p>两个RDD进行合并<br><strong>scala版本</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">var</span> <span class="type">RDD1</span> = sc.parallelize(<span class="type">List</span>(<span class="string">"aa"</span>,<span class="string">"aa"</span>,<span class="string">"bb"</span>,<span class="string">"cc"</span>,<span class="string">"dd"</span>))</span><br><span class="line">scala&gt; <span class="keyword">var</span> <span class="type">RDD2</span> = sc.parallelize(<span class="type">List</span>(<span class="string">"aa"</span>,<span class="string">"dd"</span>,<span class="string">"ff"</span>))</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="type">RDD1</span>.collect</span><br><span class="line">res6: <span class="type">Array</span>[<span class="type">String</span>] = <span class="type">Array</span>(aa, aa, bb, cc, dd)</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="type">RDD2</span>.collect</span><br><span class="line">res7: <span class="type">Array</span>[<span class="type">String</span>] = <span class="type">Array</span>(aa, dd, ff)</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="type">RDD1</span>.union(<span class="type">RDD2</span>).collect</span><br><span class="line">res8: <span class="type">Array</span>[<span class="type">String</span>] = <span class="type">Array</span>(aa, aa, bb, cc, dd, aa, dd, ff)</span><br></pre></td></tr></table></figure></p>
<p><strong>java版本</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">    JavaRDD&lt;String&gt; RDD1 = sc.parallelize(Arrays.asList(<span class="string">"aa"</span>, <span class="string">"aa"</span>, <span class="string">"bb"</span>, <span class="string">"cc"</span>, <span class="string">"dd"</span>));</span><br><span class="line">    JavaRDD&lt;String&gt; RDD2 = sc.parallelize(Arrays.asList(<span class="string">"aa"</span>,<span class="string">"dd"</span>,<span class="string">"ff"</span>));</span><br><span class="line">    JavaRDD&lt;String&gt; unionRDD = RDD1.union(RDD2);</span><br><span class="line">    List&lt;String&gt; collect = unionRDD.collect();</span><br><span class="line">    <span class="keyword">for</span> (String str:collect) &#123;</span><br><span class="line">        System.out.print(str+<span class="string">", "</span>);</span><br><span class="line">    &#125;</span><br><span class="line">-----------输出---------</span><br><span class="line">aa, aa, bb, cc, dd, aa, dd, ff,</span><br></pre></td></tr></table></figure></p>
<h2 id="intersection"><a href="#intersection" class="headerlink" title="intersection"></a>intersection</h2><p>RDD1.intersection(RDD2) 返回两个RDD的交集，并且去重<br>intersection 需要混洗数据，比较浪费性能<br><strong>scala版本</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">var</span> <span class="type">RDD1</span> = sc.parallelize(<span class="type">List</span>(<span class="string">"aa"</span>,<span class="string">"aa"</span>,<span class="string">"bb"</span>,<span class="string">"cc"</span>,<span class="string">"dd"</span>))</span><br><span class="line">scala&gt; <span class="keyword">var</span> <span class="type">RDD2</span> = sc.parallelize(<span class="type">List</span>(<span class="string">"aa"</span>,<span class="string">"dd"</span>,<span class="string">"ff"</span>))</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="type">RDD1</span>.collect</span><br><span class="line">res6: <span class="type">Array</span>[<span class="type">String</span>] = <span class="type">Array</span>(aa, aa, bb, cc, dd)</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="type">RDD2</span>.collect</span><br><span class="line">res7: <span class="type">Array</span>[<span class="type">String</span>] = <span class="type">Array</span>(aa, dd, ff)</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">var</span> insertsectionRDD = <span class="type">RDD1</span>.intersection(<span class="type">RDD2</span>)</span><br><span class="line">scala&gt; insertsectionRDD.collect</span><br><span class="line"></span><br><span class="line">res9: <span class="type">Array</span>[<span class="type">String</span>] = <span class="type">Array</span>(aa, dd)</span><br></pre></td></tr></table></figure></p>
<p><strong>java版本</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">    JavaRDD&lt;String&gt; RDD1 = sc.parallelize(Arrays.asList(&quot;aa&quot;, &quot;aa&quot;, &quot;bb&quot;, &quot;cc&quot;, &quot;dd&quot;));</span><br><span class="line">    JavaRDD&lt;String&gt; RDD2 = sc.parallelize(Arrays.asList(&quot;aa&quot;,&quot;dd&quot;,&quot;ff&quot;));</span><br><span class="line">    JavaRDD&lt;String&gt; intersectionRDD = RDD1.intersection(RDD2);</span><br><span class="line">    List&lt;String&gt; collect = intersectionRDD.collect();</span><br><span class="line">    for (String str:collect) &#123;</span><br><span class="line">        System.out.print(str+&quot; &quot;);</span><br><span class="line">    &#125;</span><br><span class="line">-------------输出-----------</span><br><span class="line">aa dd</span><br></pre></td></tr></table></figure></p>
<h2 id="subtract"><a href="#subtract" class="headerlink" title="subtract"></a>subtract</h2><p>RDD1.subtract(RDD2),返回在RDD1中出现，但是不在RDD2中出现的元素，不去重<br><strong>scala版本</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">JavaRDD</span>&lt;<span class="type">String</span>&gt; <span class="type">RDD1</span> = sc.parallelize(<span class="type">Arrays</span>.asList(<span class="string">"aa"</span>, <span class="string">"aa"</span>,<span class="string">"bb"</span>, <span class="string">"cc"</span>, <span class="string">"dd"</span>));</span><br><span class="line"></span><br><span class="line"><span class="type">JavaRDD</span>&lt;<span class="type">String</span>&gt; <span class="type">RDD2</span> = sc.parallelize(<span class="type">Arrays</span>.asList(<span class="string">"aa"</span>,<span class="string">"dd"</span>,<span class="string">"ff"</span>));</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">var</span> substractRDD =<span class="type">RDD1</span>.subtract(<span class="type">RDD2</span>)</span><br><span class="line"></span><br><span class="line">scala&gt;  substractRDD.collect</span><br><span class="line">res10: <span class="type">Array</span>[<span class="type">String</span>] = <span class="type">Array</span>(bb, cc)</span><br></pre></td></tr></table></figure></p>
<p><strong>java版本</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">    JavaRDD&lt;String&gt; RDD1 = sc.parallelize(Arrays.asList(<span class="string">"aa"</span>, <span class="string">"aa"</span>, <span class="string">"bb"</span>,<span class="string">"cc"</span>, <span class="string">"dd"</span>));</span><br><span class="line">    JavaRDD&lt;String&gt; RDD2 = sc.parallelize(Arrays.asList(<span class="string">"aa"</span>,<span class="string">"dd"</span>,<span class="string">"ff"</span>));</span><br><span class="line">    JavaRDD&lt;String&gt; subtractRDD = RDD1.subtract(RDD2);</span><br><span class="line">    List&lt;String&gt; collect = subtractRDD.collect();</span><br><span class="line">    <span class="keyword">for</span> (String str:collect) &#123;</span><br><span class="line">        System.out.print(str+<span class="string">" "</span>);</span><br><span class="line">    &#125;</span><br><span class="line">------------输出-----------------</span><br><span class="line">bb  cc</span><br></pre></td></tr></table></figure></p>
<h2 id="cartesian"><a href="#cartesian" class="headerlink" title="cartesian"></a>cartesian</h2><p>RDD1.cartesian(RDD2) 返回RDD1和RDD2的笛卡儿积，这个开销非常大</p>
<p><strong>scala版本</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scala&gt;  <span class="keyword">var</span> <span class="type">RDD1</span> = sc.parallelize(<span class="type">List</span>(<span class="string">"1"</span>,<span class="string">"2"</span>,<span class="string">"3"</span>))</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">var</span> <span class="type">RDD2</span> = sc.parallelize(<span class="type">List</span>(<span class="string">"a"</span>,<span class="string">"b"</span>,<span class="string">"c"</span>))</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">var</span> cartesianRDD = <span class="type">RDD1</span>.cartesian(<span class="type">RDD2</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; cartesianRDD.collect</span><br><span class="line">res11: <span class="type">Array</span>[(<span class="type">String</span>, <span class="type">String</span>)] = <span class="type">Array</span>((<span class="number">1</span>,a), (<span class="number">1</span>,b), (<span class="number">1</span>,c), (<span class="number">2</span>,a), (<span class="number">2</span>,b), (<span class="number">2</span>,c), (<span class="number">3</span>,a), (<span class="number">3</span>,b), (<span class="number">3</span>,c))</span><br></pre></td></tr></table></figure></p>
<p><strong>java版本</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">    JavaRDD&lt;String&gt; RDD1 = sc.parallelize(Arrays.asList(<span class="string">"1"</span>, <span class="string">"2"</span>, <span class="string">"3"</span>));</span><br><span class="line">    JavaRDD&lt;String&gt; RDD2 = sc.parallelize(Arrays.asList(<span class="string">"a"</span>,<span class="string">"b"</span>,<span class="string">"c"</span>));</span><br><span class="line">    JavaPairRDD&lt;String, String&gt; cartesian = RDD1.cartesian(RDD2);</span><br><span class="line"></span><br><span class="line">    List&lt;Tuple2&lt;String, String&gt;&gt; collect1 = cartesian.collect();</span><br><span class="line">    <span class="keyword">for</span> (Tuple2&lt;String, String&gt; tp:collect1) &#123;</span><br><span class="line">        System.out.println(<span class="string">"("</span>+tp._1+<span class="string">" "</span>+tp._2+<span class="string">")"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">------------输出-----------------</span><br><span class="line">(<span class="number">1</span> a)</span><br><span class="line">(<span class="number">1</span> b)</span><br><span class="line">(<span class="number">1</span> c)</span><br><span class="line">(<span class="number">2</span> a)</span><br><span class="line">(<span class="number">2</span> b)</span><br><span class="line">(<span class="number">2</span> c)</span><br><span class="line">(<span class="number">3</span> a)</span><br><span class="line">(<span class="number">3</span> b)</span><br><span class="line">(<span class="number">3</span> c)</span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://ryanlic.github.io/RyanLi.github.io/2018/08/03/2018-08-03 Spark RDD常用算子操作（二） filter,map,flatMap/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ryan Li">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/RyanLi.github.io/uploads/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ryan Li God">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/RyanLi.github.io/2018/08/03/2018-08-03 Spark RDD常用算子操作（二） filter,map,flatMap/" itemprop="url">Spark RDD常用算子操作（二） filter,map,flatMap</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-08-03T21:22:50+10:00">
                2018-08-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>本文作者：翟开顺<br>首发：CSDN<br>本人仅为自己方便查阅做了摘抄，请支持原作者<br>原文地址：<a href="https://blog.csdn.net/t1dmzks/article/details/72077428" target="_blank" rel="noopener">https://blog.csdn.net/t1dmzks/article/details/72077428</a></p>
</blockquote>
<h1 id="filter-map-flatMap"><a href="#filter-map-flatMap" class="headerlink" title="filter,map,flatMap"></a>filter,map,flatMap</h1><h2 id="filter"><a href="#filter" class="headerlink" title="filter"></a>filter</h2><p>举例，在F:\sparktest\sample.txt 文件的内容如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">aa bb cc aa aa aa dd dd ee ee ee ee </span><br><span class="line">ff aa bb zks</span><br><span class="line">ee kks</span><br><span class="line">ee  zz zks</span><br></pre></td></tr></table></figure></p>
<p>我要将包含zks的行的内容给找出来<br><strong>scala版本</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">    <span class="keyword">val</span> lines = sc.textFile(<span class="string">"F:\\sparktest\\sample.txt"</span>).filter(line=&gt;line.contains(<span class="string">"zks"</span>))</span><br><span class="line">    <span class="comment">//打印内容</span></span><br><span class="line">    lines.collect().foreach(println(_));</span><br><span class="line">-------------输出------------------</span><br><span class="line">ff aa bb zks</span><br><span class="line">ee  zz zks</span><br></pre></td></tr></table></figure></p>
<p><strong>java版本</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">        JavaRDD&lt;String&gt; lines = sc.textFile(<span class="string">"F:\\sparktest\\sample.txt"</span>);</span><br><span class="line">        JavaRDD&lt;String&gt; zksRDD = lines.filter(<span class="keyword">new</span> Function&lt;String, Boolean&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> Boolean <span class="title">call</span><span class="params">(String s)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> s.contains(<span class="string">"zks"</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="comment">//打印内容</span></span><br><span class="line">        List&lt;String&gt; zksCollect = zksRDD.collect();</span><br><span class="line">        <span class="keyword">for</span> (String str:zksCollect) &#123;</span><br><span class="line">            System.out.println(str);</span><br><span class="line">        &#125;</span><br><span class="line">----------------输出-------------------</span><br><span class="line">ff aa bb zks</span><br><span class="line">ee  zz zks</span><br></pre></td></tr></table></figure></p>
<h2 id="map"><a href="#map" class="headerlink" title="map"></a>map</h2><p>map() 接收一个函数，把这个函数用于 RDD 中的每个元素，将函数的返回结果作为结果RDD编程 ｜ 31<br>RDD 中对应元素的值 map是一对一的关系<br>举例，在F:\sparktest\sample.txt 文件的内容如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">aa bb cc aa aa aa dd dd ee ee ee ee </span><br><span class="line">ff aa bb zks</span><br><span class="line">ee kks</span><br><span class="line">ee  zz zks</span><br></pre></td></tr></table></figure></p>
<p>把每一行变成一个数组<br><strong>scala版本</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//读取数据</span></span><br><span class="line">scala&gt; <span class="keyword">val</span> lines = sc.textFile(<span class="string">"F:\\sparktest\\sample.txt"</span>)</span><br><span class="line"><span class="comment">//用map，对于每一行数据，按照空格分割成一个一个数组，然后返回的是一对一的关系</span></span><br><span class="line">scala&gt; <span class="keyword">var</span> mapRDD = lines.map(line =&gt; line.split(<span class="string">"\\s+"</span>))</span><br><span class="line">---------------输出-----------</span><br><span class="line">res0: <span class="type">Array</span>[<span class="type">Array</span>[<span class="type">String</span>]] = <span class="type">Array</span>(<span class="type">Array</span>(aa, bb, cc, aa, aa, aa, dd, dd, ee, ee, ee, ee), <span class="type">Array</span>(ff, aa, bb, zks), <span class="type">Array</span>(ee, kks), <span class="type">Array</span>(ee, zz, zks))</span><br><span class="line"><span class="comment">//读取第一个元素</span></span><br><span class="line">scala&gt; mapRDD.first</span><br><span class="line">---输出----</span><br><span class="line">res1: <span class="type">Array</span>[<span class="type">String</span>] = <span class="type">Array</span>(aa, bb, cc, aa, aa, aa, dd, dd, ee, ee, ee, ee)</span><br></pre></td></tr></table></figure></p>
<p><strong>java版本</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">    JavaRDD&lt;Iterable&lt;String&gt;&gt; mapRDD = lines.map(<span class="keyword">new</span> Function&lt;String, Iterable&lt;String&gt;&gt;() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> Iterable&lt;String&gt; <span class="title">call</span><span class="params">(String s)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">            String[] split = s.split(<span class="string">"\\s+"</span>);</span><br><span class="line">            <span class="keyword">return</span> Arrays.asList(split);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">    <span class="comment">//读取第一个元素</span></span><br><span class="line">    System.out.println(mapRDD.first());</span><br><span class="line">---------------输出-------------</span><br><span class="line">[aa, bb, cc, aa, aa, aa, dd, dd, ee, ee, ee, ee]</span><br></pre></td></tr></table></figure></p>
<h2 id="flatMap"><a href="#flatMap" class="headerlink" title="flatMap"></a>flatMap</h2><p>有时候，我们希望对某个元素生成多个元素，实现该功能的操作叫作 flatMap()<br>faltMap的函数应用于每一个元素，对于每一个元素返回的是多个元素组成的迭代器(想要了解更多，请参考scala的flatMap和map用法)<br>例如我们将数据切分为单词<br><strong>scala版本</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">    scala&gt;  <span class="keyword">val</span> lines = sc.textFile(<span class="string">"F:\\sparktest\\sample.txt"</span>)</span><br><span class="line">    scala&gt; <span class="keyword">val</span> flatMapRDD = lines.flatMap(line=&gt;line.split(<span class="string">"\\s"</span>))</span><br><span class="line">    scala&gt; flatMapRDD.first() </span><br><span class="line">---输出----</span><br><span class="line">res0: <span class="type">String</span> = aa</span><br></pre></td></tr></table></figure></p>
<p><strong>java版本，spark2.0以下</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">    JavaRDD&lt;String&gt; lines = sc.textFile(<span class="string">"F:\\sparktest\\sample.txt"</span>);</span><br><span class="line">    JavaRDD&lt;String&gt; flatMapRDD = lines.flatMap(<span class="keyword">new</span> FlatMapFunction&lt;String, String&gt;() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> Iterable&lt;String&gt; <span class="title">call</span><span class="params">(String s)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">            String[] split = s.split(<span class="string">"\\s+"</span>);</span><br><span class="line">            <span class="keyword">return</span> Arrays.asList(split);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">    <span class="comment">//输出第一个</span></span><br><span class="line">    System.out.println(flatMapRDD.first());</span><br><span class="line">------------输出----------</span><br><span class="line">aa</span><br></pre></td></tr></table></figure></p>
<p><strong>java版本，spark2.0以上</strong><br>spark2.0以上，对flatMap的方法有所修改，就是flatMap中的Iterator和Iteratable的小区别<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;String&gt; flatMapRDD = lines.flatMap(<span class="keyword">new</span> FlatMapFunction&lt;String, String&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Iterator&lt;String&gt; <span class="title">call</span><span class="params">(String s)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        String[] split = s.split(<span class="string">"\\s+"</span>);</span><br><span class="line">        <span class="keyword">return</span> Arrays.asList(split).iterator();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://ryanlic.github.io/RyanLi.github.io/2018/08/03/2018-08-03 Spark RDD常用算子操作（一） parallelize，makeRDD，textFile/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ryan Li">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/RyanLi.github.io/uploads/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ryan Li God">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/RyanLi.github.io/2018/08/03/2018-08-03 Spark RDD常用算子操作（一） parallelize，makeRDD，textFile/" itemprop="url">Spark RDD常用算子操作（一） parallelize，makeRDD，textFile</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-08-03T21:21:50+10:00">
                2018-08-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>本文作者：翟开顺<br>首发：CSDN<br>本人仅为自己方便查阅做了摘抄，请支持原作者<br>原文地址：<a href="https://blog.csdn.net/t1dmzks/article/details/72077428" target="_blank" rel="noopener">https://blog.csdn.net/t1dmzks/article/details/72077428</a></p>
</blockquote>
<h1 id="parallelize，makeRDD，textFile"><a href="#parallelize，makeRDD，textFile" class="headerlink" title="parallelize，makeRDD，textFile"></a>parallelize，makeRDD，textFile</h1><h2 id="parallelize"><a href="#parallelize" class="headerlink" title="parallelize"></a>parallelize</h2><p>调用SparkContext 的 parallelize()，将一个存在的集合，变成一个RDD，这种方式试用于学习spark和做一些spark的测试</p>
<p><strong>scala版本</strong><br>def parallelize[T](seq: Seq[T], numSlices: Int = defaultParallelism)(implicit arg0: ClassTag[T]): RDD[T] </p>
<ul>
<li>第一个参数一是一个 Seq集合 </li>
<li>第二个参数是分区数 </li>
<li>返回的是RDD[T]</li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; sc.parallelize(<span class="type">List</span>(<span class="string">"shenzhen"</span>, <span class="string">"is a beautiful city"</span>))</span><br><span class="line">res1: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">String</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">1</span>] at parallelize at &lt;console&gt;:<span class="number">22</span></span><br></pre></td></tr></table></figure>
<p><strong>java版本</strong><br>def parallelize[T](list : java.util.List[T], numSlices : scala.Int) : org.apache.spark.api.java.JavaRDD[T] = { /* compiled code */ } </p>
<ul>
<li>第一个参数是一个List集合 </li>
<li>第二个参数是一个分区，可以默认 </li>
<li>返回的是一个JavaRDD[T]<br>java版本只能接收List的集合</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;String&gt; javaStringRDD = sc.parallelize(Arrays.asList(<span class="string">"shenzhen"</span>, <span class="string">"is a beautiful city"</span>));</span><br></pre></td></tr></table></figure>
<h2 id="makeRDD"><a href="#makeRDD" class="headerlink" title="makeRDD"></a>makeRDD</h2><p>只有scala版本的才有makeRDD<br>def makeRDD[T](seq : scala.Seq[T], numSlices : scala.Int = { /* compiled code */ })<br>跟parallelize类似</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sc.makeRDD(<span class="type">List</span>(<span class="string">"shenzhen"</span>, <span class="string">"is a beautiful city"</span>))</span><br></pre></td></tr></table></figure>
<h2 id="textFile"><a href="#textFile" class="headerlink" title="textFile"></a>textFile</h2><p>调用SparkContext.textFile()方法，从外部存储中读取数据来创建 RDD<br>例如在我本地F:\dataexample\wordcount\input下有个sample.txt文件，文件随便写了点内容，我需要将里面的内容读取出来创建RDD</p>
<p><strong>scala版本</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> lines = sc.textFile(<span class="string">"F:\\dataexample\\wordcount\\input"</span>)</span><br></pre></td></tr></table></figure></p>
<p><strong>java版本</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;String&gt; lines = sc.textFile(<span class="string">"F:\\dataexample\\wordcount\\input"</span>);</span><br></pre></td></tr></table></figure></p>
<p>注: textFile支持分区，支持模式匹配，例如把F:\dataexample\wordcount\目录下inp开头的给转换成RDD<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">var lines = sc.textFile(<span class="string">"F:\\dataexample\\wordcount\\inp*"</span>)</span><br></pre></td></tr></table></figure></p>
<p>多个路径可以使用逗号分隔，例如<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">var lines = sc.textFile(<span class="string">"dir1,dir2"</span>,<span class="number">3</span>)</span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://ryanlic.github.io/RyanLi.github.io/2018/07/31/2018-07-31 Spark2-1-3集群搭建/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ryan Li">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/RyanLi.github.io/uploads/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ryan Li God">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/RyanLi.github.io/2018/07/31/2018-07-31 Spark2-1-3集群搭建/" itemprop="url">Spark学习笔记（六）：Spark 2.1.3集群搭建</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-07-31T15:03:43+10:00">
                2018-07-31
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="安装Spark包"><a href="#安装Spark包" class="headerlink" title="安装Spark包"></a>安装Spark包</h2><ol>
<li>将spark-2.1.3-bin-hadoop2.4.tgz使用SFTP上传到/usr/local目录下。</li>
<li><p>解压缩spark包：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar zxvf spark-2.1.3-bin-hadoop2.4.tgz</span><br></pre></td></tr></table></figure>
</li>
<li><p>更改spark目录名：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv spark-2.1.3-bin-hadoop2.4 spark</span><br></pre></td></tr></table></figure>
</li>
<li><p>设置spark环境变量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">vi .bashrc</span><br><span class="line">export SPARK_HOME=/usr/local/spark</span><br><span class="line">export PATH=$SPARK_HOME/bin</span><br><span class="line">export CLASSPATH=.:$CLASSPATH:$JAVA_HOME/lib:$JAVA_HOME/jre/lib</span><br><span class="line"></span><br><span class="line">source .bashrc</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="修改spark-env-sh文件"><a href="#修改spark-env-sh文件" class="headerlink" title="修改spark-env.sh文件"></a>修改spark-env.sh文件</h2><ol>
<li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/spark/conf</span><br></pre></td></tr></table></figure>
</li>
<li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp spark-env.sh.template spark-env.sh</span><br></pre></td></tr></table></figure>
</li>
<li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">vi spark-env.sh</span><br><span class="line">export JAVA_HOME=/usr/java/latest</span><br><span class="line">export SCALA_HOME=/usr/local/scala</span><br><span class="line">export SPARK_MASTER_IP=10.211.55.24</span><br><span class="line">export SPARK_WORKER_MEMORY=2g</span><br><span class="line">export HADOOP_CONF_DIR=/usr/local/hadoop/etc/hadoop</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="修改slaves文件"><a href="#修改slaves文件" class="headerlink" title="修改slaves文件"></a>修改slaves文件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">spark1</span><br><span class="line">spark2</span><br><span class="line">spark3</span><br></pre></td></tr></table></figure>
<h2 id="安装spark集群"><a href="#安装spark集群" class="headerlink" title="安装spark集群"></a>安装spark集群</h2><p>在另外两个节点进行一模一样的配置，使用scp将spark和.bashrc拷贝到spark2和spark3即可。</p>
<h2 id="启动spark集群"><a href="#启动spark集群" class="headerlink" title="启动spark集群"></a>启动spark集群</h2><ol>
<li>在spark目录下的sbin目录</li>
<li><p>执行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./start-all.sh</span><br></pre></td></tr></table></figure>
</li>
<li><p>使用jsp和8080端口可以检查集群是否启动成功</p>
</li>
<li>进入spark-shell查看是否正常</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://ryanlic.github.io/RyanLi.github.io/2018/07/31/2018-07-31 kafka-2-9-2-0-8-1集群搭建/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ryan Li">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/RyanLi.github.io/uploads/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ryan Li God">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/RyanLi.github.io/2018/07/31/2018-07-31 kafka-2-9-2-0-8-1集群搭建/" itemprop="url">Spark学习笔记（五）：Kafka 2.9.2-0.8.1集群搭建（包括scala安装）</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-07-31T14:41:58+10:00">
                2018-07-31
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="安装scala-2-11-8"><a href="#安装scala-2-11-8" class="headerlink" title="安装scala 2.11.8"></a>安装scala 2.11.8</h2><blockquote><p>注意，scala的版本和之后要安装的spark版本密切关联，必须要和spark/jars中的scala-compiler-2.11.8.jar版本一致，而且之后用IDE打包的时候，选择scala版本也要一致</p>
</blockquote>
<ol>
<li>将scala-2.11.8.tgz使用WinSCP拷贝到spark1的/usr/local目录下。</li>
<li><p>对scala-2.11.8.tgz进行解压缩：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf scala-2.11.8.tgz</span><br></pre></td></tr></table></figure>
</li>
<li><p>对scala目录进行重命名：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv scala-2.11.8 scala</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置scala相关的环境变量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vi .bashrc</span><br><span class="line">export SCALA_HOME=/usr/local/scala</span><br><span class="line">export PATH=$SCALA_HOME/bin</span><br><span class="line"></span><br><span class="line">source .bashrc</span><br></pre></td></tr></table></figure>
</li>
<li><p>查看scala是否安装成功：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scala -version</span><br></pre></td></tr></table></figure>
</li>
<li><p>按照上述步骤在spark2和spark3机器上都安装好scala。使用scp将scala和.bashrc拷贝到spark2和spark3上即可</p>
</li>
</ol>
<h2 id="安装Kafka包"><a href="#安装Kafka包" class="headerlink" title="安装Kafka包"></a>安装Kafka包</h2><ol>
<li>将kafka_2.9.2-0.8.1.tgz使用SFTP工具拷贝到spark1的/usr/local目录下</li>
<li><p>对kafka_2.9.2-0.8.1.tgz进行解压缩：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf kafka_2.9.2-0.8.1.tgz</span><br></pre></td></tr></table></figure>
</li>
<li><p>对kafka目录进行改名：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv kafka_2.9.2-0.8.1 kafka</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置kafka</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vi /usr/local/kafka/config/server.properties</span><br><span class="line"># broker.id：依次增长的整数，0、1、2、3、4，集群中Broker的唯一id</span><br><span class="line"></span><br><span class="line">zookeeper.connect=10.211.55.24:2181,10.211.55.25:2181,10.211.55.26:2181</span><br><span class="line"># 这里填写自己的 spark1:2181,spark2:2181,spark3:2181</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装slf4j<br>将slf4j-1.7.6.zip上传到/usr/local目录下，再把slf4j中的slf4j-nop-1.7.6.jar复制到kafka的libs目录下面</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">unzip slf4j-1.7.6.zip</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="搭建kafka集群"><a href="#搭建kafka集群" class="headerlink" title="搭建kafka集群"></a>搭建kafka集群</h2><ol>
<li>按照上述步骤在spark2和spark3分别安装kafka。用scp把kafka拷贝到spark2和spark3即可。</li>
<li>唯一区别的，就是server.properties中的broker.id，要设置为1和2</li>
</ol>
<h2 id="启动kafka集群"><a href="#启动kafka集群" class="headerlink" title="启动kafka集群"></a>启动kafka集群</h2><ol>
<li><p>在三台机器上分别执行以下命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup bin/kafka-server-start.sh config/server.properties &amp;</span><br></pre></td></tr></table></figure>
</li>
<li><p>使用jps检查启动是否成功</p>
</li>
</ol>
<h2 id="测试kafka集群"><a href="#测试kafka集群" class="headerlink" title="测试kafka集群"></a>测试kafka集群</h2><p>使用基本命令检查kafka是否搭建成功<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --zookeeper 10.211.55.24:2181,10.211.55.25:2181,10.211.55.26:2181 --topic TestTopic --replication-factor 1 --partitions 1 --create</span><br><span class="line"></span><br><span class="line">bin/kafka-console-producer.sh --broker-list 10.211.55.24:9092,10.211.55.25:9092,10.211.55.26:9092 --topic TestTopic</span><br><span class="line"></span><br><span class="line">bin/kafka-console-consumer.sh --zookeeper 10.211.55.24:2181,10.211.55.25:2181,10.211.55.26:2181 --topic TestTopic --from-beginning</span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://ryanlic.github.io/RyanLi.github.io/2018/07/31/2018-07-31 ZooKeeper3-4-5集群搭建/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ryan Li">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/RyanLi.github.io/uploads/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ryan Li God">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/RyanLi.github.io/2018/07/31/2018-07-31 ZooKeeper3-4-5集群搭建/" itemprop="url">Spark学习笔记（四）：ZooKeeper 3.4.5集群搭建</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-07-31T14:32:43+10:00">
                2018-07-31
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="安装ZooKeeper包"><a href="#安装ZooKeeper包" class="headerlink" title="安装ZooKeeper包"></a>安装ZooKeeper包</h2><ol>
<li>将zookeeper-3.4.5.tar.gz使用SFTP工具拷贝到spark1的/usr/local目录下</li>
<li><p>对zookeeper-3.4.5.tar.gz进行解压缩：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf zookeeper-3.4.5.tar.gz</span><br></pre></td></tr></table></figure>
</li>
<li><p>对zookeeper目录进行重命名：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv zookeeper-3.4.5 zk</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置zookeeper相关的环境变量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vi .bashrc</span><br><span class="line">export ZOOKEEPER_HOME=/usr/local/zk</span><br><span class="line">export PATH=$ZOOKEEPER_HOME/bin</span><br><span class="line">source .bashrc</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="配置zoo-cfg"><a href="#配置zoo-cfg" class="headerlink" title="配置zoo.cfg"></a>配置zoo.cfg</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cd zk/conf</span><br><span class="line">mv zoo_sample.cfg zoo.cfg</span><br><span class="line"></span><br><span class="line">vi zoo.cfg</span><br><span class="line">修改：dataDir=/usr/local/zk/data</span><br><span class="line">新增：</span><br><span class="line">server.0=spark1:2888:3888	</span><br><span class="line">server.1=spark2:2888:3888</span><br><span class="line">server.2=spark3:2888:3888</span><br></pre></td></tr></table></figure>
<h2 id="设置zk节点标识"><a href="#设置zk节点标识" class="headerlink" title="设置zk节点标识"></a>设置zk节点标识</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cd zk</span><br><span class="line">mkdir data</span><br><span class="line">cd data</span><br><span class="line"></span><br><span class="line">vi myid</span><br><span class="line">0</span><br></pre></td></tr></table></figure>
<h2 id="搭建zk集群"><a href="#搭建zk集群" class="headerlink" title="搭建zk集群"></a>搭建zk集群</h2><ol>
<li>在另外两个节点上按照上述步骤配置ZooKeeper，使用scp将zk和~/.bashrc拷贝到spark2和spark3上即可，记得source ~/.bashrc</li>
<li>唯一的区别是spark2和spark3的标识号分别设置为1和2</li>
</ol>
<h2 id="启动ZooKeeper集群"><a href="#启动ZooKeeper集群" class="headerlink" title="启动ZooKeeper集群"></a>启动ZooKeeper集群</h2><ol>
<li><p>分别在三台机器上执行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zkServer.sh start</span><br></pre></td></tr></table></figure>
</li>
<li><p>检查ZooKeeper状态：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zkServer.sh status</span><br></pre></td></tr></table></figure></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://ryanlic.github.io/RyanLi.github.io/2018/07/31/2018-07-31 Hive0-13搭建/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ryan Li">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/RyanLi.github.io/uploads/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ryan Li God">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/RyanLi.github.io/2018/07/31/2018-07-31 Hive0-13搭建/" itemprop="url">Spark学习笔记（三）：Hive 0.13搭建</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-07-31T14:24:55+10:00">
                2018-07-31
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="安装hive包"><a href="#安装hive包" class="headerlink" title="安装hive包"></a>安装hive包</h2><ol>
<li>将apache-hive-0.13.1-bin.tar.gz使用SFTP工具上传到spark1的/usr/local目录下。</li>
<li><p>解压缩hive安装包：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf apache-hive-0.13.1-bin.tar.gz</span><br></pre></td></tr></table></figure>
</li>
<li><p>重命名hive目录：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv apache-hive-0.13.1-bin hive</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置hive相关的环境变量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vi .bashrc</span><br><span class="line">export HIVE_HOME=/usr/local/hive</span><br><span class="line">export PATH=$HIVE_HOME/bin</span><br><span class="line">source .bashrc</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="安装mysql"><a href="#安装mysql" class="headerlink" title="安装mysql"></a>安装mysql</h2><ol>
<li>在spark1上安装mysql</li>
<li><p>使用yum安装mysql server</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yum install -y mysql-server</span><br><span class="line">service mysqld start</span><br><span class="line">chkconfig mysqld on</span><br></pre></td></tr></table></figure>
</li>
<li><p>使用yum安装mysql connector</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y mysql-connector-java</span><br></pre></td></tr></table></figure>
</li>
<li><p>将mysql connector拷贝到hive的lib包中</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp /usr/share/java/mysql-connector-java-5.1.17.jar /usr/local/hive/lib</span><br></pre></td></tr></table></figure>
</li>
<li><p>在mysql上创建hive元数据库，并对hive进行授权</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">create database if not exists hive_metadata;</span><br><span class="line">grant all privileges on hive_metadata.* to &apos;hive&apos;@&apos;%&apos; identified by &apos;hive&apos;;</span><br><span class="line">grant all privileges on hive_metadata.* to &apos;hive&apos;@&apos;localhost&apos; identified by &apos;hive&apos;;</span><br><span class="line">grant all privileges on hive_metadata.* to &apos;hive&apos;@&apos;spark1&apos; identified by &apos;hive&apos;;</span><br><span class="line">flush privileges;</span><br><span class="line">use hive_metadata;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="配置hive-site-xml"><a href="#配置hive-site-xml" class="headerlink" title="配置hive-site.xml"></a>配置hive-site.xml</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mv hive-default.xml.template hive-site.xml</span><br><span class="line">vi hive-site.xml</span><br></pre></td></tr></table></figure>
<p>更改如下项目：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;jdbc:mysql://spark1:3306/hive_metadata?createDatabaseIfNotExist=true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;hive&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;hive&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;/user/hive/warehouse&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></p>
<h2 id="配置hive-env-sh和hive-config-sh"><a href="#配置hive-env-sh和hive-config-sh" class="headerlink" title="配置hive-env.sh和hive-config.sh"></a>配置hive-env.sh和hive-config.sh</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mv hive-env.sh.template hive-env.sh</span><br><span class="line">vi /usr/local/hive/bin/hive-config.sh</span><br><span class="line"></span><br><span class="line">export JAVA_HOME=/usr/java/latest</span><br><span class="line">export HIVE_HOME=/usr/local/hive</span><br><span class="line">export HADOOP_HOME=/usr/local/hadoop</span><br></pre></td></tr></table></figure>
<h2 id="验证hive是否安装成功"><a href="#验证hive是否安装成功" class="headerlink" title="验证hive是否安装成功"></a>验证hive是否安装成功</h2><p>直接输入hive命令，可以进入hive命令行</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://ryanlic.github.io/RyanLi.github.io/2018/07/31/2018-07-31 Hadoop2-4-1集群搭建/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ryan Li">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/RyanLi.github.io/uploads/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ryan Li God">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/RyanLi.github.io/2018/07/31/2018-07-31 Hadoop2-4-1集群搭建/" itemprop="url">Spark学习笔记（二）：Hadoop 2.4.1集群搭建</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-07-31T13:32:07+10:00">
                2018-07-31
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="安装hadoop包"><a href="#安装hadoop包" class="headerlink" title="安装hadoop包"></a>安装hadoop包</h2><ol>
<li>下载好hadoop-2.4.1.tar.gz，使用SFTP工具上传到CentOS的/usr/local目录下</li>
<li><p>将hadoop包进行解压缩：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf hadoop-2.4.1.tar.gz</span><br></pre></td></tr></table></figure>
</li>
<li><p>对hadoop目录进行重命名：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv hadoop-2.4.1 hadoop</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置hadoop相关环境变量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vi .bashrc</span><br><span class="line">export HADOOP_HOME=/usr/local/hadoop</span><br><span class="line">export PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin</span><br><span class="line">source .bashrc</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="配置Hadoop"><a href="#配置Hadoop" class="headerlink" title="配置Hadoop"></a>配置Hadoop</h2><h3 id="修改core-site-xml"><a href="#修改core-site-xml" class="headerlink" title="修改core-site.xml"></a>修改core-site.xml</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;fs.default.name&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;hdfs://spark1:9000&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>
<h3 id="修改hdfs-site-xml"><a href="#修改hdfs-site-xml" class="headerlink" title="修改hdfs-site.xml"></a>修改hdfs-site.xml</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.name.dir&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;/usr/local/data/namenode&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.data.dir&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;/usr/local/data/datanode&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.tmp.dir&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;/usr/local/data/tmp&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;3&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>
<h3 id="修改mapred-site-xml"><a href="#修改mapred-site-xml" class="headerlink" title="修改mapred-site.xml"></a>修改mapred-site.xml</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>
<h3 id="修改yarn-site-xml"><a href="#修改yarn-site-xml" class="headerlink" title="修改yarn-site.xml"></a>修改yarn-site.xml</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;spark1&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>
<h3 id="修改slaves文件"><a href="#修改slaves文件" class="headerlink" title="修改slaves文件"></a>修改slaves文件</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">spark1</span><br><span class="line">spark2</span><br><span class="line">spark3</span><br></pre></td></tr></table></figure>
<h3 id="在另外两台机器上搭建hadoop"><a href="#在另外两台机器上搭建hadoop" class="headerlink" title="在另外两台机器上搭建hadoop"></a>在另外两台机器上搭建hadoop</h3><ol>
<li>使用如上配置在另外两台机器上搭建hadoop，可以使用scp命令将spark1上面的hadoop安装包和.bashrc配置文件都拷贝过去</li>
<li>要记得对.bashrc文件进行source，以让它生效</li>
<li>记得在spark2和spark3的/usr/local目录下创建data目录</li>
</ol>
<h2 id="启动hdfs集群"><a href="#启动hdfs集群" class="headerlink" title="启动hdfs集群"></a>启动hdfs集群</h2><ol>
<li><p>格式化namenode：在spark1上执行以下命令(不要执行多次，不然会导致datanode的ID不一致，以后都只要直接第二步):</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode -format</span><br></pre></td></tr></table></figure>
</li>
<li><p>启动hdfs集群：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-dfs.sh</span><br></pre></td></tr></table></figure>
</li>
<li><p>验证启动是否成功：jps、50070端口<br>spark1：namenode、datanode、secondarynamenode<br>spark2：datanode<br>spark3：datanode</p>
</li>
</ol>
<h2 id="启动yarn集群"><a href="#启动yarn集群" class="headerlink" title="启动yarn集群"></a>启动yarn集群</h2><ol>
<li><p>启动yarn集群：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/hadoop/sbin/start-yarn.sh</span><br></pre></td></tr></table></figure>
</li>
<li><p>验证启动是否成功：jps、8088端口<br>spark1：resourcemanager、nodemanager<br>spark2：nodemanager<br>spark3：nodemanager</p>
</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://ryanlic.github.io/RyanLi.github.io/2018/07/31/2018-07-31 CentOS6-5集群搭建/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ryan Li">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/RyanLi.github.io/uploads/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ryan Li God">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/RyanLi.github.io/2018/07/31/2018-07-31 CentOS6-5集群搭建/" itemprop="url">Spark学习笔记（一）：CentOS 6.5集群搭建</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-07-31T12:46:36+10:00">
                2018-07-31
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="运行环境"><a href="#运行环境" class="headerlink" title="运行环境"></a>运行环境</h2><ol>
<li>CentOS 6.5</li>
<li>JDK 1.7</li>
<li>Hadoop 2.4.1</li>
<li>Hive 0.13</li>
<li>ZooKeeper 3.4.5</li>
<li>kafka_2.9.2-0.8.1</li>
<li>Spark 2.1.3</li>
<li>scala 2.11.8</li>
</ol>
<h2 id="安装CentOS-6-5"><a href="#安装CentOS-6-5" class="headerlink" title="安装CentOS 6.5"></a>安装CentOS 6.5</h2><ol>
<li>在macOS下，使用<strong><em>Parallels Desktop</em></strong>直接安装，CentOS 6.5使用的只需要官网的一个DVD1.iso文件。</li>
<li>启动以后使用<strong><em>Termius</em></strong>连接三台机器，使用<strong><em>Transmit</em></strong>传文件。<h2 id="CentOS-6-5防火墙配置"><a href="#CentOS-6-5防火墙配置" class="headerlink" title="CentOS 6.5防火墙配置"></a>CentOS 6.5防火墙配置</h2>关闭防火墙<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">service iptables stop</span><br><span class="line">chkconfig iptables off</span><br><span class="line">vi /etc/selinux/config</span><br><span class="line">SELINUX=disabled</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="JDK-1-7安装"><a href="#JDK-1-7安装" class="headerlink" title="JDK 1.7安装"></a>JDK 1.7安装</h2><p>我下载的CentOS自带，所以不用安装，装之前用java -version测试是否自带JDK。</p>
<ol>
<li>将jdk-7u60-linux-i586.rpm通过WinSCP上传到虚拟机中</li>
<li><p>安装JDK：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpm -ivh jdk-7u65-linux-i586.rpm</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置jdk相关的环境变量</p>
</li>
<li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vi .bashrc</span><br><span class="line">export JAVA_HOME=/usr/java/latest</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br><span class="line">source .bashrc</span><br></pre></td></tr></table></figure>
</li>
<li><p>测试jdk安装是否成功：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -version</span><br></pre></td></tr></table></figure>
</li>
<li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rm -f /etc/udev/rules.d/70-persistent-net.rules</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="安装第二台和第三台虚拟机"><a href="#安装第二台和第三台虚拟机" class="headerlink" title="安装第二台和第三台虚拟机"></a>安装第二台和第三台虚拟机</h2><ol>
<li>安装上述步骤，再安装两台一模一样环境的虚拟机，因为后面hadoop和spark都是要搭建集群的。</li>
<li>集群的最小环境就是三台。因为后面要搭建ZooKeeper、kafka等集群。</li>
<li>另外两台机器的hostname分别设置为spark2和spark3即可，通过终端输入ifconfig查看ip，记下。</li>
<li><p>安装好之后，记得要在三台机器的/etc/hosts文件中，配置全三台机器的ip地址到hostname的映射，而不能只配置本机。比如我的：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[spark1@spark1 Desktop]$ cat /etc/hosts</span><br><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line">10.211.55.24 spark1</span><br><span class="line">10.211.55.25 spark2</span><br><span class="line">10.211.55.26 spark3</span><br></pre></td></tr></table></figure>
</li>
<li><p>mac中Parallels Desktop会自动配置到虚拟机的地址映射，开启虚拟机以后在mac中可以直接ssh root@spark1进行连接</p>
</li>
</ol>
<h2 id="配置集群ssh免密码登录"><a href="#配置集群ssh免密码登录" class="headerlink" title="配置集群ssh免密码登录"></a>配置集群ssh免密码登录</h2><ol>
<li><p>首先在三台机器上配置对本机的ssh免密码登录<br>生成本机的公钥，过程中不断敲回车即可，ssh-keygen命令默认会将公钥放在/root/.ssh目录下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa</span><br></pre></td></tr></table></figure>
</li>
<li><p>将公钥复制为authorized_keys文件，此时使用ssh连接本机就不需要输入密码了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /root/.ssh</span><br><span class="line">cp id_rsa.pub authorized_keys</span><br></pre></td></tr></table></figure>
</li>
<li><p>接着配置三台机器互相之间的ssh免密码登录，使用ssh-copy-id -i spark{N}命令将本机的公钥拷贝到指定机器的authorized_keys文件中：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@spark1 ~]# ssh-copy-id -i spark2</span><br><span class="line">[root@spark1 ~]# ssh-copy-id -i spark3</span><br><span class="line">[root@spark2 ~]# ssh-copy-id -i spark1</span><br><span class="line">[root@spark2 ~]# ssh-copy-id -i spark3</span><br><span class="line">[root@spark3 ~]# ssh-copy-id -i spark1</span><br><span class="line">[root@spark3 ~]# ssh-copy-id -i spark2</span><br></pre></td></tr></table></figure></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://ryanlic.github.io/RyanLi.github.io/2018/07/25/2018-07-25 启动Hadoop、Spark等环境步骤记录/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ryan Li">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/RyanLi.github.io/uploads/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ryan Li God">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/RyanLi.github.io/2018/07/25/2018-07-25 启动Hadoop、Spark等环境步骤记录/" itemprop="url">启动Hadoop、Spark等环境步骤记录</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-07-25T14:19:06+10:00">
                2018-07-25
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h2><ol>
<li><p>启动hdfs集群：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-dfs.sh</span><br></pre></td></tr></table></figure>
</li>
<li><p>验证启动是否成功：jps、50070端口<br>spark1：namenode、datanode、secondarynamenode<br>spark2：datanode<br>spark3：datanode</p>
</li>
</ol>
<h2 id="YARN"><a href="#YARN" class="headerlink" title="YARN"></a>YARN</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/hadoop/sbin/start-yarn.sh</span><br></pre></td></tr></table></figure>
<h2 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h2><p>在spark1中，直接输入:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive</span><br></pre></td></tr></table></figure></p>
<h2 id="ZooKeeper"><a href="#ZooKeeper" class="headerlink" title="ZooKeeper"></a>ZooKeeper</h2><ol>
<li><p>分别在三台机器上执行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zkServer.sh start</span><br></pre></td></tr></table></figure>
</li>
<li><p>检查ZooKeeper状态：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zkServer.sh status</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="kafka"><a href="#kafka" class="headerlink" title="kafka"></a>kafka</h2><ol>
<li><p>在三台机器上分别执行以下命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/kafka/</span><br></pre></td></tr></table></figure>
</li>
<li><p>执行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup bin/kafka-server-start.sh config/server.properties &amp;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h2><ol>
<li><p>在spark目录下的sbin目录</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/spark/sbin</span><br></pre></td></tr></table></figure>
</li>
<li><p>执行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./start-all.sh</span><br></pre></td></tr></table></figure>
</li>
<li><p>使用jsp和8080端口可以检查集群是否启动成功</p>
</li>
<li>进入spark-shell查看是否正常</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/RyanLi.github.io/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/RyanLi.github.io/">1</a><span class="page-number current">2</span><a class="page-number" href="/RyanLi.github.io/page/3/">3</a><a class="extend next" rel="next" href="/RyanLi.github.io/page/3/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/RyanLi.github.io/uploads/avatar.jpeg"
                alt="Ryan Li" />
            
              <p class="site-author-name" itemprop="name">Ryan Li</p>
              <p class="site-description motion-element" itemprop="description">I miss u.</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/RyanLi.github.io/archives/">
              
                  <span class="site-state-item-count">21</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Ryan Li</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/RyanLi.github.io/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/RyanLi.github.io/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/RyanLi.github.io/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/RyanLi.github.io/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/RyanLi.github.io/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/RyanLi.github.io/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/RyanLi.github.io/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/RyanLi.github.io/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/RyanLi.github.io/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/RyanLi.github.io/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
